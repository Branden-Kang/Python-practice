{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMvGKUEnVB7stAMhC3pEO2P"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[Reference](https://levelup.gitconnected.com/how-to-mlforecast-your-time-series-data-c583283e0c28)"
      ],
      "metadata": {
        "id": "c1bl1ra24YFT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "zz4UzcvI4H8_"
      },
      "outputs": [],
      "source": [
        "from mlforecast import MLForecast\n",
        "from coreforecast.scalers import AutoDifferences\n",
        "import lightgbm as lgb\n",
        "\n",
        "# Create an MLForecast instance with AutoDifferences\n",
        "fcst = MLForecast(\n",
        "    models=[lgb.LGBMRegressor()],\n",
        "    freq='D',\n",
        "    lags=[1, 7, 14],\n",
        "    target_transforms=[AutoDifferences(max_diffs=2)]\n",
        ")\n",
        "\n",
        "# Fit the model and make predictions\n",
        "fcst.fit(train_data)\n",
        "predictions = fcst.predict(horizon=30)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For Quarterly Data:\n",
        "from mlforecast import MLForecast\n",
        "from mlforecast.lag_transforms import RollingMean, ExpandingMean\n",
        "\n",
        "fcst = MLForecast(\n",
        "    models=[],  # Add your models here\n",
        "    freq='Q',   # Quarterly frequency\n",
        "    lags=[1, 4],  # Lag of 1 quarter and 1 year\n",
        "    lag_transforms={\n",
        "        1: [ExpandingMean()],\n",
        "        4: [RollingMean(window_size=4)]  # Rolling mean over the past year\n",
        "    },\n",
        "    date_features=['quarter']\n",
        ")"
      ],
      "metadata": {
        "id": "R5sRaypc4b4u"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For Weekly Data\n",
        "fcst = MLForecast(\n",
        "    models=[],  # Add your models here\n",
        "    freq='W',   # Weekly frequency\n",
        "    lags=[1, 4, 52],  # Lag of 1 week, 1 month, and 1 year\n",
        "    lag_transforms={\n",
        "        1: [ExpandingMean()],\n",
        "        4: [RollingMean(window_size=4)],  # Rolling mean over the past month\n",
        "        52: [RollingMean(window_size=52)]  # Rolling mean over the past year\n",
        "    },\n",
        "    date_features=['week']\n",
        ")"
      ],
      "metadata": {
        "id": "2ejsXOrb41QO"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For Daily Data\n",
        "fcst = MLForecast(\n",
        "    models=[],  # Add your models here\n",
        "    freq='D',   # Daily frequency\n",
        "    lags=[1, 7, 30, 365],  # Lag of 1 day, 1 week, 1 month, and 1 year\n",
        "    lag_transforms={\n",
        "        1: [ExpandingMean()],\n",
        "        7: [RollingMean(window_size=7)],   # Rolling mean over the past week\n",
        "        30: [RollingMean(window_size=30)], # Rolling mean over the past month\n",
        "        365: [RollingMean(window_size=365)] # Rolling mean over the past year\n",
        "    },\n",
        "    date_features=['dayofweek', 'month']\n",
        ")"
      ],
      "metadata": {
        "id": "bjQ3rzq045pO"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For Hourly Data\n",
        "fcst = MLForecast(\n",
        "    models=[],  # Add your models here\n",
        "    freq='H',   # Hourly frequency\n",
        "    lags=[1, 24, 168, 720],  # Lag of 1 hour, 1 day, 1 week, and 1 month\n",
        "    lag_transforms={\n",
        "        1: [ExpandingMean()],\n",
        "        24: [RollingMean(window_size=24)],   # Rolling mean over the past day\n",
        "        168: [RollingMean(window_size=168)], # Rolling mean over the past week\n",
        "        720: [RollingMean(window_size=720)]  # Rolling mean over the past month\n",
        "    },\n",
        "    date_features=['hour', 'dayofweek']\n",
        ")"
      ],
      "metadata": {
        "id": "G9xCX71a49Jz"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.base import BaseEstimator, RegressorMixin\n",
        "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
        "\n",
        "class CustomModel(BaseEstimator, RegressorMixin):\n",
        "    def __init__(self, param1=1, param2=1):\n",
        "        self.param1 = param1\n",
        "        self.param2 = param2\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        # Check that X and y have correct shape\n",
        "        X, y = check_X_y(X, y)\n",
        "        # Store the classes seen during fit\n",
        "        self.classes_ = unique_labels(y)\n",
        "\n",
        "        # Your model fitting logic here\n",
        "\n",
        "        # Return the classifier\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        # Check is fit had been called\n",
        "        check_is_fitted(self)\n",
        "        # Input validation\n",
        "        X = check_array(X)\n",
        "\n",
        "        # Your prediction logic here\n",
        "\n",
        "        return y_pred"
      ],
      "metadata": {
        "id": "2CBD8npK5BQY"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from mlforecast import MLForecast\n",
        "from your_module import CustomModel\n",
        "\n",
        "mlf = MLForecast(\n",
        "    models=[CustomModel()],  # Use your custom model here\n",
        "    freq='D',  # Frequency of the data - 'D' for daily frequency\n",
        "    lags=[1, 2, 3],  # Lag features to use\n",
        "    date_features=['dayofweek', 'month'],  # Date-based features\n",
        ")"
      ],
      "metadata": {
        "id": "mtNehFBE5ED-"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model\n",
        "mlf.fit(df)\n",
        "\n",
        "# Make predictions\n",
        "predictions = mlf.predict(horizon=7)"
      ],
      "metadata": {
        "id": "RyvO0Eox5FzN"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from mlforecast import MLForecast\n",
        "from mlforecast.target_transforms import Differences\n",
        "from numba import njit\n",
        "import lightgbm as lgb\n",
        "import xgboost as xgb\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from statsmodels.tsa.seasonal import seasonal_decompose\n",
        "from mlforecast import MLForecast\n",
        "from mlforecast.lag_transforms import (\n",
        "    RollingMean, RollingStd, RollingMin, RollingMax, RollingQuantile,\n",
        "    SeasonalRollingMean, SeasonalRollingStd, SeasonalRollingMin,\n",
        "    SeasonalRollingMax, SeasonalRollingQuantile,\n",
        "    ExpandingMean\n",
        ")\n",
        "from coreforecast.scalers import AutoDifferences\n",
        "\n",
        "file_path = \"USD-INR.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "df['Month'] = pd.to_datetime(df['Month'])\n",
        "df = df.set_index('Month').resample('MS').mean()\n",
        "df = df.interpolate() #to interpolate and fill missing values\n",
        "df.reset_index(inplace=True)\n",
        "print(df.head())\n",
        "\n",
        "result = seasonal_decompose(df['RUPEES/US$'], model='additive')\n",
        "\n",
        "fig, (ax1, ax2, ax3, ax4) = plt.subplots(4, 1, figsize=(10, 12))\n",
        "\n",
        "result.observed.plot(ax=ax1, color=\"#69d\")\n",
        "ax1.set_ylabel('Observed')\n",
        "\n",
        "result.trend.plot(ax=ax2, color='#ff7f0e')\n",
        "ax2.set_ylabel('Trend')\n",
        "\n",
        "result.seasonal.plot(ax=ax3, color='#ff7f0e')\n",
        "ax3.set_ylabel('Seasonal')\n",
        "\n",
        "result.resid.plot(ax=ax4, color='#ff7f0e')\n",
        "ax4.set_ylabel('Residual')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "df = pd.DataFrame({'unique_id':[1]*len(df),\n",
        "        'ds': df[\"Month\"], \"y\":df['RUPEES/US$']})\n",
        "\n",
        "#Train-Test Split\n",
        "train_size = int(len(df) * 0.8)\n",
        "train, test = df.iloc[:train_size], df.iloc[train_size:]\n",
        "\n",
        "print(f'Train set size: {len(train)}')\n",
        "print(f'Test set size: {len(test)}')\n",
        "\n",
        "models = [LinearRegression(),  # Simple linear regression model\n",
        "    lgb.LGBMRegressor(verbosity=-1),  # LightGBM regressor with verbosity turned off\n",
        "    xgb.XGBRegressor(),  # XGBoost regressor with default parameters\n",
        "    RandomForestRegressor(random_state=0),  # Random Forest regressor with fixed random state for reproducibility\n",
        "]\n",
        "fcst = MLForecast(\n",
        "    models=models,  # List of models to be used for forecasting\n",
        "    freq='MS',  # Monthly frequency, starting at the beginning of each month\n",
        "    lags=[1,3,5,7,12],  # Lag features: values from 1, 3, 5, 7, and 12 time steps ago\n",
        "    lag_transforms={\n",
        "        1: [  # Transformations applied to lag 1\n",
        "            RollingMean(window_size=3),  # Rolling mean with a window of 3 time steps\n",
        "            RollingStd(window_size=3),  # Rolling standard deviation with a window of 3 time steps\n",
        "            RollingMin(window_size=3),  # Rolling minimum with a window of 3 time steps\n",
        "            RollingMax(window_size=3),  # Rolling maximum with a window of 3 time steps\n",
        "            RollingQuantile(p=0.5, window_size=3),  # Rolling median (50th percentile) with a window of 3 time steps\n",
        "            ExpandingMean()  # Expanding mean (mean of all previous values)\n",
        "        ],\n",
        "        6:[  # Transformations applied to lag 6\n",
        "            RollingMean(window_size=6),  # Rolling mean with a window of 6 time steps\n",
        "            RollingStd(window_size=6),  # Rolling standard deviation with a window of 6 time steps\n",
        "            RollingMin(window_size=6),  # Rolling minimum with a window of 6 time steps\n",
        "            RollingMax(window_size=6),  # Rolling maximum with a window of 6 time steps\n",
        "            RollingQuantile(p=0.5, window_size=6),  # Rolling median (50th percentile) with a window of 6 time steps\n",
        "        ],\n",
        "        12: [  # Transformations applied to lag 12 (likely for yearly seasonality)\n",
        "            SeasonalRollingMean(season_length=12, window_size=3),  # Seasonal rolling mean with 12-month seasonality and 3-month window\n",
        "            SeasonalRollingStd(season_length=12, window_size=3),  # Seasonal rolling standard deviation with 12-month seasonality and 3-month window\n",
        "            SeasonalRollingMin(season_length=12, window_size=3),  # Seasonal rolling minimum with 12-month seasonality and 3-month window\n",
        "            SeasonalRollingMax(season_length=12, window_size=3),  # Seasonal rolling maximum with 12-month seasonality and 3-month window\n",
        "            SeasonalRollingQuantile(p=0.5, season_length=12, window_size=3)  # Seasonal rolling median with 12-month seasonality and 3-month window\n",
        "        ]\n",
        "    },\n",
        "    date_features=['year', 'month', 'quarter'],  # Extract year, month, and quarter from the date as features\n",
        "    target_transforms=[Differences([1])])  # Apply first-order differencing to the target variable\n",
        "\n",
        "preprocessed_df = fcst.preprocess(train)\n",
        "print(preprocessed_df)\n",
        "\n",
        "fcst.fit(train_)\n",
        "# Fits the MLForecast model to the training data\n",
        "# This trains all specified models (LinearRegression, LGBMRegressor, XGBRegressor, RandomForestRegressor)\n",
        "# and prepares the feature engineering pipeline\n",
        "\n",
        "ml_prediction = fcst.predict(len(test_))\n",
        "# Generates predictions for a horizon equal to the length of the test set\n",
        "# Returns a DataFrame with predictions from all models\n",
        "\n",
        "ml_prediction.rename(columns={'ds': 'Month'}, inplace=True)\n",
        "# Renames the 'ds' column (default name for date/time column in MLForecast) to 'Month'\n",
        "# This is done in-place, modifying the original DataFrame\n",
        "\n",
        "fcst_result = test.copy()\n",
        "# Creates a copy of the test DataFrame to store the results\n",
        "# This preserves the original test data while allowing us to add predictions\n",
        "\n",
        "fcst_result.set_index(\"Month\", inplace=True)\n",
        "# Sets the 'Month' column as the index of the fcst_result DataFrame\n",
        "# This is done in-place, modifying the DataFrame\n",
        "\n",
        "fcst_result[\"LinearRegression_fcst\"]=ml_prediction[\"LinearRegression\"].values\n",
        "# Adds a new column 'LinearRegression_fcst' to fcst_result\n",
        "# Populates it with the predictions from the LinearRegression model\n",
        "\n",
        "fcst_result[\"LGBM_fcst\"]=ml_prediction[\"LGBMRegressor\"].values\n",
        "# Adds a new column 'LGBM_fcst' to fcst_result\n",
        "# Populates it with the predictions from the LGBMRegressor model\n",
        "\n",
        "fcst_result[\"XGB_fcst\"]=ml_prediction[\"XGBRegressor\"].values\n",
        "# Adds a new column 'XGB_fcst' to fcst_result\n",
        "# Populates it with the predictions from the XGBRegressor model\n",
        "\n",
        "fcst_result[\"RandomForest_fcst\"]=ml_prediction[\"RandomForestRegressor\"].values\n",
        "# Adds a new column 'RandomForest_fcst' to fcst_result\n",
        "# Populates it with the predictions from the RandomForestRegressor model\n",
        "\n",
        "fcst_result.head()\n",
        "# Displays the first five rows of the fcst_result DataFrame\n",
        "# This allows you to see a preview of the results, including the actual values and predictions from all models\n",
        "\n",
        "#Defining a function to calculate the error metrics\n",
        "def calculate_error_metrics(actual_values, predicted_values):\n",
        "    actual_values = np.array(actual_values)\n",
        "    predicted_values = np.array(predicted_values)\n",
        "\n",
        "    metrics_dict = {\n",
        "        'MAE': np.mean(np.abs(actual_values - predicted_values)),  # Mean Absolute Error\n",
        "        'RMSE': np.sqrt(np.mean((actual_values - predicted_values)**2)),  # Root Mean Square Error\n",
        "        'MAPE': np.mean(np.abs((actual_values - predicted_values) / actual_values)) * 100}  # Mean Absolute Percentage Error\n",
        "\n",
        "    result_df = pd.DataFrame(list(metrics_dict.items()), columns=['Metric', 'Value'])\n",
        "    return result_df\n",
        "\n",
        "# Extracting actual values from the result DataFrame\n",
        "actuals = fcst_result['RUPEES/US$']\n",
        "\n",
        "# Dictionary to store error metrics for each model\n",
        "error_metrics_dict = {}\n",
        "\n",
        "# Calculating error metrics for each model's predictions\n",
        "for col in fcst_result.columns[1:]:  # Iterating through prediction columns (skipping the first column which is likely the actual values)\n",
        "    predicted_values = fcst_result[col]\n",
        "    error_metrics_dict[col] = calculate_error_metrics(actuals, predicted_values)['Value'].values  # Extracting 'Value' column\n",
        "\n",
        "# Creating a DataFrame from the error metrics dictionary\n",
        "error_metrics_df = pd.DataFrame(error_metrics_dict).T.reset_index()\n",
        "error_metrics_df.columns = ['Model', 'MAE', 'RMSE', 'MAPE']  # Renaming columns for clarity\n",
        "print(error_metrics_df)"
      ],
      "metadata": {
        "id": "4ZoHXK2v5KEX"
      },
      "execution_count": 11,
      "outputs": []
    }
  ]
}