{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Streamlining Model Selection.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN5s6JnGhfHDoDuAW3D1+bw"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ppNc8rpO1B7N",
        "colab_type": "text"
      },
      "source": [
        "[Reference](https://medium.com/better-programming/streamlining-model-selection-de50c421d129)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTZYqDIN1JVz",
        "colab_type": "text"
      },
      "source": [
        "# Normal code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bMzSnfoO1FSB",
        "colab_type": "text"
      },
      "source": [
        "```python\n",
        "#Baseline logistic model\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "#splitting the data into training and testing sets\n",
        "x_train, x_test, y_train, y_test = train_test_split(features,labels,test_size=0.2)\n",
        "clf = LogisticRegression()\n",
        "model = clf.fit(x_train,y_train)\n",
        "predictions = model.predict(x_test)\n",
        "model.score(x_test,y_test)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wF69Ihqk1LRq",
        "colab_type": "text"
      },
      "source": [
        "# GridSearchCV"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-4jVyB41QEY",
        "colab_type": "text"
      },
      "source": [
        "```python\n",
        "#GridSearchCV inserted into a function that streamlines the process\n",
        "def perform_gridsearch(features,labels):\n",
        "    penalty = ['l1', 'l2']\n",
        "    C = np.logspace(0, 4, 10)\n",
        "    logistic = linear_model.LogisticRegression()\n",
        "    # Create range of candidate penalty hyperparameter values\n",
        "    penalty = ['l1', 'l2']\n",
        "    # Create range of candidate regularization hyperparameter values C\n",
        "    C = np.logspace(0, 4, 10)\n",
        "    # Create dictionary hyperparameter candidates\n",
        "    hyperparameters = dict(C=C, penalty=penalty)\n",
        "    gridsearch = GridSearchCV(logistic, hyperparameters, cv=5, verbose=1) # Fit grid search\n",
        "    best_model = gridsearch.fit(features,labels)\n",
        "    predictions = best_model.predict(features)\n",
        "    fpr, tpr, thresholds = metrics.roc_curve(labels,predictions)\n",
        "    print(predictions)\n",
        "    print(fpr,tpr,thresholds)\n",
        "    print('Best Model Parameters:', best_model.best_estimator_) \n",
        "    print('Best C:', best_model.best_estimator_.get_params()['C'])\n",
        "    print(\"The mean accuracy of the model is:\",best_model.score(features,labels))\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uecj6qYx1Zu-",
        "colab_type": "text"
      },
      "source": [
        "# RandomizedSearchCV\n",
        "It donâ€™t have any specific hyperparameter values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CL-iBbsn1lo4",
        "colab_type": "text"
      },
      "source": [
        "```python\n",
        "def perform_randomized_search(features,labels):\n",
        "    # Create logistic regression\n",
        "    logistic = linear_model.LogisticRegression()\n",
        "    # Create range of candidate regularization penalty hyperparameter values\n",
        "    penalty = ['l1', 'l2']\n",
        "    # Create distribution of candidate regularization hyperparameter values\n",
        "    C = uniform(loc=0, scale=4)\n",
        "    # Create hyperparameter options\n",
        "    hyperparameters = dict(C=C, penalty=penalty)\n",
        "    # Create randomized search\n",
        "    randomizedsearch = RandomizedSearchCV(\n",
        "    logistic, hyperparameters, random_state=1, n_iter=100, cv=5, verbose=1)\n",
        "    # Fit randomized search\n",
        "    best_model = randomizedsearch.fit(features,labels)\n",
        "    predictions=best_model.predict(features)\n",
        "    fpr, tpr, thresholds = metrics.roc_curve(labels,predictions)\n",
        "    print(fpr, tpr, thresholds)\n",
        "    print('Best Penalty:', best_model.best_estimator_) \n",
        "    print('Best C:', best_model.best_estimator_.get_params()['C'])\n",
        "    print(\"The mean accuracy of the model is:\",best_model.score(features,labels))\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "npxBySCT1tze",
        "colab_type": "text"
      },
      "source": [
        "# Pipelining and Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QcGqy_y61yFC",
        "colab_type": "text"
      },
      "source": [
        "```python\n",
        "def execute_pipeline(features,labels):\n",
        "    #Preprocessing\n",
        "    pca_components = PCA() ## if n_components not specified, keeps all components\n",
        "    std_scaler = StandardScaler()\n",
        "    preprocess = FeatureUnion([(\"std\",std_scaler), (\"pca\", pca_components)])\n",
        "    # Create a pipeline\n",
        "    pipe = Pipeline([(\"classifier\", LogisticRegression())])\n",
        "    # Create dictionary with candidate learning algorithms and their hyperparameters\n",
        "    search_space = [\n",
        "                {\"classifier\": [LogisticRegression()],\n",
        "                 \"classifier__penalty\": ['l2','l1'],\n",
        "                 \"classifier__C\": np.logspace(0, 4, 10)\n",
        "                 },\n",
        "                {\"classifier\": [LogisticRegression()],\n",
        "                 \"classifier__penalty\": ['l2'],\n",
        "                 \"classifier__C\": np.logspace(0, 4, 10),\n",
        "                 \"classifier__solver\":['newton-cg','saga','sag','liblinear'] ##This solvers don't allow L1 penalty\n",
        "                 },\n",
        "                {\"classifier\": [RandomForestClassifier()],\n",
        "                 \"classifier__n_estimators\": [10, 100,200],\n",
        "                 \"classifier__max_depth\":[5,8,15,None],\n",
        "                 \"classifier__min_samples_leaf\":[1,2,5,10,15],\n",
        "                 \"classifier__max_leaf_nodes\": [2, 5,10]\n",
        "                 },\n",
        "                 {\"classifier\": [SVC()],\n",
        "                 \"classifier__C\": [0.01,0.1,1,10,100],\n",
        "                 \"classifier__kernel\":['linear','rbf','sigmoid']\n",
        "                }]\n",
        "                 \n",
        "    gridsearch = GridSearchCV(pipe, search_space, cv=5, verbose=1,n_jobs=-1) # Fit grid search\n",
        "    best_model = gridsearch.fit(features,labels)\n",
        "    predictions = best_model.predict(features)\n",
        "    fpr_pipe, tpr_pipe, thresholds_pipe = metrics.roc_curve(labels,predictions)\n",
        "    print(fpr_pipe, tpr_pipe, thresholds_pipe)\n",
        "    print(best_model.best_estimator_)\n",
        "    print(\"The mean accuracy of the model is:\",best_model.score(features,labels))\n",
        "'''\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qAUi0QU62FDp",
        "colab_type": "text"
      },
      "source": [
        "![image](https://miro.medium.com/max/1360/1*_PwxmaOj_dyBI8pRNYQdVA.jpeg)"
      ]
    }
  ]
}