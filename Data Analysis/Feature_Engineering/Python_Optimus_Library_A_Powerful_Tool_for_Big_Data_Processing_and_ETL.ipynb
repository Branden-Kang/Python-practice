{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMeXLamx6Vh0CvbEEdqBxBs"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[Reference](https://medium.com/@tubelwj/python-optimus-library-a-powerful-tool-for-big-data-processing-and-etl-06d2d6f5b26a)"
      ],
      "metadata": {
        "id": "7jBPNxyyBy9j"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "rDAUxs1lBjEi"
      },
      "outputs": [],
      "source": [
        "pip install optimuspyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from optimus import Optimus\n",
        "\n",
        "# Create Optimus object\n",
        "op = Optimus()"
      ],
      "metadata": {
        "id": "MnnlW3ISBqcC"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from optimus import Optimus\n",
        "\n",
        "# Create Optimus object with specific Spark configuration\n",
        "op = Optimus(master=\"local\", app_name=\"optimus_test\")"
      ],
      "metadata": {
        "id": "xMv3u7qDBrUM"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from optimus import Optimus\n",
        "\n",
        "# Create Optimus object\n",
        "op = Optimus()\n",
        "\n",
        "# Load CSV file\n",
        "df = op.load.csv('business.csv')\n",
        "df.show()"
      ],
      "metadata": {
        "id": "hIuswE-1B9a4"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from optimus import Optimus\n",
        "\n",
        "# Create an Optimus object\n",
        "op = Optimus()\n",
        "\n",
        "# Load dataset\n",
        "df = op.load.csv('business.csv')\n",
        "\n",
        "# View basic information of the dataset\n",
        "df.printSchema()\n",
        "\n",
        "# Filter data\n",
        "filtered_df = df.filter(df[\"total_amount\"] > 2000.0)\n",
        "\n",
        "# Select specific columns\n",
        "selected_df = df.select(\"order_id\", \"total_amount\")\n",
        "\n",
        "# Create a new column\n",
        "df = df.withColumn(\"profit_double\", df[\"profit\"] * 2)\n",
        "df.show()"
      ],
      "metadata": {
        "id": "OuskINmvCA3Z"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from optimus import Optimus\n",
        "\n",
        "# Create an Optimus object\n",
        "op = Optimus()\n",
        "\n",
        "# Load dataset\n",
        "df = op.load.csv('business.csv')\n",
        "\n",
        "# Calculate the average value for each group\n",
        "grouped_df = df.groupBy(\"group\").agg({\"total_amount\": \"mean\"})\n",
        "grouped_df.show()"
      ],
      "metadata": {
        "id": "oGGp6F4RCCIt"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Generate data summary report\n",
        "summary = df.profiler.run()\n",
        "print(summary)"
      ],
      "metadata": {
        "id": "LyahzcpjCDt8"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# One-hot encoding\n",
        "df = df.cols.one_hot_encode(\"column2\")\n",
        "\n",
        "# Feature selection\n",
        "df = df.cols.select([\"column1\", \"column3\"])"
      ],
      "metadata": {
        "id": "ivHNiZ34CE6P"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a data pipeline\n",
        "pipeline = op.Pipeline()\n",
        "\n",
        "# Add operations to the pipeline\n",
        "pipeline.add(\"drop_missing\", [\"column1\"])\n",
        "pipeline.add(\"fill_na\", \"column2\", value=\"Unknown\")\n",
        "pipeline.add(\"outliers_replace\", [\"column3\"], method=\"median\")\n",
        "\n",
        "# Execute pipeline operations\n",
        "df = pipeline.run(df)"
      ],
      "metadata": {
        "id": "QdaGnImbCHME"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from optimus import Optimus\n",
        "\n",
        "# Create an Optimus object\n",
        "op = Optimus()\n",
        "\n",
        "# Load dataset\n",
        "df = op.load.csv('business.csv')\n",
        "\n",
        "# Remove duplicates\n",
        "df = df.dropDuplicates()\n",
        "\n",
        "# Handle missing values\n",
        "df = df.fillna({\"total_amount\": 0})\n",
        "\n",
        "# Detect outliers\n",
        "df = df.outliers(columns=[\"total_amount\"], method=\"z_score\", threshold=3)\n",
        "df.show()"
      ],
      "metadata": {
        "id": "G04as_F4CId6"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from optimus import Optimus\n",
        "\n",
        "# Create an Optimus object\n",
        "op = Optimus()\n",
        "\n",
        "# Load dataset\n",
        "df = op.load.csv('business.csv')\n",
        "\n",
        "# Convert data types\n",
        "df = df.astype({\"PCs\": \"int\", \"total_amount\": \"float\"})\n",
        "df.printSchema()"
      ],
      "metadata": {
        "id": "z8Ml410wCKKf"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from optimus import Optimus\n",
        "\n",
        "# Create an Optimus object\n",
        "op = Optimus()\n",
        "\n",
        "# Load dataset\n",
        "df = op.load.csv('business.csv')\n",
        "\n",
        "# Plot a histogram\n",
        "df.plot.hist(\"total_amount\", bins=10)"
      ],
      "metadata": {
        "id": "J4vbt5BlCLrG"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from optimus import Optimus\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Create an Optimus object\n",
        "op = Optimus()\n",
        "\n",
        "# Load dataset\n",
        "df = op.load.csv('business.csv')\n",
        "\n",
        "# Prepare data\n",
        "X = df.select(\"PCs\", \"total_amount\").toPandas().values\n",
        "y = df.select(\"target\").toPandas().values.ravel()\n",
        "\n",
        "# Train model\n",
        "model = LinearRegression()\n",
        "model.fit(X, y)\n",
        "\n",
        "# Prediction\n",
        "predictions = model.predict(X)\n",
        "print(predictions)"
      ],
      "metadata": {
        "id": "zs_uuXOgCNqr"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from optimus import Optimus\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "# Create an Optimus object\n",
        "op = Optimus()\n",
        "\n",
        "# Simulate real-time data stream\n",
        "data = [{\"time\": i, \"value\": i * 4+ (i % 6)} for i in range(3000)]\n",
        "\n",
        "# Convert to an Optimus DataFrame\n",
        "df = op.create.df(data)\n",
        "\n",
        "# Compute rolling average in real-time\n",
        "df = df.withColumn(\"rolling_mean\", df[\"value\"].rolling(15).mean())\n",
        "df.show()"
      ],
      "metadata": {
        "id": "5C4PNTupCP2U"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from optimus import Optimus\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "# Create an Optimus object\n",
        "op = Optimus()\n",
        "\n",
        "# Load geospatial dataset\n",
        "df = op.load.csv('geospatial_location_data.csv')\n",
        "\n",
        "# Convert geospatial data to float\n",
        "df = df.withColumn(\"longitude\", col(\"longitude\").cast(\"float\"))\n",
        "df = df.withColumn(\"latitude\", col(\"latitude\").cast(\"float\"))\n",
        "\n",
        "# Compute the average values for each region\n",
        "agg_df = df.groupBy(\"region\").agg({\"latitude\": \"mean\", \"longitude\": \"mean\"})\n",
        "agg_df.show()"
      ],
      "metadata": {
        "id": "MZ0eQ_7DCRlT"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from optimus import Optimus\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "# Create an Optimus object\n",
        "op = Optimus()\n",
        "\n",
        "# Load financial dataset\n",
        "df = op.load.csv('financial_data.csv')\n",
        "\n",
        "# Calculate stock returns\n",
        "df = df.withColumn(\"return\", (col(\"close\") / col(\"close\").shift(1)) - 1)\n",
        "\n",
        "# Aggregate to calculate monthly returns\n",
        "monthly_returns = df.groupBy(df[\"date\"].dt.to_period(\"M\")).agg({\"return\": \"sum\"})\n",
        "monthly_returns.show()"
      ],
      "metadata": {
        "id": "kNloKIRnCS9B"
      },
      "execution_count": 16,
      "outputs": []
    }
  ]
}
