{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "What data scientists keep missing about imbalanced datasets.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOIvqXPHxYdtHWqvq8I00Pw"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[Reference](https://medium.com/mlearning-ai/what-data-scientists-keep-missing-about-imbalanced-datasets-d1f10e808297)"
      ],
      "metadata": {
        "id": "eeNzt5KPIwMm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Random oversampling"
      ],
      "metadata": {
        "id": "q8AWCd3sI-K-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WoDkraXTItyF"
      },
      "outputs": [],
      "source": [
        "# Create function and apply for random oversampling - binary\n",
        "def overSamplingBinary(X, y, targetBalance = 0.5):\n",
        "    # define majority/minority classes based on the inputted\n",
        "    # target column (y)\n",
        "    yMajority = y.value_counts().idxmax()\n",
        "    yMinority = y.value_counts().idxmin()\n",
        "    # We next create separate majority and minority dataframes which are converted\n",
        "    # to lists\n",
        "    X['target'] = y\n",
        "    majority = X[X['target'] == yMajority].values.tolist()\n",
        "    minority = X[X['target'] == yMinority].values.tolist()\n",
        "    # Next we implement a while loop to keep randomly selecting rows\n",
        "    # from the minority data until the target balance between minority\n",
        "    # and majority is achieved\n",
        "    enlargedMinority = []\n",
        "    while len(enlargedMinority)/(len(majority) + len(enlargedMinority)) < targetBalance:\n",
        "        randomValue = random.choice(minority)\n",
        "        enlargedMinority.append(randomValue)\n",
        "    # Take the original column names\n",
        "    columnNames = list(X.columns)\n",
        "    # Create a new dataset by comining target and features\n",
        "    newDataset = enlargedMinority + majority\n",
        "    # combine this back as a df with original column names\n",
        "    # for features\n",
        "    newDataset = pd.DataFrame(newDataset, columns = columnNames)\n",
        "    return newDataset"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Random undersampling"
      ],
      "metadata": {
        "id": "oefSu7EII8sN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create function for random undersampling - binary\n",
        "def underSamplingBinary(X, y, targetBalance = 0.5):\n",
        "    # define majority/minority classes\n",
        "    yMajority = y.value_counts().idxmax()\n",
        "    yMinority = y.value_counts().idxmin()\n",
        "    # Create separate majority and minority lists\n",
        "    X['target'] = y\n",
        "    majority = X[X['target'] == yMajority].values.tolist()\n",
        "    minority = X[X['target'] == yMinority].values.tolist()\n",
        "    # While the length of the majority is larger than the targeted balance\n",
        "    # we randomly remove one instance from the majority dataset\n",
        "    while len(majority)/(len(minority) + len(majority)) > targetBalance:\n",
        "        majority.pop(random.randrange(len(majority)))\n",
        "    # Take the original column names\n",
        "    columnNames = list(X.columns)\n",
        "    newDataset = minority + majority\n",
        "    newDataset = pd.DataFrame(newDataset, columns = columnNames)\n",
        "    return newDataset"
      ],
      "metadata": {
        "id": "h29fhNFfIzz0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SMOTE"
      ],
      "metadata": {
        "id": "ULqC9SNPI6zu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Implement imblearn\n",
        "from imblearn.over_sampling import SMOTE\n",
        "smote = SMOTE(sampling_strategy=1)\n",
        "X_sm, y_sm = smote.fit_resample(featuresTrain, targetTrain)"
      ],
      "metadata": {
        "id": "dUl9tSaOI2KX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
