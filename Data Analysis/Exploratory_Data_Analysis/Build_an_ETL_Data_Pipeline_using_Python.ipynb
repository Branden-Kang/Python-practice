{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMTIpIShWBKIFv4LU+jz1LU"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[Reference](https://medium.com/@topefolorunso/build-an-etl-data-pipeline-using-python-139c6875b046)"
      ],
      "metadata": {
        "id": "pWnEn-rrflrW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AR7Ld9hjbbYU",
        "outputId": "55a4d747-9d09-480f-ffb9-8adf8f0ee34a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into '/root/basic-etl-pipeline'...\n",
            "remote: Enumerating objects: 16, done.\u001b[K\n",
            "remote: Counting objects: 100% (16/16), done.\u001b[K\n",
            "remote: Compressing objects: 100% (12/12), done.\u001b[K\n",
            "remote: Total 16 (delta 2), reused 12 (delta 1), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (16/16), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone --single-branch --branch main https://github.com/topefolorunso/basic-etl-pipeline.git ~/basic-etl-pipeline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd ~/basic-etl-pipeline"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVSdR4FRfoz5",
        "outputId": "88d5573d-600d-42b9-d8b8-34a0f078b4a6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/root/basic-etl-pipeline\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from pandas.core.frame import DataFrame\n",
        "\n",
        "def extract(file_path: str) -> DataFrame:\n",
        "    '''\n",
        "    extracts csv data and converts to pandas Dataframe\n",
        "    args:\n",
        "        file_path (str): path to the csv file\n",
        "    \n",
        "    returns:\n",
        "        df (DataFrame): pandas dataframe containing the csv data\n",
        "    '''\n",
        "\n",
        "    # exracts the csv data as pandas daaframe\n",
        "    df = pd.read_csv(file_path)\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "mzCHyAXtfr9V"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transform(df: DataFrame) -> DataFrame:\n",
        "    '''\n",
        "    cleans data\n",
        "    args:\n",
        "        df (DataFrame): pandas dataframe containing the raw data\n",
        "    \n",
        "    returns:\n",
        "        df (DataFrame): pandas dataframe containing the clean data\n",
        "    '''\n",
        "\n",
        "    # drop null values\n",
        "    df.dropna(inplace=True)\n",
        "\n",
        "    # remove decimal from year column and convert to string\n",
        "    df.Year = df.Year.astype('int').astype(\"str\")\n",
        "    \n",
        "    return df"
      ],
      "metadata": {
        "id": "YMV5HazyfuEK"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load(df: DataFrame, save_path: str):\n",
        "    '''\n",
        "    writes pandas Dataframe to csv file\n",
        "    args:\n",
        "        df (DataFrame): pandas dataframe containing the clean data\n",
        "        save_path (str): path to save the csv file\n",
        "    \n",
        "    returns:\n",
        "        None\n",
        "    '''\n",
        "\n",
        "    # write dataframe to csv\n",
        "    df.to_csv(save_path, index=False)\n",
        "    return"
      ],
      "metadata": {
        "id": "jzVR_cPafvdY"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from etl import *\n",
        "\n",
        "file_path = \"~/basic-etl-pipeline/data/economic-indicators.csv\"\n",
        "save_path = \"~/basic-etl-pipeline/data/clean_economic-indicators.csv\"\n",
        "\n",
        "def run_pipeline(file_path:str, save_path:str):\n",
        "\n",
        "    # extract\n",
        "    df = extract(file_path=file_path)\n",
        "\n",
        "    # transform\n",
        "    df = transform(df=df)\n",
        "\n",
        "    # load\n",
        "    load(df=df, save_path=save_path)\n",
        "\n",
        "    return\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # run pipeline\n",
        "    run_pipeline(file_path=file_path, save_path=save_path)"
      ],
      "metadata": {
        "id": "sdvurWxvfwqj"
      },
      "execution_count": 6,
      "outputs": []
    }
  ]
}
