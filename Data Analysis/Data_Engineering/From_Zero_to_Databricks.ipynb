{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMegjkBxLDwWnNc9yLo0uQR"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[Reference](https://medium.com/@sauravkumarrajjoli/from-zero-to-databricks-the-beginner-friendly-guide-i-wish-i-had-cd78ecda683d)"
      ],
      "metadata": {
        "id": "hFocHlI0ieSq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Apache Spark: The Engine Running Under the Hood"
      ],
      "metadata": {
        "id": "xyihiMWyihTb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "LEjk0XfkgP2q"
      },
      "outputs": [],
      "source": [
        "df = spark.read.csv(\"/mnt/bronze/customers.csv\", header=True)\n",
        "df.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Connecting to Storage: How Databricks Reads Your Data"
      ],
      "metadata": {
        "id": "2DZKrIObimyp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dbutils.fs.mount(\n",
        "  source=\"abfss://bronze@account.dfs.core.windows.net/\",\n",
        "  mount_point=\"/mnt/bronze\",\n",
        "  extra_configs=configs\n",
        ")"
      ],
      "metadata": {
        "id": "RPbimcl_ijkT"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.read.csv(\"/mnt/bronze/orders.csv\", header=True)"
      ],
      "metadata": {
        "id": "VjMs-HUqioti"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The Spark DataFrame: Your Daily Workhorse"
      ],
      "metadata": {
        "id": "c8zpaEb7irnY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = [(1, \"Alice\"), (2, \"Bob\")]\n",
        "df = spark.createDataFrame(data, [\"id\", \"name\"])\n",
        "display(df)"
      ],
      "metadata": {
        "id": "EW_7kA5NiqXA"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col, expr, current_date\n",
        "\n",
        "df2 = (df\n",
        "      .withColumn(\"id_squared\", col(\"id\") * col(\"id\"))\n",
        "      .withColumn(\"load_date\", current_date()))"
      ],
      "metadata": {
        "id": "x1sbiCCSitWs"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reading and Writing Data: Your First Real Task"
      ],
      "metadata": {
        "id": "4gAaowqBi0Lc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.read \\\n",
        "          .option(\"header\", True) \\\n",
        "          .csv(\"/mnt/bronze/customers.csv\")"
      ],
      "metadata": {
        "id": "uz0X-RxmiyoX"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.write \\\n",
        "  .mode(\"overwrite\") \\\n",
        "  .format(\"parquet\") \\\n",
        "  .save(\"/mnt/silver/customers_cleaned/\")"
      ],
      "metadata": {
        "id": "j3s2kw28i1fj"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.write.saveAsTable(\"sales.customers_cleaned\")"
      ],
      "metadata": {
        "id": "rd-cKk2Gi3Ek"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Delta Lake: The Secret Power Behind Databricks"
      ],
      "metadata": {
        "id": "KfrXLm0Ai7jf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.write \\\n",
        "  .format(\"delta\") \\\n",
        "  .mode(\"overwrite\") \\\n",
        "  .saveAsTable(\"demo_db.customers\")"
      ],
      "metadata": {
        "id": "jXXPR1g9i40l"
      },
      "execution_count": 9,
      "outputs": []
    }
  ]
}
