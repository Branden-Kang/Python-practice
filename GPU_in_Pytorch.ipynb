{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GPU in Pytorch.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO9X0kCpTjhqCaqMd7qcpsR"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QgekShHLgJ9O",
        "colab_type": "text"
      },
      "source": [
        "[Reference](https://towardsdatascience.com/speed-up-your-algorithms-part-1-pytorch-56d8a4ae7051)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eeJU4kVOeKeG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0d13a979-ce0b-416a-d42a-97206dd9bd60"
      },
      "source": [
        "import torch\n",
        "torch.cuda.is_available()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QdGe2DeHeYFb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 482
        },
        "outputId": "85c8f9f7-550c-4d68-b907-ef1b29585e28"
      },
      "source": [
        "import torch\n",
        "!pip install pycuda\n",
        "import pycuda.driver as cuda\n",
        "cuda.init()\n",
        "## Get Id of default device\n",
        "torch.cuda.current_device()\n",
        "# 0\n",
        "cuda.Device(0).name() # '0' is the id of your GPU\n",
        "# Tesla K80"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pycuda\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/3f/5658c38579b41866ba21ee1b5020b8225cec86fe717e4b1c5c972de0a33c/pycuda-2019.1.2.tar.gz (1.6MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6MB 2.7MB/s \n",
            "\u001b[?25hCollecting pytools>=2011.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/73/d5/989a1d2bba90f5c085e4929a4b703bbd8cc6b4a4218f1671fadab2abe966/pytools-2020.4.tar.gz (67kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 6.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: decorator>=3.2.0 in /usr/local/lib/python3.6/dist-packages (from pycuda) (4.4.2)\n",
            "Collecting appdirs>=1.4.0\n",
            "  Downloading https://files.pythonhosted.org/packages/3b/00/2344469e2084fb287c2e0b57b72910309874c3245463acd6cf5e3db69324/appdirs-1.4.4-py2.py3-none-any.whl\n",
            "Collecting mako\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/37/0e706200d22172eb8fa17d68a7ae22dec7631a0a92266634fb518a88a5b2/Mako-1.1.3-py2.py3-none-any.whl (75kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 6.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.8.0 in /usr/local/lib/python3.6/dist-packages (from pytools>=2011.2->pycuda) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from pytools>=2011.2->pycuda) (1.18.5)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.6/dist-packages (from mako->pycuda) (1.1.1)\n",
            "Building wheels for collected packages: pycuda, pytools\n",
            "  Building wheel for pycuda (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycuda: filename=pycuda-2019.1.2-cp36-cp36m-linux_x86_64.whl size=4537347 sha256=5c620d0c0c9201f52c22b395c19c8ebcfa0b4b5e0446caac8d34712f4a7e36f1\n",
            "  Stored in directory: /root/.cache/pip/wheels/a6/60/f0/b1c430c73d281ac3e46070480db50f7907364eb6f6d3188396\n",
            "  Building wheel for pytools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytools: filename=pytools-2020.4-py2.py3-none-any.whl size=67175 sha256=75ca53b550d6551a0f0af6a99605b976e91841b034454dead2904f349b3070d8\n",
            "  Stored in directory: /root/.cache/pip/wheels/5e/20/0b/fac51840734b2587ecc239a62522b164c374e929e2c9be66c5\n",
            "Successfully built pycuda pytools\n",
            "Installing collected packages: appdirs, pytools, mako, pycuda\n",
            "Successfully installed appdirs-1.4.4 mako-1.1.3 pycuda-2019.1.2 pytools-2020.4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Tesla K80'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWfuwJhledta",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "794d7361-21b0-40a3-bc05-432c493cab0f"
      },
      "source": [
        "# A simple class to know about your cuda devices\n",
        "import pycuda.driver as cuda\n",
        "import pycuda.autoinit # Necessary for using its functions\n",
        "cuda.init() # Necesarry for using its functions\n",
        "\n",
        "class aboutCudaDevices():\n",
        "    def __init__(self):\n",
        "        pass\n",
        "    \n",
        "    def num_devices(self):\n",
        "        \"\"\"Return number of devices connected.\"\"\"\n",
        "        return cuda.Device.count()\n",
        "    \n",
        "    def devices(self):\n",
        "        \"\"\"Get info on all devices connected.\"\"\"\n",
        "        num = cuda.Device.count()\n",
        "        print(\"%d device(s) found:\"%num)\n",
        "        for i in range(num):\n",
        "            print(cuda.Device(i).name(), \"(Id: %d)\"%i)\n",
        "            \n",
        "    def mem_info(self):\n",
        "        \"\"\"Get available and total memory of all devices.\"\"\"\n",
        "        available, total = cuda.mem_get_info()\n",
        "        print(\"Available: %.2f GB\\nTotal:     %.2f GB\"%(available/1e9, total/1e9))\n",
        "        \n",
        "    def attributes(self, device_id=0):\n",
        "        \"\"\"Get attributes of device with device Id = device_id\"\"\"\n",
        "        return cuda.Device(device_id).get_attributes()\n",
        "    \n",
        "    def __repr__(self):\n",
        "        \"\"\"Class representation as number of devices connected and about them.\"\"\"\n",
        "        num = cuda.Device.count()\n",
        "        string = \"\"\n",
        "        string += (\"%d device(s) found:\\n\"%num)\n",
        "        for i in range(num):\n",
        "            string += ( \"    %d) %s (Id: %d)\\n\"%((i+1),cuda.Device(i).name(),i))\n",
        "            string += (\"          Memory: %.2f GB\\n\"%(cuda.Device(i).total_memory()/1e9))\n",
        "        return string\n",
        "\n",
        "# You can print output just by typing its name (__repr__):\n",
        "aboutCudaDevices()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1 device(s) found:\n",
              "    1) Tesla K80 (Id: 0)\n",
              "          Memory: 12.00 GB"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FO0LAJgqe0PO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "8d0574d9-5c40-45db-8614-2a21e9d83c1f"
      },
      "source": [
        "import torch\n",
        "# Returns the current GPU memory usage by \n",
        "# tensors in bytes for a given device\n",
        "torch.cuda.memory_allocated()\n",
        "# Returns the current GPU memory managed by the\n",
        "# caching allocator in bytes for a given device\n",
        "torch.cuda.memory_cached()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/cuda/memory.py:346: FutureWarning: torch.cuda.memory_cached has been renamed to torch.cuda.memory_reserved\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yshA2Nqe2ii",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Releases all unoccupied cached memory currently held by\n",
        "# the caching allocator so that those can be used in other\n",
        "# GPU application and visible in nvidia-smi\n",
        "torch.cuda.empty_cache()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebMi6I8ke4s7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = torch.FloatTensor([1., 2.]).cuda()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bob7sNKNe93h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "sq = nn.Sequential(\n",
        "         nn.Linear(20, 20),\n",
        "         nn.ReLU(),\n",
        "         nn.Linear(20, 4),\n",
        "         nn.Softmax()\n",
        ")"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7faRbuifCKj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = sq.cuda()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xxjRmJGfCUn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a92419f6-fe36-474c-dab7-b1413c8639ef"
      },
      "source": [
        "# From the discussions here: discuss.pytorch.org/t/how-to-check-if-model-is-on-cuda\n",
        "next(model.parameters()).is_cuda"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWU_AD1tfFWS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cuda0 = torch.device('cuda:0')\n",
        "cuda1 = torch.device('cuda:1')\n",
        "cuda2 = torch.device('cuda:2')"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xf-tju1DfSzv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = torch.Tensor([1., 2.]).cuda(cuda0)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4GHorquTfjfi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = torch.Tensor([1., 2.]).to(cuda0)\n",
        "y = torch.Tensor([3., 4.]).to(cuda0)\n",
        "# This Tensor will be saved on 'cuda2' only\n",
        "z = x + y"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZh0o3lLfmUz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "441c9fd2-d3ee-48ed-f0ca-88442558b5c9"
      },
      "source": [
        "z"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([4., 6.], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mVaNERGfoc1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cuda = torch.device('cuda')\n",
        "s = torch.cuda.Stream()  # Create a new stream.\n",
        "A = torch.empty((100, 100), device=cuda).normal_(0.0, 1.0)\n",
        "with torch.cuda.stream(s):\n",
        "    # because sum() may start execution before normal_() finishes!\n",
        "    B = torch.sum(A)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2-lmXy3f6uR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ffc3afa8-e449-4cec-d9ed-69eaaafbfc55"
      },
      "source": [
        "model_cpu = nn.Sequential(\n",
        "         nn.Linear(20, 20),\n",
        "         nn.ReLU(),\n",
        "         nn.Linear(20, 4),\n",
        "         nn.Softmax()\n",
        ").float()\n",
        "model_gpu = model.float()\n",
        "next(model_cpu.parameters()).is_cuda, next(model_gpu.parameters()).is_cuda"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(False, True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PsfoMtiEmMlp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cpu_inp = torch.ones((100000, 20), dtype=torch.float32)\n",
        "gpu_inp = torch.ones((100000, 20), dtype=torch.float32).cuda()"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ark2lhYDmPHH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "5292e11a-21af-4d22-aefb-ef14889bb212"
      },
      "source": [
        "%timeit res = model_cpu(cpu_inp)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py:117: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10 loops, best of 3: 24.1 ms per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zPryCtMmQsZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "541d6e47-8daf-4edd-af77-7919b0481441"
      },
      "source": [
        "%%timeit \n",
        "for i in range(10): # Because we don't have enough memory on GPU\n",
        "  res = model_gpu(gpu_inp[i*1000:i*1000+1000])"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py:117: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The slowest run took 7.41 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
            "100 loops, best of 3: 2.28 ms per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6ApCFnYmSRF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 325
        },
        "outputId": "bf055258-f5dc-412c-db28-03cab04535ea"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, ax = plt.subplots(1, 1)\n",
        "ax.plot([\"a\", \"b\"], [28, 3.61], \"-o\")\n",
        "ax.set_xticklabels([\"CPU Model\", \"GPU Model\"])\n",
        "fig.suptitle(\"CPU vs GPU\", fontsize=17)\n",
        "ax.set_ylabel(\"Time (ms)\")\n",
        "ax.set_xlabel(\"Model Type\")"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Model Type')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIFZ-X5bmTk7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "module =  nn.Sequential(\n",
        "         nn.Linear(20, 20),\n",
        "         nn.ReLU(),\n",
        "         nn.Linear(20, 4),\n",
        "         nn.Softmax()\n",
        ").cuda()\n",
        "\n",
        "inp = torch.ones((30, 20)).cuda()"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWOD7ZsZmaHg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "0477f298-8724-475e-dde4-2d4b0b1504fd"
      },
      "source": [
        "# Replicate module to devices in device_ids\n",
        "replicas = nn.parallel.replicate(module, [0])\n",
        "\n",
        "# Distribute input to devices in device_ids\n",
        "inputs = nn.parallel.scatter(inp, [0])\n",
        "\n",
        "# Apply the models to corresponding inputs\n",
        "outputs = nn.parallel.parallel_apply(replicas, inputs)\n",
        "\n",
        "# Gather result from all devices to output_device\n",
        "result = nn.parallel.gather(outputs, 0)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py:117: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJ8n9tgymeN_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6a86e76a-f019-46e8-bf26-075001f87c6f"
      },
      "source": [
        "result.shape # Output from module"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([30, 4])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WDObjHYfmflM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "5e89aedd-d2d6-49e6-d217-6792426cf998"
      },
      "source": [
        "# Or we could have done:\n",
        "model = nn.DataParallel(model, device_ids=[0])\n",
        "result = model(inp)\n",
        "result.shape"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py:117: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([30, 4])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    }
  ]
}