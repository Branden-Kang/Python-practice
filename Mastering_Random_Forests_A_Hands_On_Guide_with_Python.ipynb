{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOGJD9y1JAWZs9gUmjx21m8"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[Reference](https://python.plainenglish.io/mastering-random-forests-a-hands-on-guide-with-python-7f92a22a535c)"
      ],
      "metadata": {
        "id": "mCVgYZYxW2Xu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Node:\n",
        "    def __init__(self, feature=None, threshold=None, left=None, right=None, value=None):\n",
        "        self.feature=feature\n",
        "        self.threshold=threshold\n",
        "        self.left=left\n",
        "        self.right=right\n",
        "        self.value=value\n",
        "\n",
        "    # If the node has a value it is a leaf node\n",
        "    def is_leaf(self):\n",
        "        return self.value is not None"
      ],
      "metadata": {
        "id": "YyaRiGCqg651"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "QtziRzYNWrzA"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "class DecisionTree:\n",
        "    def __init__(self, min_samples=2, max_depth=2):\n",
        "        self.min_samples = min_samples\n",
        "        self.max_depth = max_depth\n",
        "\n",
        "    # Helper function to calculate the entropy of a partition\n",
        "    def entropy(self, y):\n",
        "        entropy = 0\n",
        "\n",
        "        # get the unique target values\n",
        "        labels = np.unique(y)\n",
        "\n",
        "        for label in labels:\n",
        "            # get all the elements with the current value label\n",
        "            label_elements = y[y==label]\n",
        "\n",
        "            # calculate the label probability\n",
        "            pl = len(label_elements)/len(y)\n",
        "\n",
        "            # then calculate the entropy\n",
        "            entropy += -pl*np.log2(pl)\n",
        "\n",
        "        return entropy\n",
        "\n",
        "    # splits the data into left and right nodes\n",
        "    def split_data(self, dataset, feature, threshold):\n",
        "\n",
        "        # Initialize empty lists to store split data\n",
        "        left_data = []\n",
        "        right_data = []\n",
        "\n",
        "        for idx, row in enumerate(dataset):\n",
        "            if row[feature] <= threshold:\n",
        "                left_data.append(idx)\n",
        "            else:\n",
        "                right_data.append(idx)\n",
        "\n",
        "        # turn left and right data into arrays\n",
        "        left_idx = np.array(left_data)\n",
        "        right_idx = np.array(right_data)\n",
        "\n",
        "        # return the indexes of left and right nodes\n",
        "        return left_idx, right_idx\n",
        "\n",
        "    # Helper function to calculate the information gain of a split\n",
        "    def information_gain(self, target, left, right):\n",
        "        parent_entropy = self.entropy(target)\n",
        "\n",
        "        left_entropy, right_entropy = self.entropy(target[left]), self.entropy(target[right])\n",
        "\n",
        "        # calculate the heights of each node\n",
        "        left_weight = len(left)/len(target)\n",
        "        right_weight = len(right)/len(target)\n",
        "\n",
        "        # calculate the information gain\n",
        "        info_gain = parent_entropy - (left_weight*left_entropy + right_weight*right_entropy)\n",
        "        return info_gain\n",
        "\n",
        "    # method that returns the feature and threshold values that split the data with the larger information gain\n",
        "    def best_split(self, dataset, target, num_features):\n",
        "        best_gain = -1\n",
        "\n",
        "        for feat_idx in range(num_features):\n",
        "\n",
        "            # get the column of the current feature\n",
        "            data_column = dataset[:,feat_idx]\n",
        "\n",
        "            # get a list of each unique value of the column to use as a threshold\n",
        "            threshold = np.unique(data_column)\n",
        "\n",
        "            # perform a split and calculate the information gain for each threshold value\n",
        "            for thr in threshold:\n",
        "                left, right = self.split_data(dataset, feat_idx, thr)\n",
        "\n",
        "                # make sure that each split have samples\n",
        "                if len(left) and len(right):\n",
        "                    gain = self.information_gain(target, left, right)\n",
        "\n",
        "                    if gain > best_gain:\n",
        "                        best_gain = gain\n",
        "                        split_idx = feat_idx\n",
        "                        split_threshold = thr\n",
        "\n",
        "        return split_idx, split_threshold, gain\n",
        "\n",
        "    # Set the value of a leaf node based on the most common class label present\n",
        "    def leaf_value(self, y):\n",
        "        y = list(y)\n",
        "\n",
        "        most_common = max(y, key=y.count)\n",
        "\n",
        "        return most_common\n",
        "\n",
        "    # function to split the data until stop conditions are achieved\n",
        "    # Stopping rules:\n",
        "    # Minimum number of samples in a node\n",
        "    # When the number of labels in a node equals 1 (100% purity)\n",
        "    # Maximum depth of the tree\n",
        "    def grow_tree(self, X, y, depth=0):\n",
        "        n_samples, n_features = X.shape\n",
        "        n_labels = len(np.unique(y))\n",
        "\n",
        "        # check stopping criteria\n",
        "        if (n_samples < self.min_samples or n_labels == 1 or depth >= self.max_depth):\n",
        "            node_value = self.leaf_value(y)\n",
        "            return Node(value=node_value)\n",
        "\n",
        "        # use the best split\n",
        "        best_idx, best_thresh, best_gain = self.best_split(X, y, n_features)\n",
        "\n",
        "        # creating the nodes\n",
        "        if best_gain:\n",
        "            left_idx, right_idx = self.split_data(X, best_idx, best_thresh)\n",
        "            left_node = self.grow_tree(X[left_idx, :], y[left_idx], depth=depth+1)\n",
        "            right_node = self.grow_tree(X[right_idx, :], y[right_idx], depth=depth+1)\n",
        "            return Node(best_idx, best_thresh, left_node, right_node)\n",
        "\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.root = self.grow_tree(X,y)\n",
        "\n",
        "    def predict_value(self, x, node):\n",
        "        # recursively traverse the tree to find the value for a sample x\n",
        "        if node.is_leaf():\n",
        "            return node.value\n",
        "\n",
        "        feat = node.feature\n",
        "        if x[feat] <= node.threshold:\n",
        "            return self.predict_value(x, node.left)\n",
        "        return self.predict_value(x, node.right)\n",
        "\n",
        "    # predict the leaf's values for each sample on X\n",
        "    def predict(self, X):\n",
        "        pred_values = [self.predict_value(x, self.root) for x in X]\n",
        "        return np.array(pred_values)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class RandomForest:\n",
        "    # constructor method for hyperparameter initialization\n",
        "    def __init__(self, min_samples=2, max_depth=2, n_trees=10, n_features=None):\n",
        "        self.min_samples = min_samples\n",
        "        self.max_depth = max_depth\n",
        "        self.n_trees = n_trees\n",
        "        self.n_features = n_features\n",
        "        self.trees = []\n",
        "\n",
        "\n",
        "    # method for bootstrapping samples\n",
        "    def bootastrap_sample(self, X, y):\n",
        "        n_samples = X.shape[0]\n",
        "        idxs = np.random.choice(n_samples, n_samples, replace=True)\n",
        "\n",
        "        return X[idxs], y[idxs]\n",
        "\n",
        "    # method for training each tree in the ensemble using a random subset of parameters\n",
        "    def fit(self, X, y):\n",
        "\n",
        "        for _ in range(self.n_trees):\n",
        "            tree = DecisionTree(min_samples=self.min_samples, max_depth= self.max_depth)\n",
        "            X_sample, y_sample = self.bootastrap_sample(X,y)\n",
        "            tree.fit(X_sample, y_sample)\n",
        "            self.trees.append(tree)\n",
        "\n",
        "\n",
        "    # method to calculate the predicted value by majority vote\n",
        "    def tree_value(self, y):\n",
        "        y = list(y)\n",
        "\n",
        "        most_common = max(y, key=y.count)\n",
        "\n",
        "        return most_common\n",
        "\n",
        "    def predict(self, X):\n",
        "        pred_values = np.array([tree.predict(X) for tree in self.trees])\n",
        "        true_preds = np.swapaxes(pred_values, 0, 1)\n",
        "        predictions = np.array([self.tree_value(pred) for pred in true_preds])\n",
        "        return predictions"
      ],
      "metadata": {
        "id": "YSQ2Fj3OW9tO"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    from sklearn.datasets import load_breast_cancer\n",
        "    from sklearn.model_selection import train_test_split\n",
        "\n",
        "    # auxiliar function to calculate the accuracy of the model\n",
        "    def accuracy(y_true, y_pred):\n",
        "        accuracy = (np.sum(y_true == y_pred) / len(y_true))*100\n",
        "        return accuracy\n",
        "\n",
        "    breast_cancer = load_breast_cancer()\n",
        "    X = breast_cancer.data\n",
        "    y = breast_cancer.target\n",
        "\n",
        "    # split the data into train and test datasets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=123)\n",
        "\n",
        "    model = RandomForest(max_depth=10, n_trees=10, n_features=15)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # calculate and print the accuracy value\n",
        "    acc = accuracy(y_test, y_pred)\n",
        "\n",
        "    print(acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NkbECo5mW-Dh",
        "outputId": "5da773b1-f663-45cb-83fd-1a5a2e593e6f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "97.36842105263158\n"
          ]
        }
      ]
    }
  ]
}