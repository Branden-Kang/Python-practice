{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP: Text Processing In Data Science Projects.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNusCdc+bdJ0Rx8EGolUniJ"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5r-D-R2-7Q7",
        "colab_type": "text"
      },
      "source": [
        "# NLP: Text Processing In Data Science Projects\n",
        "- [Reference](https://medium.com/fintechexplained/nlp-text-processing-in-data-science-projects-f083009d78fc)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-G5mIBqj-5g5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "b149f7a5-3ff5-48d0-b997-1c5ca23d0a20"
      },
      "source": [
        "!pip install nltk"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OB4_BQU8_WPU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "9f71aa6a-c9b7-473c-9a78-25a30672f09e"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from nltk.tokenize import TreebankWordTokenizer\n",
        "import string\n",
        "from nltk.corpus import stopwords"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tA5vAMvv_HT-",
        "colab_type": "text"
      },
      "source": [
        "## 1. Convert Text To Lowercase"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8R_rYb5_DrY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text = 'This is an NLP article of FinTechExplained'\n",
        "\n",
        "lower_case_text = lowercase(text)\n",
        "print(lower_case_text)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0qtrbgz_fA9",
        "colab_type": "text"
      },
      "source": [
        "## 2. Tokenise Paragraphs To Sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8cWNsBA_LUO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "2d55b3fb-58da-467b-c76a-b99860749ac2"
      },
      "source": [
        "text = 'FinTechExplained aims to explain how text processing works.  Once we have gathered the text, the next stage is about cleaning and consolidating the text. It is important to ensure the text is standardised and the noise is removed so that efficient analysis can be performed on the text to derive meaningful insights.'\n",
        "list = sent_tokenize(text)\n",
        "print(list)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['FinTechExplained aims to explain how text processing works.', 'Once we have gathered the text, the next stage is about cleaning and consolidating the text.', 'It is important to ensure the text is standardised and the noise is removed so that efficient analysis can be performed on the text to derive meaningful insights.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8CVRokyl_g_5",
        "colab_type": "text"
      },
      "source": [
        "## 3. Tokenise Sentences To Words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFK3A361_YMd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "a62b24b3-b703-40a0-e97c-b1ee248af756"
      },
      "source": [
        "tokenizer = TreebankWordTokenizer()\n",
        "text = 'FinTechExplained aims to explain how text processing works.  Once we have gathered the text, the next stage is about cleaning and consolidating the text. It is important to ensure the text is standardised and the noise is removed so that efficient analysis can be performed on the text to derive meaningful insights.'\n",
        "print(tokenizer.tokenize(text))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['FinTechExplained', 'aims', 'to', 'explain', 'how', 'text', 'processing', 'works.', 'Once', 'we', 'have', 'gathered', 'the', 'text', ',', 'the', 'next', 'stage', 'is', 'about', 'cleaning', 'and', 'consolidating', 'the', 'text.', 'It', 'is', 'important', 'to', 'ensure', 'the', 'text', 'is', 'standardised', 'and', 'the', 'noise', 'is', 'removed', 'so', 'that', 'efficient', 'analysis', 'can', 'be', 'performed', 'on', 'the', 'text', 'to', 'derive', 'meaningful', 'insights', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9FjoVZQO_r-N",
        "colab_type": "text"
      },
      "source": [
        "## 4. Remove Numbers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RggDrGk1_ofk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a6e3dd17-6a3f-432e-f20c-fbd13df65097"
      },
      "source": [
        "import re\n",
        "result = re.sub(r'\\d+', '', '909FinTechExplained9876')\n",
        "print(result)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FinTechExplained\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BfbOgrFi_x5H",
        "colab_type": "text"
      },
      "source": [
        "## 5. Remove Punctuation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCSrvM6x_waS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "punctuation = string.punctuation\n",
        "words = ['You','Are','Reading','FinTechExplained', '!', 'NLP', '.']\n",
        "clean_words = [w for w in words if w not in punctuation]\n",
        "clean_words = ['You','Are','Reading','FinTechExplained', 'NLP']"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r5BBAHv7_9Nv",
        "colab_type": "text"
      },
      "source": [
        "## 6. Remove Stop words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FzGBHd2I_2UK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ac98f08b-5e94-417d-e5cb-d0ce6e7e1d02"
      },
      "source": [
        "text = 'FinTechExplained is an important publication'\n",
        "words = nltk.word_tokenize(text)\n",
        "stopwords = stopwords.words('english')\n",
        "clean = [w for w in words if w not in stopwords]\n",
        "print(clean)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['FinTechExplained', 'important', 'publication']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2IUaaVhAKCM",
        "colab_type": "text"
      },
      "source": [
        "## 7. Remove Whitespaces"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQwfrQa9ADfD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "outputId": "d9c4d8d9-b9a1-4e44-b519-4d5b7bfdebd1"
      },
      "source": [
        "' '.join('FinTechExplained Is A      Publication. \\n This is about NLP'.split())"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'FinTechExplained Is A Publication. This is about NLP'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    }
  ]
}