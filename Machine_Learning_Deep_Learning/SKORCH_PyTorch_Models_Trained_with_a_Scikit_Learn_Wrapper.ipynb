{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SKORCH: PyTorch Models Trained with a Scikit-Learn Wrapper.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO2LInwlszGhdcGTwsgPrME"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uf-6sdzp4DKD"
      },
      "source": [
        "[Reference](https://towardsdatascience.com/skorch-pytorch-models-trained-with-a-scikit-learn-wrapper-62b9a154623e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Vq4UgW44WJX"
      },
      "source": [
        "![SKORCH](https://miro.medium.com/max/1400/1*E4GZb4qpcppgTM6BYN_X_Q.jpeg)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZhs0guA5PPD"
      },
      "source": [
        "# PyTorch Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swIIEamj4BUM"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self, num_units=10, dropout=0.1):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        self.num_units = num_units\n",
        "        self.linear_1 = nn.Linear(13, num_units)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.linear_2 = nn.Linear(num_units, 10)\n",
        "        self.linear_3 = nn.Linear(10, 3)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.linear_1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.linear_2(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.linear_3(x)\n",
        "        x = F.softmax(x, dim=-1)\n",
        "\n",
        "        return x"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_jxkNaXL5Qvj"
      },
      "source": [
        "# Training with SKORCH"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "am7v0RBz5RnH"
      },
      "source": [
        "## 1. Basic Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nBbtJKjf5Q_K"
      },
      "source": [
        "# Import PyTorch model\n",
        "from src import NeuralNet\n",
        "# Import SKORCH NN classifier\n",
        "from skorch import NeuralNetClassifier\n",
        "\n",
        "# The Neural Net is initialized with fixed hyperparameters\n",
        "nn = NeuralNetClassifier(NeuralNet, max_epochs=10, lr=0.01, batch_size=12, optimizer=optim.RMSprop)\n",
        "# Training\n",
        "nn.fit(self.x, self.y)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4m1fH4qc6FDD"
      },
      "source": [
        "## 2. Pipeline: Scaler + Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fza-cOQw5oeQ"
      },
      "source": [
        "# Import PyTorch model\n",
        "from src import NeuralNet\n",
        "\n",
        "# Import Pipeline and Scaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Import SKORCH NN classifier\n",
        "from skorch import NeuralNetClassifier\n",
        "\n",
        "# The Neural Net is initialized with fixed hyperparameters\n",
        "nn = NeuralNetClassifier(NeuralNet, max_epochs=10, lr=0.01, batch_size=12, optimizer=optim.RMSprop)\n",
        "# The pipeline instatiated, it wraps scaling and training phase\n",
        "pipeline = Pipeline([('scale', StandardScaler()), ('nn', nn)])\n",
        "# Pipeline execution\n",
        "pipeline.fit(self.x, self.y)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bmzclGPD6G4b"
      },
      "source": [
        "## 3. Pipeline: Scaler + Training + Callbacks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ec5gb9u58IH"
      },
      "source": [
        "# PyTorch optimizer\n",
        "from torch import optim\n",
        "\n",
        "# Pipeline and Standar scaler import\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Import the epoch scoring callback\n",
        "from skorch.callbacks import EpochScoring\n",
        "from skorch import NeuralNetClassifier\n",
        "\n",
        "from src import NeuralNet\n",
        "\n",
        "# The EpochScoring from callbacks is initialized\n",
        "balanced_accuracy = EpochScoring(scoring='balanced_accuracy', lower_is_better=False)\n",
        "accuracy = EpochScoring(scoring='accuracy', lower_is_better=False)\n",
        "\n",
        "# The Neural Net is initialized with fixed hyperparameters\n",
        "nn = NeuralNetClassifier(NeuralNet, max_epochs=10, lr=0.01, batch_size=12, optimizer=optim.RMSprop, callbacks=[balanced_accuracy, accuracy])\n",
        "# The pipeline instatiated, it wraps scaling and training phase\n",
        "pipeline = Pipeline([('scale', StandardScaler()), ('nn', nn)])\n",
        "# Pipeline execution\n",
        "pipeline.fit(self.x, self.y)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mcCvZNhG6Ihp"
      },
      "source": [
        "## 4. GridSearch: Pipeline + Scaler + Training + Callbacks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "soKiF9jH6B9-"
      },
      "source": [
        "# PyTorch optimizer\n",
        "from torch import optim\n",
        "\n",
        "# Pipeline\n",
        "from sklearn.pipeline import Pipeline\n",
        "# Scaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "# Grid Search\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Scoring with callbacks\n",
        "from skorch.callbacks import EpochScoring\n",
        "# Neural Net wrapper\n",
        "from skorch import NeuralNetClassifier\n",
        "# PyTorch model\n",
        "from src import NeuralNet\n",
        "\n",
        "# The Neural Net is instantiated, none hyperparameter is provided\n",
        "nn = NeuralNetClassifier(NeuralNet, verbose=0, train_split=False)\n",
        "# The pipeline is instantiated, it wraps scaling and training phase\n",
        "pipeline = Pipeline([('scale', StandardScaler()), ('nn', nn)])\n",
        "\n",
        "# The parameters for the grid search are defined\n",
        "# It must be used the prefix \"nn__\" when setting hyperparamters for the training phase\n",
        "# It must be used the prefix \"nn__module__\" when setting hyperparameters for the Neural Net\n",
        "params = {\n",
        "\t'nn__max_epochs':[10, 20],\n",
        "\t'nn__lr': [0.1, 0.01],\n",
        "\t'nn__module__num_units': [5, 10],\n",
        "\t'nn__module__dropout': [0.1, 0.5],\n",
        "\t'nn__optimizer': [optim.Adam, optim.SGD, optim.RMSprop]}\n",
        "\n",
        "# The grid search module is instantiated\n",
        "gs = GridSearchCV(pipeline, params, refit=False, cv=3, scoring='balanced_accuracy', verbose=1)\n",
        "# Initialize grid search\n",
        "gs.fit(self.x, self.y)"
      ],
      "execution_count": 7,
      "outputs": []
    }
  ]
}