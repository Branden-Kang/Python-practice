{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Easily Build a Stock Sentiment App with Streamlit.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOYpz0YJh2JsKFAl81HBYT9"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[Reference](https://medium.datadriveninvestor.com/easily-build-a-stock-sentiment-app-with-streamlit-9f61cba58c2e)"
      ],
      "metadata": {
        "id": "ct-Mkl-YEVcG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Dgg4y1CuC-oW"
      },
      "outputs": [],
      "source": [
        "import streamlit as st\n",
        "from urllib.request import urlopen, Request\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import plotly\n",
        "import plotly.express as px\n",
        "import json # for graph plotting in website\n",
        "# NLTK VADER for sentiment analysis\n",
        "import nltk\n",
        "nltk.downloader.download('vader_lexicon')\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "\n",
        "def get_news(ticker):\n",
        "    url = finviz_url + ticker\n",
        "    req = Request(url=url,headers={'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; WOW64; rv:20.0) Gecko/20100101 Firefox/20.0'}) \n",
        "    response = urlopen(req)    \n",
        "    # Read the contents of the file into 'html'\n",
        "    html = BeautifulSoup(response)\n",
        "    # Find 'news-table' in the Soup and load it into 'news_table'\n",
        "    news_table = html.find(id='news-table')\n",
        "    return news_table\n",
        "\t\n",
        "# parse news into dataframe\n",
        "def parse_news(news_table):\n",
        "    parsed_news = []\n",
        "    \n",
        "    for x in news_table.findAll('tr'):\n",
        "        # read the text from each tr tag into text\n",
        "        # get text from a only\n",
        "        text = x.a.get_text() \n",
        "        # splite text in the td tag into a list \n",
        "        date_scrape = x.td.text.split()\n",
        "        # if the length of 'date_scrape' is 1, load 'time' as the only element\n",
        "\n",
        "        if len(date_scrape) == 1:\n",
        "            time = date_scrape[0]\n",
        "            \n",
        "        # else load 'date' as the 1st element and 'time' as the second    \n",
        "        else:\n",
        "            date = date_scrape[0]\n",
        "            time = date_scrape[1]\n",
        "        \n",
        "        # Append ticker, date, time and headline as a list to the 'parsed_news' list\n",
        "        parsed_news.append([date, time, text])        \n",
        "        # Set column names\n",
        "        columns = ['date', 'time', 'headline']\n",
        "        # Convert the parsed_news list into a DataFrame called 'parsed_and_scored_news'\n",
        "        parsed_news_df = pd.DataFrame(parsed_news, columns=columns)        \n",
        "        # Create a pandas datetime object from the strings in 'date' and 'time' column\n",
        "        parsed_news_df['datetime'] = pd.to_datetime(parsed_news_df['date'] + ' ' + parsed_news_df['time'])\n",
        "        \n",
        "    return parsed_news_df\n",
        "        \n",
        "def score_news(parsed_news_df):\n",
        "    # Instantiate the sentiment intensity analyzer\n",
        "    vader = SentimentIntensityAnalyzer()\n",
        "    \n",
        "    # Iterate through the headlines and get the polarity scores using vader\n",
        "    scores = parsed_news_df['headline'].apply(vader.polarity_scores).tolist()\n",
        "\n",
        "    # Convert the 'scores' list of dicts into a DataFrame\n",
        "    scores_df = pd.DataFrame(scores)\n",
        "\n",
        "    # Join the DataFrames of the news and the list of dicts\n",
        "    parsed_and_scored_news = parsed_news_df.join(scores_df, rsuffix='_right')             \n",
        "    parsed_and_scored_news = parsed_and_scored_news.set_index('datetime')    \n",
        "    parsed_and_scored_news = parsed_and_scored_news.drop(['date', 'time'], 1)          \n",
        "    parsed_and_scored_news = parsed_and_scored_news.rename(columns={\"compound\": \"sentiment_score\"})\n",
        "\n",
        "    return parsed_and_scored_news\n",
        "\n",
        "def plot_hourly_sentiment(parsed_and_scored_news, ticker):\n",
        "   \n",
        "    # Group by date and ticker columns from scored_news and calculate the mean\n",
        "    mean_scores = parsed_and_scored_news.resample('H').mean()\n",
        "\n",
        "    # Plot a bar chart with plotly\n",
        "    fig = px.bar(mean_scores, x=mean_scores.index, y='sentiment_score', title = ticker + ' Hourly Sentiment Scores')\n",
        "    return fig # instead of using fig.show(), we return fig and turn it into a graphjson object for displaying in web page later\n",
        "\n",
        "def plot_daily_sentiment(parsed_and_scored_news, ticker):\n",
        "   \n",
        "    # Group by date and ticker columns from scored_news and calculate the mean\n",
        "    mean_scores = parsed_and_scored_news.resample('D').mean()\n",
        "\n",
        "    # Plot a bar chart with plotly\n",
        "    fig = px.bar(mean_scores, x=mean_scores.index, y='sentiment_score', title = ticker + ' Daily Sentiment Scores')\n",
        "    return fig # instead of using fig.show(), we return fig and turn it into a graphjson object for displaying in web page later\n",
        "\n",
        "# for extracting data from finviz\n",
        "finviz_url = 'https://finviz.com/quote.ashx?t='\n",
        "\n",
        "st.set_page_config(page_title = \"Bohmian's Stock News Sentiment Analyzer\", layout = \"wide\")\n",
        "st.header(\"Bohmian's Stock News Sentiment Analyzer\")\n",
        "\n",
        "ticker = st.text_input('Enter Stock Ticker', '').upper()\n",
        "\n",
        "try:\n",
        "\tst.subheader(\"Hourly and Daily Sentiment of {} Stock\".format(ticker))\n",
        "\tnews_table = get_news(ticker)\n",
        "\tparsed_news_df = parse_news(news_table)\n",
        "\tparsed_and_scored_news = score_news(parsed_news_df)\n",
        "\tfig_hourly = plot_hourly_sentiment(parsed_and_scored_news, ticker)\n",
        "\tfig_daily = plot_daily_sentiment(parsed_and_scored_news, ticker) \n",
        "\t \n",
        "\tst.plotly_chart(fig_hourly)\n",
        "\tst.plotly_chart(fig_daily)\n",
        "\n",
        "\tdescription = \"\"\"\n",
        "\t\tThe above chart averages the sentiment scores of {} stock hourly and daily.\n",
        "\t\tThe table below gives each of the most recent headlines of the stock and the negative, neutral, positive and an aggregated sentiment score.\n",
        "\t\tThe news headlines are obtained from the FinViz website.\n",
        "\t\tSentiments are given by the nltk.sentiment.vader Python library.\n",
        "\t\t\"\"\".format(ticker)\n",
        "\t\t\n",
        "\tst.write(description)\t \n",
        "\tst.table(parsed_and_scored_news)\n",
        "\t\n",
        "except:\n",
        "\tst.write(\"Enter a correct stock ticker, e.g. 'AAPL' above and hit Enter.\")\t\n",
        "\n",
        "hide_streamlit_style = \"\"\"\n",
        "<style>\n",
        "#MainMenu {visibility: hidden;}\n",
        "footer {visibility: hidden;}\n",
        "</style>\n",
        "\"\"\"\n",
        "st.markdown(hide_streamlit_style, unsafe_allow_html=True) "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Procfile\n",
        "# web: sh setup.sh && streamlit run app.py"
      ],
      "metadata": {
        "id": "YoX5FtyJEI7F"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # setup.sh\n",
        "# mkdir -p ~/.streamlit/\n",
        "# echo \"\\\n",
        "# [server]\\n\\\n",
        "# headless = true\\n\\\n",
        "# port = $PORT\\n\\\n",
        "# enableCORS = false\\n\\\n",
        "# \\n\\\n",
        "# \" > ~/.streamlit/config.toml"
      ],
      "metadata": {
        "id": "YFuzZy8dELAc"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # requirements.txt\n",
        "# streamlit\n",
        "# pandas\n",
        "# nltk\n",
        "# urllib3\n",
        "# bs4\n",
        "# plotly\n",
        "# gunicorn"
      ],
      "metadata": {
        "id": "ztiZb--DEOCh"
      },
      "execution_count": 4,
      "outputs": []
    }
  ]
}