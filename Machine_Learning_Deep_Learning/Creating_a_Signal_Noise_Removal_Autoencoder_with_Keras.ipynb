{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMiFjSMwITeZDkaT7gKQVGB"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[Reference](https://pub.aimind.so/creating-a-signal-noise-removal-autoencoder-with-keras-7e0774c51df3)"
      ],
      "metadata": {
        "id": "ty6i6PDAvHM4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "BKsJPfxVvDMK"
      },
      "outputs": [],
      "source": [
        "import tensorflow.keras\n",
        "from tensorflow.keras.models import Sequential, save_model\n",
        "from tensorflow.keras.layers import Conv1D, Conv1DTranspose\n",
        "from tensorflow.keras.constraints import max_norm\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "# Model configuration\n",
        "input_shape = (150, 1)\n",
        "batch_size = 150\n",
        "no_epochs = 5\n",
        "train_test_split = 0.3\n",
        "validation_split = 0.2\n",
        "verbosity = 1\n",
        "max_norm_value = 2.0\n",
        "\n",
        "# Load data\n",
        "data_noisy = np.load('./signal_waves_noisy_medium.npy')\n",
        "x_val_noisy, y_val_noisy = data_noisy[:,0], data_noisy[:,1]\n",
        "data_pure = np.load('./signal_waves_medium.npy')\n",
        "x_val_pure, y_val_pure = data_pure[:,0], data_pure[:,1]\n",
        "\n",
        "# Reshape data\n",
        "y_val_noisy_r = []\n",
        "y_val_pure_r = []\n",
        "for i in range(0, len(y_val_noisy)):\n",
        "  noisy_sample = y_val_noisy[i]\n",
        "  pure_sample = y_val_pure[i]\n",
        "  noisy_sample = (noisy_sample - np.min(noisy_sample)) / (np.max(noisy_sample) - np.min(noisy_sample))\n",
        "  pure_sample = (pure_sample - np.min(pure_sample)) / (np.max(pure_sample) - np.min(pure_sample))\n",
        "  y_val_noisy_r.append(noisy_sample)\n",
        "  y_val_pure_r.append(pure_sample)\n",
        "y_val_noisy_r   = np.array(y_val_noisy_r)\n",
        "y_val_pure_r    = np.array(y_val_pure_r)\n",
        "noisy_input     = y_val_noisy_r.reshape((y_val_noisy_r.shape[0], y_val_noisy_r.shape[1], 1))\n",
        "pure_input      = y_val_pure_r.reshape((y_val_pure_r.shape[0], y_val_pure_r.shape[1], 1))\n",
        "\n",
        "# Train/test split\n",
        "percentage_training = math.floor((1 - train_test_split) * len(noisy_input))\n",
        "noisy_input, noisy_input_test = noisy_input[:percentage_training], noisy_input[percentage_training:]\n",
        "pure_input, pure_input_test = pure_input[:percentage_training], pure_input[percentage_training:]\n",
        "\n",
        "# Create the model\n",
        "model = Sequential()\n",
        "model.add(Conv1D(128, kernel_size=3, kernel_constraint=max_norm(max_norm_value), activation='relu', kernel_initializer='he_uniform', input_shape=input_shape))\n",
        "model.add(Conv1D(32, kernel_size=3, kernel_constraint=max_norm(max_norm_value), activation='relu', kernel_initializer='he_uniform'))\n",
        "model.add(Conv1DTranspose(32, kernel_size=3, kernel_constraint=max_norm(max_norm_value), activation='relu', kernel_initializer='he_uniform'))\n",
        "model.add(Conv1DTranspose(128, kernel_size=3, kernel_constraint=max_norm(max_norm_value), activation='relu', kernel_initializer='he_uniform'))\n",
        "model.add(Conv1D(1, kernel_size=3, kernel_constraint=max_norm(max_norm_value), activation='sigmoid', padding='same'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# Compile and fit data\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "model.fit(noisy_input, pure_input,\n",
        "                epochs=no_epochs,\n",
        "                batch_size=batch_size,\n",
        "                validation_split=validation_split)\n",
        "\n",
        "# Generate reconstructions\n",
        "num_reconstructions = 4\n",
        "samples = noisy_input_test[:num_reconstructions]\n",
        "reconstructions = model.predict(samples)\n",
        "\n",
        "# Plot reconstructions\n",
        "for i in np.arange(0, num_reconstructions):\n",
        "  # Prediction index\n",
        "  prediction_index = i + percentage_training\n",
        "  # Get the sample and the reconstruction\n",
        "  original = y_val_noisy[prediction_index]\n",
        "  pure = y_val_pure[prediction_index]\n",
        "  reconstruction = np.array(reconstructions[i])\n",
        "  # Matplotlib preparations\n",
        "  fig, axes = plt.subplots(1, 3)\n",
        "  # Plot sample and reconstruciton\n",
        "  axes[0].plot(original)\n",
        "  axes[0].set_title('Noisy waveform')\n",
        "  axes[1].plot(pure)\n",
        "  axes[1].set_title('Pure waveform')\n",
        "  axes[2].plot(reconstruction)\n",
        "  axes[2].set_title('Conv Autoencoder Denoised waveform')\n",
        "  plt.show()"
      ]
    }
  ]
}
