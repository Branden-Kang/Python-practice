{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPQQeM9TYATLGWYWyob5Swj"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[Reference](https://medium.datadriveninvestor.com/why-your-machine-learning-model-fails-in-production-a-deep-dive-into-sampling-design-698874ed3dfd)"
      ],
      "metadata": {
        "id": "mxFmXaDa5tya"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Random Sampling"
      ],
      "metadata": {
        "id": "e4jIblbn5wmQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MPc2IXcc5XDE",
        "outputId": "cca7801d-0edc-4029-b862-1e96856f7ac8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train shape: (120, 4)\n",
            "Test shape: (30, 4)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load example dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Random sampling (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"Train shape:\", X_train.shape)\n",
        "print(\"Test shape:\", X_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Stratified Sampling"
      ],
      "metadata": {
        "id": "yDuV3NbS5zqj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Stratified sampling\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "# Check distribution\n",
        "import numpy as np\n",
        "print(\"Train class distribution:\", np.bincount(y_train))\n",
        "print(\"Test class distribution:\", np.bincount(y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZ4PBn005yqy",
        "outputId": "b8e66778-cc5e-448a-8b39-2480a4317111"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train class distribution: [40 40 40]\n",
            "Test class distribution: [10 10 10]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Systematic Sampling"
      ],
      "metadata": {
        "id": "raCHfb1B54wn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Sample dataset\n",
        "df = pd.DataFrame({'feature': range(1, 101), 'label': np.random.choice([0, 1], size=100)})\n",
        "\n",
        "# Step 1: Shuffle the data (optional but recommended unless already randomized)\n",
        "df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# Step 2: Define sampling interval\n",
        "k = 5  # every 5th record goes to test set\n",
        "\n",
        "# Step 3: Index-based split\n",
        "test_indices = list(range(0, len(df), k))\n",
        "train_indices = list(set(range(len(df))) - set(test_indices))\n",
        "\n",
        "# Step 4: Create train and test sets\n",
        "train_df = df.loc[train_indices].reset_index(drop=True)\n",
        "test_df = df.loc[test_indices].reset_index(drop=True)\n",
        "print(\"Train size:\", len(train_df))\n",
        "print(\"Test size:\", len(test_df))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "htoq0tcF532n",
        "outputId": "e56a9f38-9e86-4e93-ef0e-dc4bfebfec1c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train size: 80\n",
            "Test size: 20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Time-based (Temporal) Sampling"
      ],
      "metadata": {
        "id": "DI-m3uhE59A-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Simulated time-series data\n",
        "df = pd.DataFrame({\n",
        "    'date': pd.date_range(start='2022-01-01', periods=100),\n",
        "    'feature': range(100),\n",
        "    'target': [1 if x < 50 else 0 for x in range(100)]\n",
        "})\n",
        "\n",
        "# Sort by date\n",
        "df = df.sort_values('date')\n",
        "\n",
        "# Time-based split\n",
        "train = df[df['date'] < '2022-03-01']\n",
        "test = df[df['date'] >= '2022-03-01']\n",
        "\n",
        "print(\"Train size:\", train.shape)\n",
        "print(\"Test size:\", test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zNXjnhVG57te",
        "outputId": "0687df31-614c-4dcb-f019-910313540800"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train size: (59, 3)\n",
            "Test size: (41, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Cluster and Multi-stage Sampling"
      ],
      "metadata": {
        "id": "7Rv7JUN35_TF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Simulate cluster-like data\n",
        "np.random.seed(42)\n",
        "df = pd.DataFrame({\n",
        "    'region': np.random.choice(['North', 'South', 'East', 'West'], size=1000),\n",
        "    'feature': np.random.randn(1000),\n",
        "    'target': np.random.randint(0, 2, size=1000)\n",
        "})\n",
        "\n",
        "# Choose 2 clusters randomly\n",
        "clusters = df['region'].unique()\n",
        "selected_clusters = np.random.choice(clusters, size=2, replace=False)\n",
        "sampled_df = df[df['region'].isin(selected_clusters)]\n",
        "\n",
        "print(\"Sampled from clusters:\", selected_clusters)\n",
        "print(\"Sample size:\", sampled_df.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xSnaHeT45-KW",
        "outputId": "3092e958-7f71-49d6-a301-01c27f2529ca"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sampled from clusters: ['West' 'North']\n",
            "Sample size: (538, 3)\n"
          ]
        }
      ]
    }
  ]
}
