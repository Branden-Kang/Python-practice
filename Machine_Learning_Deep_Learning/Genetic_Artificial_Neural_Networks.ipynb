{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Genetic Artificial Neural Networks",
      "provenance": [],
      "authorship_tag": "ABX9TyPElAMiBzsdp3+QeOPlJVGm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4lrM76oiOOQm"
      },
      "source": [
        "[Reference](https://medium.com/swlh/genetic-artificial-neural-networks-d6b85578ba99)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jtvYYzwSfzFZ"
      },
      "source": [
        "Dataset is [here](https://archive.ics.uci.edu/ml/datasets/banknote+authentication#)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0JxgbR74K44S",
        "outputId": "60f1827b-9a09-4dea-92fa-cd13aea9e6c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "\n",
        "# Could make a generalized instance of the Model Keras class for a GNN\n",
        "# New Type of Neural Network\n",
        "class GeneticNeuralNetwork(Sequential):\n",
        "    # Constructor\n",
        "    def __init__(self, child_weights=None):\n",
        "        # Initialize Sequential Model Super Class\n",
        "        super().__init__()\n",
        "        # If no weights provided randomly generate them\n",
        "        if child_weights is None:\n",
        "            # Layers are created and randomly generated\n",
        "            layer1 = Dense(4, input_shape=(4,), activation='sigmoid')\n",
        "            layer2 = Dense(2, activation='sigmoid')\n",
        "            layer3 = Dense(1, activation='sigmoid')\n",
        "            # Layers are added to the model\n",
        "            self.add(layer1)\n",
        "            self.add(layer2)\n",
        "            self.add(layer3)\n",
        "        # If weights are provided set them within the layers\n",
        "        else:\n",
        "            # Set weights within the layers\n",
        "            self.add(\n",
        "                Dense(\n",
        "                    4,\n",
        "                    input_shape=(4,),\n",
        "                    activation='sigmoid',\n",
        "                    weights=[child_weights[0], np.zeros(4)])\n",
        "                )\n",
        "            self.add(\n",
        "                Dense(\n",
        "                 2,\n",
        "                 activation='sigmoid',\n",
        "                 weights=[child_weights[1], np.zeros(2)])\n",
        "            )\n",
        "            self.add(\n",
        "                Dense(\n",
        "                 1,\n",
        "                 activation='sigmoid',\n",
        "                 weights=[child_weights[2], np.zeros(1)])\n",
        "            )\n",
        "\n",
        "    # Function for forward propagating a row vector of a matrix\n",
        "    def forward_propagation(self, X_train, y_train):\n",
        "        # Forward propagation\n",
        "        y_hat = self.predict(X_train.values)\n",
        "        # Compute fitness score\n",
        "        self.fitness = accuracy_score(y_train, y_hat.round())\n",
        "\n",
        "    # Standard Backpropagation\n",
        "    def compile_train(self, epochs):\n",
        "        self.compile(\n",
        "                      optimizer='rmsprop',\n",
        "                      loss='binary_crossentropy',\n",
        "                      metrics=['accuracy']\n",
        "                      )\n",
        "        self.fit(X_train.values, y_train.values, epochs=epochs)\n",
        "\n",
        "\n",
        "# Chance to mutate weights\n",
        "def mutation(child_weights):\n",
        "    # Add a chance for random mutation\n",
        "    selection = random.randint(0, len(child_weights)-1)\n",
        "    mut = random.uniform(0, 1)\n",
        "    if mut >= .5:\n",
        "        child_weights[selection] *= random.randint(2, 5)\n",
        "    else:\n",
        "        # No mutation\n",
        "        pass\n",
        "\n",
        "\n",
        "# Crossover traits between two Genetic Neural Networks\n",
        "def dynamic_crossover(nn1, nn2):\n",
        "    # Lists for respective weights\n",
        "    nn1_weights = []\n",
        "    nn2_weights = []\n",
        "    child_weights = []\n",
        "    # Get all weights from all layers in the first network\n",
        "    for layer in nn1.layers:\n",
        "        nn1_weights.append(layer.get_weights()[0])\n",
        "\n",
        "    # Get all weights from all layers in the second network\n",
        "    for layer in nn2.layers:\n",
        "        nn2_weights.append(layer.get_weights()[0])\n",
        "\n",
        "    # Iterate through all weights from all layers for crossover\n",
        "    for i in range(0, len(nn1_weights)):\n",
        "        # Get single point to split the matrix in parents based on # of cols\n",
        "        split = random.randint(0, np.shape(nn1_weights[i])[1]-1)\n",
        "        # Iterate through after a single point and set the remaing cols to nn_2\n",
        "        for j in range(split, np.shape(nn1_weights[i])[1]-1):\n",
        "            nn1_weights[i][:, j] = nn2_weights[i][:, j]\n",
        "\n",
        "        # After crossover add weights to child\n",
        "        child_weights.append(nn1_weights[i])\n",
        "\n",
        "    # Add a chance for mutation\n",
        "    mutation(child_weights)\n",
        "\n",
        "    # Create and return child object\n",
        "    child = GeneticNeuralNetwork(child_weights)\n",
        "    return child\n",
        "\n",
        "\n",
        "# Read Data\n",
        "data = pd.read_csv('https://raw.githubusercontent.com/RomanMichaelPaolucci/Genetic_Neural_Network/master/gnn/assets/banknote.csv')\n",
        "# Create Matrix of Independent Variables\n",
        "X = data.drop(['Y'], axis=1)\n",
        "# Create Vector of Dependent Variable\n",
        "y = data['Y']\n",
        "# Create a Train Test Split for Genetic Optimization\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
        "# Create a List of all active GeneticNeuralNetworks\n",
        "networks = []\n",
        "pool = []\n",
        "# Track Generations\n",
        "generation = 0\n",
        "# Initial Population\n",
        "n = 20\n",
        "\n",
        "# Generate n randomly weighted neural networks\n",
        "for i in range(0, n):\n",
        "    networks.append(GeneticNeuralNetwork())\n",
        "\n",
        "# Cache Max Fitness\n",
        "max_fitness = 0\n",
        "\n",
        "# Max Fitness Weights\n",
        "optimal_weights = []\n",
        "\n",
        "# Evolution Loop\n",
        "while max_fitness < .9:\n",
        "    # Log the current generation\n",
        "    generation += 1\n",
        "    print('Generation: ', generation)\n",
        "\n",
        "    # Forward propagate the neural networks to compute a fitness score\n",
        "    for nn in networks:\n",
        "        # Propagate to calculate fitness score\n",
        "        nn.forward_propagation(X_train, y_train)\n",
        "        # Add to pool after calculating fitness\n",
        "        pool.append(nn)\n",
        "\n",
        "    # Clear for propagation of next children\n",
        "    networks.clear()\n",
        "\n",
        "    # Sort based on fitness\n",
        "    pool = sorted(pool, key=lambda x: x.fitness)\n",
        "    pool.reverse()\n",
        "\n",
        "    # Find Max Fitness and Log Associated Weights\n",
        "    for i in range(0, len(pool)):\n",
        "        # If there is a new max fitness among the population\n",
        "        if pool[i].fitness > max_fitness:\n",
        "            max_fitness = pool[i].fitness\n",
        "            print('Max Fitness: ', max_fitness)\n",
        "            # Reset optimal_weights\n",
        "            optimal_weights = []\n",
        "            # Iterate through layers, get weights, and append to optimal\n",
        "            for layer in pool[i].layers:\n",
        "                optimal_weights.append(layer.get_weights()[0])\n",
        "            print(optimal_weights)\n",
        "\n",
        "    # Crossover, top 5 randomly select 2 partners for child\n",
        "    for i in range(0, 5):\n",
        "        for j in range(0, 2):\n",
        "            # Create a child and add to networks\n",
        "            temp = dynamic_crossover(pool[i], random.choice(pool))\n",
        "            # Add to networks to calculate fitness score next iteration\n",
        "            networks.append(temp)\n",
        "\n",
        "# Create a Genetic Neural Network with optimal initial weights\n",
        "gnn = GeneticNeuralNetwork(optimal_weights)\n",
        "gnn.compile_train(10)\n",
        "\n",
        "# Test the Genetic Neural Network Out of Sample\n",
        "y_hat = gnn.predict(X_test.values)\n",
        "print('Test Accuracy: %.2f' % accuracy_score(y_test, y_hat.round()))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Generation:  1\n",
            "Max Fitness:  0.6190476190476191\n",
            "[array([[ 0.59713453,  0.11312538,  0.3191859 ,  0.03097457],\n",
            "       [ 0.18138033,  0.31044883,  0.0520094 , -0.2794119 ],\n",
            "       [-0.53189266, -0.55048275, -0.7072301 , -0.38685054],\n",
            "       [ 0.2516951 , -0.28033507,  0.10837084, -0.614552  ]],\n",
            "      dtype=float32), array([[-0.79730296, -0.514477  ],\n",
            "       [ 0.44680023, -0.30450654],\n",
            "       [ 0.6837721 , -0.6308942 ],\n",
            "       [-0.17251062,  0.03944778]], dtype=float32), array([[-0.82808644],\n",
            "       [ 0.84126794]], dtype=float32)]\n",
            "Generation:  2\n",
            "Max Fitness:  0.749271137026239\n",
            "[array([[-2.5522614 ,  0.84687114,  0.70293546,  0.12389827],\n",
            "       [-2.2133865 , -1.1992662 ,  1.2360437 , -1.1176476 ],\n",
            "       [-0.7469313 , -1.7898163 ,  0.62374187, -1.5474021 ],\n",
            "       [-1.8946857 ,  0.47878695,  0.9998443 , -2.458208  ]],\n",
            "      dtype=float32), array([[-0.49619913, -0.514477  ],\n",
            "       [ 0.15875125, -0.30450654],\n",
            "       [-0.18358994, -0.6308942 ],\n",
            "       [-0.83935714,  0.03944778]], dtype=float32), array([[-0.82808644],\n",
            "       [ 0.84126794]], dtype=float32)]\n",
            "Generation:  3\n",
            "Generation:  4\n",
            "Generation:  5\n",
            "Generation:  6\n",
            "Generation:  7\n",
            "Generation:  8\n",
            "Max Fitness:  0.750242954324587\n",
            "[array([[-2.5522614 ,  0.11312538, -0.40380907,  0.12389827],\n",
            "       [-2.2133865 ,  0.31044883,  0.8092976 , -1.1176476 ],\n",
            "       [-0.7469313 , -0.55048275, -0.2875151 , -1.5474021 ],\n",
            "       [-1.8946857 , -0.28033507,  0.8546838 , -2.458208  ]],\n",
            "      dtype=float32), array([[-4.8023586 , -1.543431  ],\n",
            "       [ 3.979208  , -0.9135196 ],\n",
            "       [-1.3401089 , -1.8926826 ],\n",
            "       [-1.4335699 ,  0.11834335]], dtype=float32), array([[-0.82808644],\n",
            "       [ 0.84126794]], dtype=float32)]\n",
            "Generation:  9\n",
            "Max Fitness:  0.8289601554907677\n",
            "[array([[-7.656784 ,  2.5406134,  2.1088064,  0.3716948],\n",
            "       [-6.6401596, -3.5977986,  3.708131 , -3.352943 ],\n",
            "       [-2.240794 , -5.3694487,  1.8712256, -4.642206 ],\n",
            "       [-5.684057 ,  1.4363608,  2.999533 , -7.3746243]], dtype=float32), array([[-0.6545663 , -0.514477  ],\n",
            "       [ 0.43064594, -0.30450654],\n",
            "       [ 0.3115561 , -0.6308942 ],\n",
            "       [-0.6669116 ,  0.03944778]], dtype=float32), array([[-4.1404324],\n",
            "       [ 4.20634  ]], dtype=float32)]\n",
            "Generation:  10\n",
            "Generation:  11\n",
            "Max Fitness:  0.8309037900874635\n",
            "[array([[-2.5522614 ,  0.2678284 , -0.80036813,  0.12389827],\n",
            "       [-2.2133865 ,  0.5967055 , -0.48757267, -1.1176476 ],\n",
            "       [-0.7469313 ,  0.6636117 , -0.6152574 , -1.5474021 ],\n",
            "       [-1.8946857 ,  0.4381711 , -0.21993881, -2.458208  ]],\n",
            "      dtype=float32), array([[-4.8023586 , -1.543431  ],\n",
            "       [ 3.979208  , -0.9135196 ],\n",
            "       [-1.3401089 , -1.8926826 ],\n",
            "       [-1.4335699 ,  0.11834335]], dtype=float32), array([[-0.82808644],\n",
            "       [ 0.84126794]], dtype=float32)]\n",
            "Generation:  12\n",
            "Max Fitness:  0.8668610301263362\n",
            "[array([[ -2.5522614 ,   0.11312538,  -0.40380907,   1.4867792 ],\n",
            "       [ -2.2133865 ,   0.31044883,   0.8092976 , -13.411772  ],\n",
            "       [ -0.7469313 ,  -0.55048275,  -0.2875151 , -18.568825  ],\n",
            "       [ -1.8946857 ,  -0.28033507,   0.8546838 , -29.498497  ]],\n",
            "      dtype=float32), array([[-96.04717   ,  -2.057908  ],\n",
            "       [ 79.58416   ,  -1.2180262 ],\n",
            "       [-26.802177  ,  -2.5235767 ],\n",
            "       [-28.671398  ,   0.15779114]], dtype=float32), array([[-12.421297],\n",
            "       [ 12.619019]], dtype=float32)]\n",
            "Generation:  13\n",
            "Generation:  14\n",
            "Generation:  15\n",
            "Max Fitness:  0.8833819241982507\n",
            "[array([[ -2.5522614 ,  -0.34405643,  -0.63736314,   1.4867792 ],\n",
            "       [ -2.2133865 ,   0.08824849,  -0.33389652, -13.411772  ],\n",
            "       [ -0.7469313 ,  -0.10216171,   0.05396366, -18.568825  ],\n",
            "       [ -1.8946857 ,  -0.19778883,   0.8261407 , -29.498497  ]],\n",
            "      dtype=float32), array([[-96.04717   ,  -2.057908  ],\n",
            "       [ 79.58416   ,  -1.2180262 ],\n",
            "       [-26.802177  ,  -2.5235767 ],\n",
            "       [-28.671398  ,   0.15779114]], dtype=float32), array([[-37.263893],\n",
            "       [ 37.857056]], dtype=float32)]\n",
            "Generation:  16\n",
            "Max Fitness:  0.9475218658892128\n",
            "[array([[-2.5522614 ,  0.2678284 , -0.63736314,  0.12389827],\n",
            "       [-2.2133865 ,  0.5967055 , -0.33389652, -1.1176476 ],\n",
            "       [-0.7469313 ,  0.6636117 ,  0.05396366, -1.5474021 ],\n",
            "       [-1.8946857 ,  0.4381711 ,  0.8261407 , -2.458208  ]],\n",
            "      dtype=float32), array([[-96.04717   ,  -1.543431  ],\n",
            "       [ 79.58416   ,  -0.9135196 ],\n",
            "       [-26.802177  ,  -1.8926826 ],\n",
            "       [-28.671398  ,   0.11834335]], dtype=float32), array([[-3.3123457],\n",
            "       [ 3.3650718]], dtype=float32)]\n",
            "Epoch 1/10\n",
            "33/33 [==============================] - 0s 1ms/step - loss: 0.3507 - accuracy: 0.9475\n",
            "Epoch 2/10\n",
            "33/33 [==============================] - 0s 1ms/step - loss: 0.3380 - accuracy: 0.9514\n",
            "Epoch 3/10\n",
            "33/33 [==============================] - 0s 1ms/step - loss: 0.3269 - accuracy: 0.9524\n",
            "Epoch 4/10\n",
            "33/33 [==============================] - 0s 1ms/step - loss: 0.3172 - accuracy: 0.9553\n",
            "Epoch 5/10\n",
            "33/33 [==============================] - 0s 1ms/step - loss: 0.3082 - accuracy: 0.9572\n",
            "Epoch 6/10\n",
            "33/33 [==============================] - 0s 1ms/step - loss: 0.2996 - accuracy: 0.9582\n",
            "Epoch 7/10\n",
            "33/33 [==============================] - 0s 1ms/step - loss: 0.2912 - accuracy: 0.9582\n",
            "Epoch 8/10\n",
            "33/33 [==============================] - 0s 1ms/step - loss: 0.2829 - accuracy: 0.9582\n",
            "Epoch 9/10\n",
            "33/33 [==============================] - 0s 1ms/step - loss: 0.2752 - accuracy: 0.9592\n",
            "Epoch 10/10\n",
            "33/33 [==============================] - 0s 1ms/step - loss: 0.2678 - accuracy: 0.9592\n",
            "Test Accuracy: 0.94\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}