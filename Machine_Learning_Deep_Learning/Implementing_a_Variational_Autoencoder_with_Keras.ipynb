{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOgeqzigA5+bzd/fHAFmaGe"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[Reference](https://medium.com/h7w/implementing-a-variational-autoencoder-with-keras-e19d7140ad90)"
      ],
      "metadata": {
        "id": "90TDnwrWyQFq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "  Variational Autoencoder (VAE) with the Keras Functional API.\n",
        "'''\n",
        "\n",
        "import keras\n",
        "from keras.layers import Conv2D, Conv2DTranspose, Input, Flatten, Dense, Lambda, Reshape\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.models import Model\n",
        "from keras.datasets import mnist\n",
        "from keras.losses import binary_crossentropy\n",
        "from keras import backend as K\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load MNIST dataset\n",
        "(input_train, target_train), (input_test, target_test) = mnist.load_data()\n",
        "\n",
        "# Data & model configuration\n",
        "img_width, img_height = input_train.shape[1], input_train.shape[2]\n",
        "batch_size = 128\n",
        "no_epochs = 100\n",
        "validation_split = 0.2\n",
        "verbosity = 1\n",
        "latent_dim = 2\n",
        "num_channels = 1\n",
        "\n",
        "# Reshape data\n",
        "input_train = input_train.reshape(input_train.shape[0], img_height, img_width, num_channels)\n",
        "input_test = input_test.reshape(input_test.shape[0], img_height, img_width, num_channels)\n",
        "input_shape = (img_height, img_width, num_channels)\n",
        "\n",
        "# Parse numbers as floats\n",
        "input_train = input_train.astype('float32')\n",
        "input_test = input_test.astype('float32')\n",
        "\n",
        "# Normalize data\n",
        "input_train = input_train / 255\n",
        "input_test = input_test / 255\n",
        "\n",
        "# # =================\n",
        "# # Encoder\n",
        "# # =================\n",
        "\n",
        "# Definition\n",
        "i       = Input(shape=input_shape, name='encoder_input')\n",
        "cx      = Conv2D(filters=8, kernel_size=3, strides=2, padding='same', activation='relu')(i)\n",
        "cx      = BatchNormalization()(cx)\n",
        "cx      = Conv2D(filters=16, kernel_size=3, strides=2, padding='same', activation='relu')(cx)\n",
        "cx      = BatchNormalization()(cx)\n",
        "x       = Flatten()(cx)\n",
        "x       = Dense(20, activation='relu')(x)\n",
        "x       = BatchNormalization()(x)\n",
        "mu      = Dense(latent_dim, name='latent_mu')(x)\n",
        "sigma   = Dense(latent_dim, name='latent_sigma')(x)\n",
        "\n",
        "# Get Conv2D shape for Conv2DTranspose operation in decoder\n",
        "conv_shape = K.int_shape(cx)\n",
        "\n",
        "# Define sampling with reparameterization trick\n",
        "def sample_z(args):\n",
        "  mu, sigma = args\n",
        "  batch     = K.shape(mu)[0]\n",
        "  dim       = K.int_shape(mu)[1]\n",
        "  eps       = K.random_normal(shape=(batch, dim))\n",
        "  return mu + K.exp(sigma / 2) * eps\n",
        "\n",
        "# Use reparameterization trick to ....??\n",
        "z       = Lambda(sample_z, output_shape=(latent_dim, ), name='z')([mu, sigma])\n",
        "\n",
        "# Instantiate encoder\n",
        "encoder = Model(i, [mu, sigma, z], name='encoder')\n",
        "encoder.summary()\n",
        "\n",
        "# =================\n",
        "# Decoder\n",
        "# =================\n",
        "\n",
        "# Definition\n",
        "d_i   = Input(shape=(latent_dim, ), name='decoder_input')\n",
        "x     = Dense(conv_shape[1] * conv_shape[2] * conv_shape[3], activation='relu')(d_i)\n",
        "x     = BatchNormalization()(x)\n",
        "x     = Reshape((conv_shape[1], conv_shape[2], conv_shape[3]))(x)\n",
        "cx    = Conv2DTranspose(filters=16, kernel_size=3, strides=2, padding='same', activation='relu')(x)\n",
        "cx    = BatchNormalization()(cx)\n",
        "cx    = Conv2DTranspose(filters=8, kernel_size=3, strides=2, padding='same',  activation='relu')(cx)\n",
        "cx    = BatchNormalization()(cx)\n",
        "o     = Conv2DTranspose(filters=num_channels, kernel_size=3, activation='sigmoid', padding='same', name='decoder_output')(cx)\n",
        "\n",
        "# Instantiate decoder\n",
        "decoder = Model(d_i, o, name='decoder')\n",
        "decoder.summary()\n",
        "\n",
        "# =================\n",
        "# VAE as a whole\n",
        "# =================\n",
        "\n",
        "# Instantiate VAE\n",
        "vae_outputs = decoder(encoder(i)[2])\n",
        "vae         = Model(i, vae_outputs, name='vae')\n",
        "vae.summary()\n",
        "\n",
        "# Define loss\n",
        "def kl_reconstruction_loss(true, pred):\n",
        "  # Reconstruction loss\n",
        "  reconstruction_loss = binary_crossentropy(K.flatten(true), K.flatten(pred)) * img_width * img_height\n",
        "  # KL divergence loss\n",
        "  kl_loss = 1 + sigma - K.square(mu) - K.exp(sigma)\n",
        "  kl_loss = K.sum(kl_loss, axis=-1)\n",
        "  kl_loss *= -0.5\n",
        "  # Total loss = 50% rec + 50% KL divergence loss\n",
        "  return K.mean(reconstruction_loss + kl_loss)\n",
        "\n",
        "# Compile VAE\n",
        "vae.compile(optimizer='adam', loss=kl_reconstruction_loss)\n",
        "\n",
        "# Train autoencoder\n",
        "vae.fit(input_train, input_train, epochs = no_epochs, batch_size = batch_size, validation_split = validation_split)\n",
        "\n",
        "# =================\n",
        "# Results visualization\n",
        "# Credits for original visualization code: https://keras.io/examples/variational_autoencoder_deconv/\n",
        "# (Fran√ßois Chollet).\n",
        "# Adapted to accomodate this VAE.\n",
        "# =================\n",
        "def viz_latent_space(encoder, data):\n",
        "  input_data, target_data = data\n",
        "  mu, _, _ = encoder.predict(input_data)\n",
        "  plt.figure(figsize=(8, 10))\n",
        "  plt.scatter(mu[:, 0], mu[:, 1], c=target_data)\n",
        "  plt.xlabel('z - dim 1')\n",
        "  plt.ylabel('z - dim 2')\n",
        "  plt.colorbar()\n",
        "  plt.show()\n",
        "\n",
        "def viz_decoded(encoder, decoder, data):\n",
        "  num_samples = 15\n",
        "  figure = np.zeros((img_width * num_samples, img_height * num_samples, num_channels))\n",
        "  grid_x = np.linspace(-4, 4, num_samples)\n",
        "  grid_y = np.linspace(-4, 4, num_samples)[::-1]\n",
        "  for i, yi in enumerate(grid_y):\n",
        "      for j, xi in enumerate(grid_x):\n",
        "          z_sample = np.array([[xi, yi]])\n",
        "          x_decoded = decoder.predict(z_sample)\n",
        "          digit = x_decoded[0].reshape(img_width, img_height, num_channels)\n",
        "          figure[i * img_width: (i + 1) * img_width,\n",
        "                  j * img_height: (j + 1) * img_height] = digit\n",
        "  plt.figure(figsize=(10, 10))\n",
        "  start_range = img_width // 2\n",
        "  end_range = num_samples * img_width + start_range + 1\n",
        "  pixel_range = np.arange(start_range, end_range, img_width)\n",
        "  sample_range_x = np.round(grid_x, 1)\n",
        "  sample_range_y = np.round(grid_y, 1)\n",
        "  plt.xticks(pixel_range, sample_range_x)\n",
        "  plt.yticks(pixel_range, sample_range_y)\n",
        "  plt.xlabel('z - dim 1')\n",
        "  plt.ylabel('z - dim 2')\n",
        "  # matplotlib.pyplot.imshow() needs a 2D array, or a 3D array with the third dimension being of shape 3 or 4!\n",
        "  # So reshape if necessary\n",
        "  fig_shape = np.shape(figure)\n",
        "  if fig_shape[2] == 1:\n",
        "    figure = figure.reshape((fig_shape[0], fig_shape[1]))\n",
        "  # Show image\n",
        "  plt.imshow(figure)\n",
        "  plt.show()\n",
        "\n",
        "# Plot results\n",
        "data = (input_test, target_test)\n",
        "viz_latent_space(encoder, data)\n",
        "viz_decoded(encoder, decoder, data)"
      ],
      "metadata": {
        "id": "rwbPr-Ze1OXl"
      },
      "execution_count": 1,
      "outputs": []
    }
  ]
}
