{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transfer Learning for Image Classification using Keras.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOWqE+lAaG7QRUvEwTLls8D"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nUhT8MOAbvOb"
      },
      "source": [
        "[Reference](https://towardsdatascience.com/transfer-learning-for-image-classification-using-keras-c47ccf09c8c8)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ldFB-2r5bmrn",
        "outputId": "639c166b-4de1-4586-b122-b1103df63c65"
      },
      "source": [
        "from keras.applications.resnet50 import ResNet50, preprocess_input\n",
        "\n",
        "HEIGHT = 300\n",
        "WIDTH = 300\n",
        "\n",
        "base_model = ResNet50(weights='imagenet', \n",
        "                      include_top=False, \n",
        "                      input_shape=(HEIGHT, WIDTH, 3))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94773248/94765736 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2oldLTZbyXU"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "TRAIN_DIR = \"food_dataset\"\n",
        "HEIGHT = 300\n",
        "WIDTH = 300\n",
        "BATCH_SIZE = 8\n",
        "\n",
        "train_datagen =  ImageDataGenerator(\n",
        "      preprocessing_function=preprocess_input,\n",
        "      rotation_range=90,\n",
        "      horizontal_flip=True,\n",
        "      vertical_flip=True\n",
        "    )\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(TRAIN_DIR, \n",
        "                                                    target_size=(HEIGHT, WIDTH), \n",
        "                                                    batch_size=BATCH_SIZE)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_IS769bcbzzw"
      },
      "source": [
        "from keras.layers import Dense, Activation, Flatten, Dropout\n",
        "from keras.models import Sequential, Model\n",
        "\n",
        "def build_finetune_model(base_model, dropout, fc_layers, num_classes):\n",
        "    for layer in base_model.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    x = base_model.output\n",
        "    x = Flatten()(x)\n",
        "    for fc in fc_layers:\n",
        "        # New FC layer, random init\n",
        "        x = Dense(fc, activation='relu')(x) \n",
        "        x = Dropout(dropout)(x)\n",
        "\n",
        "    # New softmax layer\n",
        "    predictions = Dense(num_classes, activation='softmax')(x) \n",
        "    \n",
        "    finetune_model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "    return finetune_model\n",
        "\n",
        "class_list = [\"Pizza\", \"Burger\", \"Taco\"]\n",
        "FC_LAYERS = [1024, 1024]\n",
        "dropout = 0.5\n",
        "\n",
        "finetune_model = build_finetune_model(base_model, \n",
        "                                      dropout=dropout, \n",
        "                                      fc_layers=FC_LAYERS, \n",
        "                                      num_classes=len(class_list))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDKtSo0Eb38b"
      },
      "source": [
        "from keras.optimizers import SGD, Adam\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "NUM_EPOCHS = 10\n",
        "BATCH_SIZE = 8\n",
        "num_train_images = 10000\n",
        "\n",
        "adam = Adam(lr=0.00001)\n",
        "finetune_model.compile(adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "filepath=\"./checkpoints/\" + \"ResNet50\" + \"_model_weights.h5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor=[\"acc\"], verbose=1, mode='max')\n",
        "callbacks_list = [checkpoint]\n",
        "\n",
        "history = finetune_model.fit_generator(train_generator, epochs=NUM_EPOCHS, workers=8, \n",
        "                                       steps_per_epoch=num_train_images // BATCH_SIZE, \n",
        "                                       shuffle=True, callbacks=callbacks_list)\n",
        "\n",
        "\n",
        "plot_training(history)\n",
        "\n",
        "# Plot the training and validation loss + accuracy\n",
        "def plot_training(history):\n",
        "    acc = history.history['acc']\n",
        "    val_acc = history.history['val_acc']\n",
        "    loss = history.history['loss']\n",
        "    val_loss = history.history['val_loss']\n",
        "    epochs = range(len(acc))\n",
        "\n",
        "    plt.plot(epochs, acc, 'r.')\n",
        "    plt.plot(epochs, val_acc, 'r')\n",
        "    plt.title('Training and validation accuracy')\n",
        "\n",
        "    # plt.figure()\n",
        "    # plt.plot(epochs, loss, 'r.')\n",
        "    # plt.plot(epochs, val_loss, 'r-')\n",
        "    # plt.title('Training and validation loss')\n",
        "    plt.show()\n",
        "\n",
        "    plt.savefig('acc_vs_epochs.png')"
      ],
      "execution_count": 5,
      "outputs": []
    }
  ]
}