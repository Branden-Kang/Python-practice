{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Image Classification on 3 Datasets using Convolutional Neural Networks.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPQA+onmeiOAta1UgdhhZBb"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yHOGPJMYDy3n",
        "colab_type": "text"
      },
      "source": [
        "[Reference](https://medium.com/analytics-vidhya/learn-image-classification-on-3-datasets-using-convolutional-neural-networks-cnn-e457d259a2b2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0xBOZYqD1jG",
        "colab_type": "text"
      },
      "source": [
        "# MNIST Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zg-Fp7spETOF",
        "colab_type": "text"
      },
      "source": [
        "## NN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mYPMZ56dD_WL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Conv2D, MaxPool2D\n",
        "from keras.utils import np_utils"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oKQLJ552DwmY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "1b080dc8-e44f-4fb1-bf95-4a5b8d34f245"
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data() # let's print the shape of the dataset\n",
        "print(\"X_train shape\", X_train.shape) \n",
        "print(\"y_train shape\", y_train.shape) \n",
        "print(\"X_test shape\", X_test.shape) \n",
        "print(\"y_test shape\", y_test.shape)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "X_train shape (60000, 28, 28)\n",
            "y_train shape (60000,)\n",
            "X_test shape (10000, 28, 28)\n",
            "y_test shape (10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_e99uRID253",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Flattening the images from the 28x28 pixels to 1D 787 pixels\n",
        "X_train = X_train.reshape(60000, 784)\n",
        "X_test = X_test.reshape(10000, 784)\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cefce3b8D4lT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# normalizing the data to help with the training\n",
        "X_train /= 255\n",
        "X_test /= 255"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKLUuIN1D6wU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "4ae97563-69f2-4f95-9148-cf089d9667b7"
      },
      "source": [
        "# one-hot encoding using keras' numpy-related utilities\n",
        "n_classes = 10\n",
        "print(\"Shape before one-hot encoding: \", y_train.shape)\n",
        "Y_train = np_utils.to_categorical(y_train, n_classes)\n",
        "Y_test = np_utils.to_categorical(y_test, n_classes)\n",
        "print(\"Shape after one-hot encoding: \", Y_train.shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape before one-hot encoding:  (60000,)\n",
            "Shape after one-hot encoding:  (60000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0gIIjigAD812",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# building a linear stack of layers with the sequential model\n",
        "model = Sequential()\n",
        "# hidden layer\n",
        "model.add(Dense(100, input_shape=(784,), activation='relu'))\n",
        "# output layer\n",
        "model.add(Dense(10, activation='softmax'))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3HuEAysEDDz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        },
        "outputId": "691be792-f229-4442-af58-665274d7c57d"
      },
      "source": [
        "# looking at the model summary\n",
        "model.summary()\n",
        "# compiling the sequential model\n",
        "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
        "# training the model for 10 epochs\n",
        "model.fit(X_train, Y_train, batch_size=128, epochs=10, validation_data=(X_test, Y_test))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 100)               78500     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                1010      \n",
            "=================================================================\n",
            "Total params: 79,510\n",
            "Trainable params: 79,510\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3779 - accuracy: 0.8968 - val_loss: 0.1976 - val_accuracy: 0.9430\n",
            "Epoch 2/10\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1729 - accuracy: 0.9502 - val_loss: 0.1460 - val_accuracy: 0.9574\n",
            "Epoch 3/10\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1259 - accuracy: 0.9636 - val_loss: 0.1229 - val_accuracy: 0.9621\n",
            "Epoch 4/10\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0997 - accuracy: 0.9712 - val_loss: 0.1059 - val_accuracy: 0.9675\n",
            "Epoch 5/10\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0809 - accuracy: 0.9765 - val_loss: 0.0968 - val_accuracy: 0.9709\n",
            "Epoch 6/10\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0671 - accuracy: 0.9812 - val_loss: 0.0906 - val_accuracy: 0.9730\n",
            "Epoch 7/10\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0579 - accuracy: 0.9837 - val_loss: 0.0863 - val_accuracy: 0.9725\n",
            "Epoch 8/10\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0498 - accuracy: 0.9859 - val_loss: 0.0810 - val_accuracy: 0.9747\n",
            "Epoch 9/10\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0425 - accuracy: 0.9881 - val_loss: 0.0784 - val_accuracy: 0.9758\n",
            "Epoch 10/10\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0373 - accuracy: 0.9897 - val_loss: 0.0819 - val_accuracy: 0.9754\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f9101120668>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1L5T-Y-NEQ_G",
        "colab_type": "text"
      },
      "source": [
        "## CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIidXyMgEEuq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "88dcac16-d706-4e30-9552-c3142c682cfc"
      },
      "source": [
        "# keras imports for the dataset and building our neural network\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Conv2D, MaxPool2D, Flatten\n",
        "from keras.utils import np_utils\n",
        "\n",
        "# to calculate accuracy\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# loading the dataset\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "# building the input vector from the 28x28 pixels\n",
        "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "\n",
        "# normalizing the data to help with the training\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "\n",
        "# one-hot encoding using keras' numpy-related utilities\n",
        "n_classes = 10\n",
        "print(\"Shape before one-hot encoding: \", y_train.shape)\n",
        "Y_train = np_utils.to_categorical(y_train, n_classes)\n",
        "Y_test = np_utils.to_categorical(y_test, n_classes)\n",
        "print(\"Shape after one-hot encoding: \", Y_train.shape)\n",
        "\n",
        "# building a linear stack of layers with the sequential model\n",
        "model = Sequential()\n",
        "# convolutional layer\n",
        "model.add(Conv2D(25, kernel_size=(3,3), strides=(1,1), padding='valid', activation='relu', input_shape=(28,28,1)))\n",
        "model.add(MaxPool2D(pool_size=(1,1)))\n",
        "# flatten output of conv\n",
        "model.add(Flatten())\n",
        "# hidden layer\n",
        "model.add(Dense(100, activation='relu'))\n",
        "# output layer\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# compiling the sequential model\n",
        "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
        "\n",
        "# training the model for 10 epochs\n",
        "model.fit(X_train, Y_train, batch_size=128, epochs=10, validation_data=(X_test, Y_test))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape before one-hot encoding:  (60000,)\n",
            "Shape after one-hot encoding:  (60000, 10)\n",
            "Epoch 1/10\n",
            "469/469 [==============================] - 40s 84ms/step - loss: 0.1846 - accuracy: 0.9459 - val_loss: 0.0680 - val_accuracy: 0.9797\n",
            "Epoch 2/10\n",
            "469/469 [==============================] - 39s 84ms/step - loss: 0.0570 - accuracy: 0.9829 - val_loss: 0.0633 - val_accuracy: 0.9797\n",
            "Epoch 3/10\n",
            "469/469 [==============================] - 39s 84ms/step - loss: 0.0347 - accuracy: 0.9894 - val_loss: 0.0594 - val_accuracy: 0.9806\n",
            "Epoch 4/10\n",
            "469/469 [==============================] - 39s 83ms/step - loss: 0.0228 - accuracy: 0.9931 - val_loss: 0.0544 - val_accuracy: 0.9827\n",
            "Epoch 5/10\n",
            "469/469 [==============================] - 39s 83ms/step - loss: 0.0145 - accuracy: 0.9959 - val_loss: 0.0499 - val_accuracy: 0.9847\n",
            "Epoch 6/10\n",
            "469/469 [==============================] - 39s 84ms/step - loss: 0.0106 - accuracy: 0.9970 - val_loss: 0.0552 - val_accuracy: 0.9839\n",
            "Epoch 7/10\n",
            "469/469 [==============================] - 39s 84ms/step - loss: 0.0067 - accuracy: 0.9983 - val_loss: 0.0506 - val_accuracy: 0.9855\n",
            "Epoch 8/10\n",
            "469/469 [==============================] - 39s 84ms/step - loss: 0.0060 - accuracy: 0.9982 - val_loss: 0.0569 - val_accuracy: 0.9836\n",
            "Epoch 9/10\n",
            "469/469 [==============================] - 40s 84ms/step - loss: 0.0052 - accuracy: 0.9982 - val_loss: 0.0693 - val_accuracy: 0.9832\n",
            "Epoch 10/10\n",
            "469/469 [==============================] - 39s 84ms/step - loss: 0.0052 - accuracy: 0.9984 - val_loss: 0.0615 - val_accuracy: 0.9847\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f90f5f0e668>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gEHOiYYwEdVO",
        "colab_type": "text"
      },
      "source": [
        "# CIFAR-10 Dataset "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38MScUvKESIy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "2605e959-2ab5-422b-9985-f0b3a22b1586"
      },
      "source": [
        "from keras.datasets import cifar10 # loading the dataset \n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 3s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsW16WtVEhIZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "8aae9ab6-ea5e-42ff-baeb-a693287a6d3b"
      },
      "source": [
        "# keras imports for the dataset and building our neural network\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Conv2D, MaxPool2D, Flatten\n",
        "from keras.utils import np_utils\n",
        "\n",
        "# loading the dataset\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# # building the input vector from the 32x32 pixels\n",
        "X_train = X_train.reshape(X_train.shape[0], 32, 32, 3)\n",
        "X_test = X_test.reshape(X_test.shape[0], 32, 32, 3)\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "\n",
        "# normalizing the data to help with the training\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "\n",
        "# one-hot encoding using keras' numpy-related utilities\n",
        "n_classes = 10\n",
        "print(\"Shape before one-hot encoding: \", y_train.shape)\n",
        "Y_train = np_utils.to_categorical(y_train, n_classes)\n",
        "Y_test = np_utils.to_categorical(y_test, n_classes)\n",
        "print(\"Shape after one-hot encoding: \", Y_train.shape)\n",
        "\n",
        "# building a linear stack of layers with the sequential model\n",
        "model = Sequential()\n",
        "\n",
        "# convolutional layer\n",
        "model.add(Conv2D(50, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu', input_shape=(32, 32, 3)))\n",
        "\n",
        "# convolutional layer\n",
        "model.add(Conv2D(75, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu'))\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(125, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu'))\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# flatten output of conv\n",
        "model.add(Flatten())\n",
        "\n",
        "# hidden layer\n",
        "model.add(Dense(500, activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(250, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "# output layer\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# compiling the sequential model\n",
        "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
        "\n",
        "# training the model for 10 epochs\n",
        "model.fit(X_train, Y_train, batch_size=128, epochs=10, validation_data=(X_test, Y_test))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape before one-hot encoding:  (50000, 1)\n",
            "Shape after one-hot encoding:  (50000, 10)\n",
            "Epoch 1/10\n",
            "391/391 [==============================] - 562s 1s/step - loss: 1.5839 - accuracy: 0.4197 - val_loss: 1.2157 - val_accuracy: 0.5614\n",
            "Epoch 2/10\n",
            "391/391 [==============================] - 567s 1s/step - loss: 1.1094 - accuracy: 0.6063 - val_loss: 0.9060 - val_accuracy: 0.6827\n",
            "Epoch 3/10\n",
            "391/391 [==============================] - 565s 1s/step - loss: 0.9228 - accuracy: 0.6774 - val_loss: 0.8510 - val_accuracy: 0.7063\n",
            "Epoch 4/10\n",
            "391/391 [==============================] - 566s 1s/step - loss: 0.8066 - accuracy: 0.7189 - val_loss: 0.7561 - val_accuracy: 0.7388\n",
            "Epoch 5/10\n",
            "391/391 [==============================] - 566s 1s/step - loss: 0.7245 - accuracy: 0.7488 - val_loss: 0.7291 - val_accuracy: 0.7483\n",
            "Epoch 6/10\n",
            "391/391 [==============================] - 574s 1s/step - loss: 0.6535 - accuracy: 0.7729 - val_loss: 0.6812 - val_accuracy: 0.7662\n",
            "Epoch 7/10\n",
            "391/391 [==============================] - 568s 1s/step - loss: 0.6008 - accuracy: 0.7905 - val_loss: 0.6856 - val_accuracy: 0.7651\n",
            "Epoch 8/10\n",
            "391/391 [==============================] - 564s 1s/step - loss: 0.5442 - accuracy: 0.8086 - val_loss: 0.6601 - val_accuracy: 0.7719\n",
            "Epoch 9/10\n",
            "391/391 [==============================] - 569s 1s/step - loss: 0.5066 - accuracy: 0.8250 - val_loss: 0.6684 - val_accuracy: 0.7767\n",
            "Epoch 10/10\n",
            "391/391 [==============================] - 562s 1s/step - loss: 0.4668 - accuracy: 0.8364 - val_loss: 0.6462 - val_accuracy: 0.7825\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f90f4702630>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6x_DO5GcEuci",
        "colab_type": "text"
      },
      "source": [
        "# ImageNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2T0yyBXEos_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "c08141de-1e91-4307-de19-64ea2f70e658"
      },
      "source": [
        "!wget https://s3.amazonaws.com/fast-ai-imageclas/imagenette2.tgz \n",
        "!tar -xf imagenette2.tgz"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-09-08 15:55:33--  https://s3.amazonaws.com/fast-ai-imageclas/imagenette2.tgz\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.29.214\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.29.214|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1556914727 (1.4G) [application/x-tar]\n",
            "Saving to: ‘imagenette2.tgz’\n",
            "\n",
            "imagenette2.tgz     100%[===================>]   1.45G  89.0MB/s    in 20s     \n",
            "\n",
            "2020-09-08 15:55:54 (72.7 MB/s) - ‘imagenette2.tgz’ saved [1556914727/1556914727]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ix6f8M3uE2WE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "38cb2924-97ec-4d0c-ee08-6f91a166c53e"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# create a new generator\n",
        "imagegen = ImageDataGenerator()\n",
        "# load train data\n",
        "train = imagegen.flow_from_directory(\"imagenette2/train/\", class_mode=\"categorical\", shuffle=False, batch_size=128, target_size=(224, 224))\n",
        "# load val data\n",
        "val = imagegen.flow_from_directory(\"imagenette2/val/\", class_mode=\"categorical\", shuffle=False, batch_size=128, target_size=(224, 224))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 9469 images belonging to 10 classes.\n",
            "Found 3925 images belonging to 10 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-VluDdpE2rs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f76bec9b-9c8a-4f4a-fc45-b57cc4eef688"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPool2D, Flatten, Dense, InputLayer, BatchNormalization, Dropout\n",
        "\n",
        "# build a sequential model\n",
        "model = Sequential()\n",
        "model.add(InputLayer(input_shape=(224, 224, 3)))\n",
        "\n",
        "# 1st conv block\n",
        "model.add(Conv2D(25, (5, 5), activation='relu', strides=(1, 1), padding='same'))\n",
        "model.add(MaxPool2D(pool_size=(2, 2), padding='same'))\n",
        "# 2nd conv block\n",
        "model.add(Conv2D(50, (5, 5), activation='relu', strides=(2, 2), padding='same'))\n",
        "model.add(MaxPool2D(pool_size=(2, 2), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "# 3rd conv block\n",
        "model.add(Conv2D(70, (3, 3), activation='relu', strides=(2, 2), padding='same'))\n",
        "model.add(MaxPool2D(pool_size=(2, 2), padding='valid'))\n",
        "model.add(BatchNormalization())\n",
        "# ANN block\n",
        "model.add(Flatten())\n",
        "model.add(Dense(units=100, activation='relu'))\n",
        "model.add(Dense(units=100, activation='relu'))\n",
        "model.add(Dropout(0.25))\n",
        "# output layer\n",
        "model.add(Dense(units=10, activation='softmax'))\n",
        "\n",
        "# compile model\n",
        "model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n",
        "# fit on data for 30 epochs\n",
        "model.fit_generator(train, epochs=30, validation_data=val)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-14-5d5be64feff7>:30: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.fit, which supports generators.\n",
            "Epoch 1/30\n",
            "74/74 [==============================] - 703s 10s/step - loss: 2.6300 - accuracy: 0.1470 - val_loss: 2.5502 - val_accuracy: 0.1282\n",
            "Epoch 2/30\n",
            "74/74 [==============================] - 703s 10s/step - loss: 2.2079 - accuracy: 0.2177 - val_loss: 3.4608 - val_accuracy: 0.1434\n",
            "Epoch 3/30\n",
            "74/74 [==============================] - 699s 9s/step - loss: 2.0281 - accuracy: 0.3050 - val_loss: 2.0053 - val_accuracy: 0.3276\n",
            "Epoch 4/30\n",
            "74/74 [==============================] - 698s 9s/step - loss: 1.7595 - accuracy: 0.4085 - val_loss: 2.0120 - val_accuracy: 0.3279\n",
            "Epoch 5/30\n",
            "74/74 [==============================] - 693s 9s/step - loss: 1.5342 - accuracy: 0.4820 - val_loss: 1.7669 - val_accuracy: 0.4237\n",
            "Epoch 6/30\n",
            "74/74 [==============================] - 692s 9s/step - loss: 1.2852 - accuracy: 0.5726 - val_loss: 1.7539 - val_accuracy: 0.4166\n",
            "Epoch 7/30\n",
            "74/74 [==============================] - 692s 9s/step - loss: 1.0810 - accuracy: 0.6349 - val_loss: 1.9204 - val_accuracy: 0.3964\n",
            "Epoch 8/30\n",
            "74/74 [==============================] - 694s 9s/step - loss: 0.9214 - accuracy: 0.6963 - val_loss: 1.8759 - val_accuracy: 0.4290\n",
            "Epoch 9/30\n",
            "74/74 [==============================] - 690s 9s/step - loss: 0.7057 - accuracy: 0.7629 - val_loss: 2.1652 - val_accuracy: 0.3671\n",
            "Epoch 10/30\n",
            "74/74 [==============================] - 692s 9s/step - loss: 0.6689 - accuracy: 0.7808 - val_loss: 2.0379 - val_accuracy: 0.4245\n",
            "Epoch 11/30\n",
            "74/74 [==============================] - 691s 9s/step - loss: 0.4892 - accuracy: 0.8442 - val_loss: 2.4600 - val_accuracy: 0.3827\n",
            "Epoch 12/30\n",
            "74/74 [==============================] - 691s 9s/step - loss: 0.3965 - accuracy: 0.8756 - val_loss: 2.4296 - val_accuracy: 0.4163\n",
            "Epoch 13/30\n",
            "74/74 [==============================] - 692s 9s/step - loss: 0.2775 - accuracy: 0.9107 - val_loss: 2.4250 - val_accuracy: 0.4237\n",
            "Epoch 14/30\n",
            "74/74 [==============================] - 689s 9s/step - loss: 0.2289 - accuracy: 0.9271 - val_loss: 2.4921 - val_accuracy: 0.4502\n",
            "Epoch 15/30\n",
            "74/74 [==============================] - 690s 9s/step - loss: 0.1888 - accuracy: 0.9394 - val_loss: 2.6114 - val_accuracy: 0.4232\n",
            "Epoch 16/30\n",
            "74/74 [==============================] - 688s 9s/step - loss: 0.1666 - accuracy: 0.9467 - val_loss: 2.5004 - val_accuracy: 0.4403\n",
            "Epoch 17/30\n",
            "74/74 [==============================] - 689s 9s/step - loss: 0.0857 - accuracy: 0.9774 - val_loss: 2.4859 - val_accuracy: 0.4563\n",
            "Epoch 18/30\n",
            "74/74 [==============================] - 688s 9s/step - loss: 0.0773 - accuracy: 0.9773 - val_loss: 2.4106 - val_accuracy: 0.4497\n",
            "Epoch 19/30\n",
            "74/74 [==============================] - 688s 9s/step - loss: 0.0523 - accuracy: 0.9861 - val_loss: 2.6586 - val_accuracy: 0.4550\n",
            "Epoch 20/30\n",
            "74/74 [==============================] - 689s 9s/step - loss: 0.0371 - accuracy: 0.9910 - val_loss: 2.6507 - val_accuracy: 0.4566\n",
            "Epoch 21/30\n",
            "74/74 [==============================] - 691s 9s/step - loss: 0.0322 - accuracy: 0.9910 - val_loss: 2.8590 - val_accuracy: 0.4499\n",
            "Epoch 22/30\n",
            "74/74 [==============================] - 688s 9s/step - loss: 0.0272 - accuracy: 0.9938 - val_loss: 2.8161 - val_accuracy: 0.4372\n",
            "Epoch 23/30\n",
            "74/74 [==============================] - 689s 9s/step - loss: 0.0457 - accuracy: 0.9873 - val_loss: 3.2202 - val_accuracy: 0.4176\n",
            "Epoch 24/30\n",
            "74/74 [==============================] - 688s 9s/step - loss: 0.0413 - accuracy: 0.9875 - val_loss: 3.5729 - val_accuracy: 0.3941\n",
            "Epoch 25/30\n",
            "74/74 [==============================] - 686s 9s/step - loss: 0.0473 - accuracy: 0.9857 - val_loss: 2.9477 - val_accuracy: 0.4171\n",
            "Epoch 26/30\n",
            "74/74 [==============================] - 687s 9s/step - loss: 0.0643 - accuracy: 0.9811 - val_loss: 3.0044 - val_accuracy: 0.4380\n",
            "Epoch 27/30\n",
            "74/74 [==============================] - 690s 9s/step - loss: 0.1415 - accuracy: 0.9613 - val_loss: 5.4480 - val_accuracy: 0.2716\n",
            "Epoch 28/30\n",
            "74/74 [==============================] - 688s 9s/step - loss: 0.7329 - accuracy: 0.7906 - val_loss: 3.0028 - val_accuracy: 0.3811\n",
            "Epoch 29/30\n",
            "74/74 [==============================] - 689s 9s/step - loss: 0.1368 - accuracy: 0.9586 - val_loss: 2.6043 - val_accuracy: 0.4395\n",
            "Epoch 30/30\n",
            "74/74 [==============================] - 690s 9s/step - loss: 0.0380 - accuracy: 0.9917 - val_loss: 2.4880 - val_accuracy: 0.4665\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f91005b4908>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xab0ZtzOE-qD",
        "colab_type": "text"
      },
      "source": [
        "# Using Transfer Learning (VGG16) to improve accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHTHEwXpE6JR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 833
        },
        "outputId": "48a52b42-a9ed-4ce4-cad6-06fa27de1da7"
      },
      "source": [
        "from keras.applications import VGG16 \n",
        "# include top should be False to remove the softmax layer \n",
        "pretrained_model = VGG16(include_top=False, weights='imagenet') \n",
        "pretrained_model.summary()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 0s 0us/step\n",
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, None, None, 3)]   0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, None, None, 64)    1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, None, None, 64)    36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, None, None, 64)    0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, None, None, 128)   73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, None, None, 128)   147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, None, None, 128)   0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, None, None, 256)   295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, None, None, 256)   590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, None, None, 256)   590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, None, None, 256)   0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, None, None, 512)   1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, None, None, 512)   2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 14,714,688\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IH-F750GFEv_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.utils import to_categorical \n",
        "# extract train and val features \n",
        "vgg_features_train = pretrained_model.predict(train) \n",
        "vgg_features_val = pretrained_model.predict(val)\n",
        "\n",
        "# OHE target column \n",
        "train_target = to_categorical(train.labels) \n",
        "val_target = to_categorical(val.labels)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pw7hOC9_FPC4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bbe14c3-707d-4005-c49d-00721c7dfb88"
      },
      "source": [
        "model2 = Sequential()\n",
        "model2.add(Flatten(input_shape=(7,7,512)))\n",
        "model2.add(Dense(100, activation='relu'))\n",
        "model2.add(Dropout(0.5))\n",
        "model2.add(BatchNormalization())\n",
        "model2.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# compile the model\n",
        "model2.compile(optimizer='adam', metrics=['accuracy'], loss='categorical_crossentropy')\n",
        "\n",
        "model2.summary()\n",
        "\n",
        "# train model using features generated from VGG16 model\n",
        "model2.fit(vgg_features_train, train_target, epochs=50, batch_size=128, validation_data=(vgg_features_val, val_target))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_3 (Flatten)          (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 100)               2508900   \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 100)               400       \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 10)                1010      \n",
            "=================================================================\n",
            "Total params: 2,510,310\n",
            "Trainable params: 2,510,110\n",
            "Non-trainable params: 200\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "74/74 [==============================] - 4s 54ms/step - loss: 0.4370 - accuracy: 0.8825 - val_loss: 0.1968 - val_accuracy: 0.9373\n",
            "Epoch 2/50\n",
            "74/74 [==============================] - 4s 51ms/step - loss: 0.1352 - accuracy: 0.9747 - val_loss: 0.1772 - val_accuracy: 0.9462\n",
            "Epoch 3/50\n",
            "74/74 [==============================] - 4s 51ms/step - loss: 0.0638 - accuracy: 0.9925 - val_loss: 0.1722 - val_accuracy: 0.9455\n",
            "Epoch 4/50\n",
            "74/74 [==============================] - 4s 52ms/step - loss: 0.0361 - accuracy: 0.9962 - val_loss: 0.1663 - val_accuracy: 0.9480\n",
            "Epoch 5/50\n",
            "74/74 [==============================] - 4s 53ms/step - loss: 0.0232 - accuracy: 0.9985 - val_loss: 0.1714 - val_accuracy: 0.9442\n",
            "Epoch 6/50\n",
            "74/74 [==============================] - 4s 53ms/step - loss: 0.0176 - accuracy: 0.9993 - val_loss: 0.1723 - val_accuracy: 0.9434\n",
            "Epoch 7/50\n",
            "74/74 [==============================] - 4s 52ms/step - loss: 0.0144 - accuracy: 0.9989 - val_loss: 0.1659 - val_accuracy: 0.9465\n",
            "Epoch 8/50\n",
            "74/74 [==============================] - 4s 51ms/step - loss: 0.0112 - accuracy: 0.9992 - val_loss: 0.1731 - val_accuracy: 0.9450\n",
            "Epoch 9/50\n",
            "74/74 [==============================] - 4s 51ms/step - loss: 0.0089 - accuracy: 0.9997 - val_loss: 0.1686 - val_accuracy: 0.9447\n",
            "Epoch 10/50\n",
            "74/74 [==============================] - 4s 52ms/step - loss: 0.0086 - accuracy: 0.9994 - val_loss: 0.1777 - val_accuracy: 0.9452\n",
            "Epoch 11/50\n",
            "74/74 [==============================] - 4s 52ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.1810 - val_accuracy: 0.9424\n",
            "Epoch 12/50\n",
            "74/74 [==============================] - 4s 52ms/step - loss: 0.0067 - accuracy: 0.9995 - val_loss: 0.1850 - val_accuracy: 0.9411\n",
            "Epoch 13/50\n",
            "74/74 [==============================] - 4s 52ms/step - loss: 0.0075 - accuracy: 0.9987 - val_loss: 0.1888 - val_accuracy: 0.9437\n",
            "Epoch 14/50\n",
            "74/74 [==============================] - 4s 52ms/step - loss: 0.0057 - accuracy: 0.9998 - val_loss: 0.1930 - val_accuracy: 0.9442\n",
            "Epoch 15/50\n",
            "74/74 [==============================] - 4s 52ms/step - loss: 0.0046 - accuracy: 0.9998 - val_loss: 0.1961 - val_accuracy: 0.9424\n",
            "Epoch 16/50\n",
            "74/74 [==============================] - 4s 51ms/step - loss: 0.0043 - accuracy: 0.9998 - val_loss: 0.1892 - val_accuracy: 0.9417\n",
            "Epoch 17/50\n",
            "74/74 [==============================] - 4s 51ms/step - loss: 0.0045 - accuracy: 0.9995 - val_loss: 0.1992 - val_accuracy: 0.9417\n",
            "Epoch 18/50\n",
            "74/74 [==============================] - 4s 51ms/step - loss: 0.0032 - accuracy: 0.9999 - val_loss: 0.1965 - val_accuracy: 0.9422\n",
            "Epoch 19/50\n",
            "74/74 [==============================] - 4s 51ms/step - loss: 0.0033 - accuracy: 0.9998 - val_loss: 0.1937 - val_accuracy: 0.9424\n",
            "Epoch 20/50\n",
            "74/74 [==============================] - 4s 51ms/step - loss: 0.0034 - accuracy: 0.9999 - val_loss: 0.1949 - val_accuracy: 0.9450\n",
            "Epoch 21/50\n",
            "74/74 [==============================] - 4s 51ms/step - loss: 0.0031 - accuracy: 0.9997 - val_loss: 0.2092 - val_accuracy: 0.9445\n",
            "Epoch 22/50\n",
            "74/74 [==============================] - 4s 52ms/step - loss: 0.0033 - accuracy: 0.9998 - val_loss: 0.2028 - val_accuracy: 0.9432\n",
            "Epoch 23/50\n",
            "74/74 [==============================] - 4s 52ms/step - loss: 0.0031 - accuracy: 0.9997 - val_loss: 0.2071 - val_accuracy: 0.9437\n",
            "Epoch 24/50\n",
            "74/74 [==============================] - 4s 51ms/step - loss: 0.0027 - accuracy: 0.9998 - val_loss: 0.2164 - val_accuracy: 0.9422\n",
            "Epoch 25/50\n",
            "74/74 [==============================] - 4s 51ms/step - loss: 0.0032 - accuracy: 0.9996 - val_loss: 0.2188 - val_accuracy: 0.9422\n",
            "Epoch 26/50\n",
            "74/74 [==============================] - 4s 51ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.2206 - val_accuracy: 0.9427\n",
            "Epoch 27/50\n",
            "74/74 [==============================] - 4s 51ms/step - loss: 0.0041 - accuracy: 0.9993 - val_loss: 0.2272 - val_accuracy: 0.9389\n",
            "Epoch 28/50\n",
            "74/74 [==============================] - 4s 52ms/step - loss: 0.0040 - accuracy: 0.9995 - val_loss: 0.2284 - val_accuracy: 0.9401\n",
            "Epoch 29/50\n",
            "74/74 [==============================] - 4s 51ms/step - loss: 0.0031 - accuracy: 0.9998 - val_loss: 0.2231 - val_accuracy: 0.9411\n",
            "Epoch 30/50\n",
            "74/74 [==============================] - 4s 52ms/step - loss: 0.0042 - accuracy: 0.9994 - val_loss: 0.2146 - val_accuracy: 0.9414\n",
            "Epoch 31/50\n",
            "74/74 [==============================] - 4s 51ms/step - loss: 0.0042 - accuracy: 0.9993 - val_loss: 0.2112 - val_accuracy: 0.9445\n",
            "Epoch 32/50\n",
            "74/74 [==============================] - 4s 52ms/step - loss: 0.0041 - accuracy: 0.9994 - val_loss: 0.2216 - val_accuracy: 0.9417\n",
            "Epoch 33/50\n",
            "74/74 [==============================] - 4s 51ms/step - loss: 0.0045 - accuracy: 0.9992 - val_loss: 0.2413 - val_accuracy: 0.9394\n",
            "Epoch 34/50\n",
            "74/74 [==============================] - 4s 52ms/step - loss: 0.0056 - accuracy: 0.9992 - val_loss: 0.2515 - val_accuracy: 0.9361\n",
            "Epoch 35/50\n",
            "74/74 [==============================] - 4s 52ms/step - loss: 0.0058 - accuracy: 0.9988 - val_loss: 0.2584 - val_accuracy: 0.9363\n",
            "Epoch 36/50\n",
            "74/74 [==============================] - 4s 52ms/step - loss: 0.0063 - accuracy: 0.9986 - val_loss: 0.2361 - val_accuracy: 0.9406\n",
            "Epoch 37/50\n",
            "74/74 [==============================] - 4s 51ms/step - loss: 0.0054 - accuracy: 0.9989 - val_loss: 0.2350 - val_accuracy: 0.9399\n",
            "Epoch 38/50\n",
            "74/74 [==============================] - 4s 51ms/step - loss: 0.0070 - accuracy: 0.9981 - val_loss: 0.2619 - val_accuracy: 0.9381\n",
            "Epoch 39/50\n",
            "74/74 [==============================] - 4s 52ms/step - loss: 0.0085 - accuracy: 0.9977 - val_loss: 0.2469 - val_accuracy: 0.9401\n",
            "Epoch 40/50\n",
            "74/74 [==============================] - 4s 52ms/step - loss: 0.0086 - accuracy: 0.9978 - val_loss: 0.2472 - val_accuracy: 0.9422\n",
            "Epoch 41/50\n",
            "74/74 [==============================] - 4s 52ms/step - loss: 0.0066 - accuracy: 0.9982 - val_loss: 0.2550 - val_accuracy: 0.9396\n",
            "Epoch 42/50\n",
            "74/74 [==============================] - 4s 51ms/step - loss: 0.0057 - accuracy: 0.9980 - val_loss: 0.2609 - val_accuracy: 0.9417\n",
            "Epoch 43/50\n",
            "74/74 [==============================] - 4s 52ms/step - loss: 0.0042 - accuracy: 0.9993 - val_loss: 0.2481 - val_accuracy: 0.9404\n",
            "Epoch 44/50\n",
            "74/74 [==============================] - 4s 51ms/step - loss: 0.0049 - accuracy: 0.9987 - val_loss: 0.2419 - val_accuracy: 0.9424\n",
            "Epoch 45/50\n",
            "74/74 [==============================] - 4s 52ms/step - loss: 0.0045 - accuracy: 0.9990 - val_loss: 0.2325 - val_accuracy: 0.9434\n",
            "Epoch 46/50\n",
            "74/74 [==============================] - 4s 52ms/step - loss: 0.0040 - accuracy: 0.9994 - val_loss: 0.2439 - val_accuracy: 0.9432\n",
            "Epoch 47/50\n",
            "74/74 [==============================] - 4s 53ms/step - loss: 0.0053 - accuracy: 0.9988 - val_loss: 0.2422 - val_accuracy: 0.9419\n",
            "Epoch 48/50\n",
            "74/74 [==============================] - 4s 52ms/step - loss: 0.0038 - accuracy: 0.9995 - val_loss: 0.2635 - val_accuracy: 0.9447\n",
            "Epoch 49/50\n",
            "74/74 [==============================] - 4s 51ms/step - loss: 0.0026 - accuracy: 0.9995 - val_loss: 0.2461 - val_accuracy: 0.9419\n",
            "Epoch 50/50\n",
            "74/74 [==============================] - 4s 56ms/step - loss: 0.0034 - accuracy: 0.9993 - val_loss: 0.2544 - val_accuracy: 0.9409\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f91001e91d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    }
  ]
}