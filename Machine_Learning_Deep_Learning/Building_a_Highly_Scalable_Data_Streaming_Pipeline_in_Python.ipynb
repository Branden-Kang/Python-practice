{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Building a Highly Scalable Data Streaming Pipeline in Python.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNdx06y6NOudRkHFIq5e22X"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[Reference](https://medium.com/geekculture/building-a-highly-scalable-data-streaming-pipeline-in-python-1f3d317a142a)"
      ],
      "metadata": {
        "id": "3XLSTyFlBy6W"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gMSxuX5rBbFy"
      },
      "outputs": [],
      "source": [
        "# consumer > quotes_consumer.py\n",
        "import time\n",
        "\n",
        "from pipeline.redis_client import RedisClient\n",
        "\n",
        "\n",
        "class QuotesConsumer:\n",
        "    redis_client = RedisClient()\n",
        "    sleep_seconds = 1\n",
        "\n",
        "    def run(self):\n",
        "        while True:\n",
        "            if self.redis_client.get_items_in_pipeline() == 0:\n",
        "                print(f'No new data in pipeline, sleeping for {self.sleep_seconds} seconds...')\n",
        "                time.sleep(self.sleep_seconds)\n",
        "                self.sleep_seconds += 1\n",
        "                continue\n",
        "\n",
        "            self.sleep_seconds = 1\n",
        "            data = self.redis_client.get_data_from_pipeline()\n",
        "            print(f'Obtained data from pipeline, saving to file...')\n",
        "            with open('quotes.txt', 'a+') as file:\n",
        "                file.write(data.get('quote'))\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    consumer = QuotesConsumer()\n",
        "    consumer.run()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pipeline > redis_client.py\n",
        "import json\n",
        "\n",
        "import redis\n",
        "\n",
        "\n",
        "class RedisClient:\n",
        "    \"\"\"\n",
        "    Custom Redis client with all the wrapper funtions. This client implements FIFO for pipeline.\n",
        "    \"\"\"\n",
        "    connection = redis.Redis(host='localhost', port=6379, db=0)\n",
        "    key = 'DATA-PIPELINE-KEY'\n",
        "\n",
        "    def _convert_data_to_json(self, data):\n",
        "        try:\n",
        "            return json.dumps(data)\n",
        "        except Exception as e:\n",
        "            print(f'Failed to convert data into json with error: {e}')\n",
        "            raise e\n",
        "\n",
        "    def _convert_data_from_json(self, data):\n",
        "        try:\n",
        "            return json.loads(data)\n",
        "        except Exception as e:\n",
        "            print(f'Failed to convert data from json to dict with error: {e}')\n",
        "            raise e\n",
        "\n",
        "    def send_data_to_pipeline(self, data):\n",
        "        data = self._convert_data_to_json(data)\n",
        "        self.connection.lpush(self.key, data)\n",
        "\n",
        "    def get_data_from_pipeline(self):\n",
        "        try:\n",
        "            data = self.connection.rpop(self.key)\n",
        "            return self._convert_data_from_json(data)\n",
        "        except Exception as e:\n",
        "            print(f'Failed to get more data from pipeline with error: {e}')\n",
        "\n",
        "    def get_items_in_pipeline(self):\n",
        "        return self.connection.llen(self.key)"
      ],
      "metadata": {
        "id": "h9L_m7CNBgLs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}