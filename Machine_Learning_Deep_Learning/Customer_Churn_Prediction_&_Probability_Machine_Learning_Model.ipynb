{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMdzp8wOCjEUAn4fdenuXSU"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[Reference](https://dadataguy.medium.com/customer-churn-prediction-probability-machine-learning-model-fe250be4d9b8)"
      ],
      "metadata": {
        "id": "6OoJF2e81Unp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n26ze7zX1ThQ",
        "outputId": "c24d92a3-c63d-4cff-842f-dc083c2f9120"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python Version is: 3.7.15 (default, Oct 12 2022, 19:14:55) \n",
            "[GCC 7.5.0]\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "print(\"Python Version is: \" + sys.version)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install catboost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A3m8L4Je1afx",
        "outputId": "c08501cf-3f63-4df4-bf72-382011ba3975"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: catboost in /usr/local/lib/python3.7/dist-packages (1.1.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from catboost) (1.7.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from catboost) (1.15.0)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from catboost) (1.3.5)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (from catboost) (5.5.0)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (from catboost) (0.10.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from catboost) (1.21.6)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from catboost) (3.2.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost) (2022.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (0.11.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->catboost) (4.1.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from plotly->catboost) (8.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import pandas as pd\n",
        "import itertools\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import joblib #load model\n",
        "import subprocess\n",
        "from sklearn import feature_selection\n",
        "#\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "#\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression,RidgeClassifier,SGDClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, BaggingClassifier\n",
        "from sklearn.preprocessing import OneHotEncoder , OrdinalEncoder,StandardScaler , MinMaxScaler, MaxAbsScaler\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.tree import DecisionTreeClassifier,ExtraTreeClassifier \n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.feature_selection import RFE\n",
        "from lightgbm import LGBMClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import roc_auc_score, recall_score, confusion_matrix, classification_report,f1_score,accuracy_score \n",
        "from sklearn.dummy import DummyClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "#imblen learn\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.pipeline import Pipeline as imbpipeline\n",
        " \n",
        "# Get multiple outputs in the same cell\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\"\n",
        " \n",
        "# Ignore all warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "warnings.filterwarnings(action='ignore', category=DeprecationWarning)\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.float_format', lambda x: '%.2f' % x) \n",
        "# goes to two decimal places "
      ],
      "metadata": {
        "id": "GkMGIuuz1Wax"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "time_begin = time.time()\n",
        "# df = pd.read_csv(\"CleanedDF.csv\") # data = pd.read_csv(\"census.csv\")\n",
        "print(f'Run time: {round(((time.time()-time_begin)/60), 3)} mins')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A7c4mRkW1Yst",
        "outputId": "f0335d23-6e6e-447f-cd8f-6d8a525a4792"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run time: 0.0 mins\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# X = df\n",
        "# y = df['Churn']\n",
        "\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
        "#                                                     test_size=0.3, \n",
        "#                                                     random_state=42,\n",
        "#                                                     stratify=y,\n",
        "#                                                     shuffle = True\n",
        "#                                                    )\n",
        "\n",
        "# remove = ['CustomerID','ZipCode','City','ChurnCategory','ChurnReason','Churn']\n",
        "# # Numerical columns\n",
        "# num_feats = [ \n",
        "#  'Age',\n",
        "#  'NumberofDependents',\n",
        "#  'Population',\n",
        "#  'NumberofReferrals',\n",
        "#  'TenureinMonths',\n",
        "#  'AvgMonthlyLongDistanceCharges',\n",
        "#  'AvgMonthlyGBDownload',\n",
        "#  'MonthlyCharge',\n",
        "#  'TotalCharges',\n",
        "#  'TotalRefunds',\n",
        "#  'TotalExtraDataCharges',\n",
        "#  'TotalLongDistanceCharges',\n",
        "#  'TotalRevenue'\n",
        "# ]\n",
        "# # Categorical columns\n",
        "# cat_feats = [ \n",
        "#  'Gender',\n",
        "#  'Offer',\n",
        "#  'Married',\n",
        "#  'PhoneService',\n",
        "#  'MultipleLines',\n",
        "#  'InternetService',\n",
        "#  'InternetService',\n",
        "#  'InternetType',\n",
        "#  'OnlineSecurity',\n",
        "#  'OnlineBackup',\n",
        "#  'DeviceProtectionPlan',\n",
        "#  'PremiumTechSupport',\n",
        "#  'StreamingTV',\n",
        "#  'StreamingMovies',\n",
        "#  'StreamingMusic',\n",
        "#  'UnlimitedData',\n",
        "#  'Contract',\n",
        "#  'PaperlessBilling',\n",
        "#  'PaymentMethod',\n",
        "# ]\n",
        "\n",
        "# X_testcopy = X_test.copy()\n",
        "# X_test.drop(remove, axis = 1, inplace = True)\n",
        "# X_train.drop(remove, axis = 1, inplace = True)\n",
        "\n",
        "# def get_pipeline(X, model):\n",
        "#     numeric_pipeline = SimpleImputer(strategy='mean')\n",
        "#     categorical_pipeline = OneHotEncoder(handle_unknown='ignore')\n",
        "#     preprocessor = ColumnTransformer(\n",
        "#         transformers=[\n",
        "#             ('numeric', numeric_pipeline, num_feats),\n",
        "#             ('categorical', categorical_pipeline, cat_feats),\n",
        "#             ], remainder='passthrough'\n",
        "#     )\n",
        "#     bundled_pipeline = imbpipeline(steps=[\n",
        "#         ('preprocessor', preprocessor),\n",
        "#         ('smote', SMOTE(random_state=42)),\n",
        "#         ('scaler', MinMaxScaler()),\n",
        "#         ('model', model)\n",
        "#     ])\n",
        "    \n",
        "#     return bundled_pipeline\n",
        "\n",
        "# def select_model(X, y, pipeline=None):  \n",
        "#     classifiers = {}\n",
        "#     classifiers.update({\"DummyClassifier\": DummyClassifier(strategy='most_frequent')})\n",
        "#     classifiers.update({\"XGBClassifier\": XGBClassifier(use_label_encoder=False, \n",
        "#                                                        eval_metric='logloss',\n",
        "#                                                        objective='binary:logistic',\n",
        "#                                                       )})\n",
        "#     classifiers.update({\"LGBMClassifier\": LGBMClassifier()})\n",
        "#     classifiers.update({\"RandomForestClassifier\": RandomForestClassifier()})\n",
        "#     classifiers.update({\"DecisionTreeClassifier\": DecisionTreeClassifier()})\n",
        "#     classifiers.update({\"ExtraTreeClassifier\": ExtraTreeClassifier()})\n",
        "#     #classifiers.update({\"ExtraTreesClassifier\": ExtraTreeClassifier()})    \n",
        "#     classifiers.update({\"AdaBoostClassifier\": AdaBoostClassifier()})\n",
        "#     classifiers.update({\"KNeighborsClassifier\": KNeighborsClassifier()})\n",
        "#     classifiers.update({\"RidgeClassifier\": RidgeClassifier()})\n",
        "#     classifiers.update({\"SGDClassifier\": SGDClassifier()})\n",
        "#     classifiers.update({\"BaggingClassifier\": BaggingClassifier()})\n",
        "#     classifiers.update({\"BernoulliNB\": BernoulliNB()})\n",
        "#     classifiers.update({\"SVC\": SVC()})\n",
        "#     classifiers.update({\"CatBoostClassifier\":CatBoostClassifier(silent=True)})\n",
        "    \n",
        "#     # Stacking\n",
        "#     models = []\n",
        "#     models = []\n",
        "#     models.append(('XGBClassifier', XGBClassifier(use_label_encoder=False, eval_metric='logloss', objective='binary:logistic')))\n",
        "#     models.append(('CatBoostClassifier', CatBoostClassifier(silent=True)))\n",
        "#     models.append(('BaggingClassifier', BaggingClassifier()))\n",
        "#     classifiers.update({\"VotingClassifier (XGBClassifier, CatBoostClassifier, BaggingClassifier)\": VotingClassifier(models)})\n",
        "#     models = []\n",
        "#     models.append(('XGBClassifier', XGBClassifier(use_label_encoder=False, eval_metric='logloss', objective='binary:logistic')))\n",
        "#     models.append(('LGBMClassifier', LGBMClassifier()))\n",
        "#     models.append(('CatBoostClassifier', CatBoostClassifier(silent=True)))\n",
        "#     classifiers.update({\"VotingClassifier (XGBClassifier, LGBMClassifier, CatBoostClassifier)\": VotingClassifier(models)})\n",
        "    \n",
        "#     models = []\n",
        "#     models.append(('XGBClassifier', XGBClassifier(use_label_encoder=False, eval_metric='logloss', objective='binary:logistic')))\n",
        "#     models.append(('RandomForestClassifier', RandomForestClassifier()))\n",
        "#     models.append(('DecisionTreeClassifier', DecisionTreeClassifier()))\n",
        "#     classifiers.update({\"VotingClassifier (XGBClassifier, RandomForestClassifier, DecisionTreeClassifier)\": VotingClassifier(models)})\n",
        "#     models = []\n",
        "#     models.append(('XGBClassifier', XGBClassifier(use_label_encoder=False, eval_metric='logloss', objective='binary:logistic')))\n",
        "#     models.append(('AdaBoostClassifier', AdaBoostClassifier()))\n",
        "#     #models.append(('ExtraTreeClassifier', ExtraTreeClassifier()))\n",
        "#     classifiers.update({\"VotingClassifier (XGBClassifier, AdaBoostClassifier)\": VotingClassifier(models)})\n",
        "    \n",
        "#     models = []\n",
        "#     models.append(('XGBClassifier', XGBClassifier(use_label_encoder=False, eval_metric='logloss', objective='binary:logistic')))\n",
        "#     #models.append(('ExtraTreesClassifier', ExtraTreesClassifier()))\n",
        "#     classifiers.update({\"VotingClassifier (XGBClassifier)\": VotingClassifier(models)})    \n",
        "    \n",
        "#     df_models = pd.DataFrame(columns=['model', 'run_time', 'accuracy'])\n",
        "#     for key in classifiers:\n",
        "        \n",
        "#         start_time = time.time()\n",
        "#     pipeline = get_pipeline(X_train, classifiers[key])\n",
        "        \n",
        "#         cv = cross_val_score(pipeline, X, y, cv=5, scoring='accuracy')\n",
        "#     row = {'model': key,\n",
        "#                'run_time': format(round((time.time() - start_time)/60,2)),\n",
        "#                'accuracy': cv.mean(),\n",
        "#         }\n",
        "#     df_models = df_models.append(row, ignore_index=True)\n",
        "        \n",
        "#     df_models = df_models.sort_values(by='accuracy', ascending=False)\n",
        "#     return df_models\n",
        "\n",
        "# models = select_model(X_train, y_train)\n",
        "# models.sort_values(by=['accuracy','run_time'], ascending=False)\n",
        "\n",
        "# basemodel = XGBClassifier(use_label_encoder = False, eval_metric='logloss', objective='binary:logistic')\n",
        "# bundled_pipeline = get_pipeline(X_train, basemodel)\n",
        "# bundled_pipeline.fit(X_train, y_train)\n",
        "# basemodel_y_pred = bundled_pipeline.predict(X_test)\n",
        "\n",
        "# print(classification_report(y_test, basemodel_y_pred))\n",
        "# print(confusion_matrix(y_test, basemodel_y_pred))\n",
        "\n",
        "# time_begin = time.time() #starts timer\n",
        "# # Loan Model\n",
        "# model = XGBClassifier(\n",
        "#     use_label_encoder = False, eval_metric='logloss', objective='binary:logistic', learning_rate = 0.1,\n",
        "#                      n_estimators = 1000, max_depth = 9, min_child_weight = 1, gamma = 0.4, colsample_bytree = 0.8, \n",
        "#                       subsample = 0.9, reg_alpha = 1, scale_pos_weight = 1)\n",
        "# model = get_pipeline(X_train,model)\n",
        "# model.fit(X_train,y_train)\n",
        "# y_pred = model.predict(X_test)\n",
        "# # predict target probabilities\n",
        "# test_prob = model.predict_proba(X_test)[:,1]\n",
        "# test_pred = np.where(test_prob > 0.45, 1, 0) #sets the probability threshhold and can be tweaked\n",
        "# # test set metrics\n",
        "# roc_auc_score(y_test, test_pred)\n",
        "# recall_score(y_test, test_pred)\n",
        "# confusion_matrix(y_test, test_pred)\n",
        "# print(classification_report(y_test,test_pred))\n",
        "# print(f'Run time: {round(((time.time()-time_begin)/60), 3)} mins')\n",
        "# # adding predictions and their probabilities to the original test Data frame\n",
        "# X_testcopy['predictions'] = test_pred\n",
        "# X_testcopy['pred_probabilities'] = test_prob\n",
        "# # Exporting the predictions to a new CSV labeled high_churn_list\n",
        "# high_churn_list = X_testcopy[X_testcopy.pred_probabilities > 0.0].sort_values(by=['pred_probabilities'], ascending = False).reset_index().drop(columns=['index'],axis=1)\n",
        "# high_churn_list.to_csv('high_churn_list_model.csv', index = False)"
      ],
      "metadata": {
        "id": "k2gdBSO71glr"
      },
      "execution_count": 10,
      "outputs": []
    }
  ]
}
