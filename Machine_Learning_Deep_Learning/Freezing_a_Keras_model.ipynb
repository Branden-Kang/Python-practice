{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Freezing a Keras model.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNv5QaZdJqWsylzWz0coCAm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IhKDdqfMapHW"
      },
      "source": [
        "[Reference](https://towardsdatascience.com/freezing-a-keras-model-c2e26cb84a38)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gSWuCrcgapQv"
      },
      "source": [
        "#import keras modules in tensorflow implementation\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Convolution2D, MaxPool2D, Flatten, Dense\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "def CNN(input_layer):\n",
        "  '''\n",
        "  defines the layers of the model\n",
        "  input_layer - pass input layer name\n",
        "  '''\n",
        "  conv1 = Convolution2D(16, 2, padding = 'same', activation = 'relu')(input_layer)\n",
        "  pool1 = MaxPool2D(pool_size = 2)(conv1)\n",
        "  \n",
        "  conv2 = Convolution2D(32, 2, padding = 'same', activation = 'relu')(pool1)\n",
        "  pool2 = MaxPool2D(pool_size = 2)(conv2)\n",
        "    \n",
        "  flat = Flatten()(pool2)\n",
        "  dense = Dense(128, activation = 'relu')(flat)\n",
        "    \n",
        "  output = Dense(10, activation  = 'softmax', name = \"output_node\")(dense)\n",
        "  return output"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1YAEl_LsangS",
        "outputId": "6f29275f-8a97-4112-b2ce-c53a6c2d18c0"
      },
      "source": [
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "#define input layer\n",
        "inpt = Input(shape = (28,28,1), name = \"input_node\")\n",
        "\n",
        "#call the model\n",
        "logits = CNN(inpt)\n",
        "\n",
        "#define model\n",
        "model = Model(inpt,logits)\n",
        "\n",
        "#compile the model\n",
        "model.compile(optimizer = keras.optimizers.Adam(lr = 0.0001), \\\n",
        "              loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "#convert to an Estimator\n",
        "# the model_dir states where the graph and checkpoint files will be saved to\n",
        "estimator_model = tf.keras.estimator.model_to_estimator(keras_model = model, \\\n",
        "                                                        model_dir = './Keras_MNIST')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using the Keras model provided.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n",
            "/usr/local/lib/python3.7/dist-packages/keras/backend.py:401: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
            "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Using config: {'_model_dir': './Keras_MNIST', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ZDSSl5bauzu"
      },
      "source": [
        "def input_function(features,labels=None,shuffle=False):\n",
        "    input_fn = tf.estimator.inputs.numpy_input_fn(\n",
        "        x={\"input_node\": features},\n",
        "        y=labels,\n",
        "        shuffle=shuffle,\n",
        "        batch_size = 5,\n",
        "        num_epochs = 1\n",
        "    )\n",
        "    return input_fn\n",
        "  \n",
        "estimator_model.train(input_fn = input_function(X_train,y_train,True))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1p7lwVhawcF"
      },
      "source": [
        "#since we are working in TensorFlow we define placeholder layers\n",
        "X = tf.placeholder(tf.float32, [None, 28,28,1], name = \"input_node\")\n",
        "y = tf.placeholder(tf.float32, [None, 10])\n",
        "\n",
        "#call the model\n",
        "logits = mod(X)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0T81t-4Uaz1S"
      },
      "source": [
        "# Freezing the model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3Vq_Olvayxi"
      },
      "source": [
        "def freeze_graph(model_dir, output_node_names):\n",
        "  \"\"\"Extract the sub graph defined by the output nodes and convert \n",
        "  all its variables into constant \n",
        "  Args:\n",
        "      model_dir: the root folder containing the checkpoint state file\n",
        "      output_node_names: a string, containing all the output node's names, \n",
        "                          comma separated\n",
        "                        \"\"\"\n",
        "  if not tf.gfile.Exists(model_dir):\n",
        "    raise AssertionError(\n",
        "      \"Export directory doesn't exists. Please specify an export \"\n",
        "      \"directory: %s\" % model_dir)\n",
        "\n",
        "  if not output_node_names:\n",
        "    print(\"You need to supply the name of a node to --output_node_names.\")\n",
        "    return -1\n",
        "\n",
        "  # We retrieve our checkpoint fullpath\n",
        "  checkpoint = tf.train.get_checkpoint_state(model_dir)\n",
        "  input_checkpoint = checkpoint.model_checkpoint_path\n",
        "    \n",
        "  # We precise the file fullname of our freezed graph\n",
        "  absolute_model_dir = \"/\".join(input_checkpoint.split('/')[:-1])\n",
        "  output_graph = absolute_model_dir + \"/frozen_model.pb\"\n",
        "\n",
        "  # We clear devices to allow TensorFlow to control on which device it will load operations\n",
        "  clear_devices = True\n",
        "\n",
        "  # We start a session using a temporary fresh Graph\n",
        "  with tf.Session(graph=tf.Graph()) as sess:\n",
        "    # We import the meta graph in the current default Graph\n",
        "    saver = tf.train.import_meta_graph(input_checkpoint + '.meta', clear_devices=clear_devices)\n",
        "\n",
        "    # We restore the weights\n",
        "    saver.restore(sess, input_checkpoint)\n",
        "\n",
        "    # We use a built-in TF helper to export variables to constants\n",
        "    output_graph_def = tf.graph_util.convert_variables_to_constants(\n",
        "      sess, # The session is used to retrieve the weights\n",
        "      tf.get_default_graph().as_graph_def(), # The graph_def is used to retrieve the nodes \n",
        "      output_node_names.split(\",\") # The output node names are used to select the usefull nodes\n",
        "    ) \n",
        "\n",
        "    # Finally we serialize and dump the output graph to the filesystem\n",
        "    with tf.gfile.GFile(output_graph, \"wb\") as f:\n",
        "      f.write(output_graph_def.SerializeToString())\n",
        "    print(\"%d ops in the final graph.\" % len(output_graph_def.node))\n",
        "\n",
        "  return output_graph_def"
      ],
      "execution_count": 6,
      "outputs": []
    }
  ]
}