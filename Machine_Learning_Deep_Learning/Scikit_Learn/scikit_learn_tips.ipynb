{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "scikit-learn-tips.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMXgfa5vxGG7rRDTYNTUYxM"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nptvpLlDevnN",
        "colab_type": "text"
      },
      "source": [
        "[Reference1](https://medium.com/@simonprdhm/9-scikit-learn-tips-for-data-scientist-2a84ffb385ba)<br>\n",
        "[Reference2](https://github.com/justmarkham/scikit-learn-tips)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iY1tY66oeuIN",
        "colab_type": "text"
      },
      "source": [
        "# 1. make_column_transformer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ptrbmqjdSr0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "0a3ea88a-d96a-4aa7-c65b-e0a5e98bf2e1"
      },
      "source": [
        "# Load Python Package\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import make_column_transformer\n",
        "\n",
        "# Load data (loading Titanic dataset)\n",
        "data  = pd.read_csv('https://web.stanford.edu/class/archive/cs/cs109/cs109.1166/stuff/titanic.csv')\n",
        "# Make Transformer\n",
        "preprocessing = make_column_transformer(\n",
        "    (OneHotEncoder(), ['Pclass','Sex']),\n",
        "    (SimpleImputer(), ['Age']),\n",
        "    remainder='passthrough')\n",
        "\n",
        "# Fit-Transform data with transformer\n",
        "preprocessing.fit_transform(data)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.0, 0.0, 1.0, ..., 1, 0, 7.25],\n",
              "       [1.0, 0.0, 0.0, ..., 1, 0, 71.2833],\n",
              "       [0.0, 0.0, 1.0, ..., 0, 0, 7.925],\n",
              "       ...,\n",
              "       [0.0, 0.0, 1.0, ..., 1, 2, 23.45],\n",
              "       [1.0, 0.0, 0.0, ..., 0, 0, 30.0],\n",
              "       [0.0, 0.0, 1.0, ..., 0, 0, 7.75]], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0kaJ8gFe9G7",
        "colab_type": "text"
      },
      "source": [
        "# 2. make_column_transformer and make_column_selector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWW1QkUnfCAy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "48053d32-89e7-40f0-8ed8-240c54346e05"
      },
      "source": [
        "# Load Python Package\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import make_column_transformer\n",
        "from sklearn.compose import make_column_selector\n",
        "# Load data (loading Titanic dataset)\n",
        "data = pd.read_csv('https://web.stanford.edu/class/archive/cs/cs109/cs109.1166/stuff/titanic.csv')\n",
        "# Make Transformer\n",
        "preprocessing = make_column_transformer(\n",
        "    (OneHotEncoder(), make_column_selector(dtype_include='object')),\n",
        "    (SimpleImputer(), make_column_selector(dtype_include='int')),\n",
        "    remainder='drop'\n",
        ")\n",
        "\n",
        "# Fit-Transform data with transformer\n",
        "preprocessing.fit_transform(data)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<887x893 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 3499 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0AruIiafIds",
        "colab_type": "text"
      },
      "source": [
        "# 3. Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4bu3wzufDq4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6b5de363-3803-46ae-9b29-c1ee9781b40b"
      },
      "source": [
        "# Load Python Package\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import make_column_transformer\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "# Load data (loading Titanic dataset)\n",
        "data = pd.read_csv('https://web.stanford.edu/class/archive/cs/cs109/cs109.1166/stuff/titanic.csv')\n",
        "# Set X and y\n",
        "X = data.drop('Survived',axis=1)\n",
        "y = data[['Survived']]\n",
        "# Split Train and Test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.33, random_state=42)\n",
        "# Set variables\n",
        "ohe = OneHotEncoder(handle_unknown='ignore', sparse=True)\n",
        "imputer = SimpleImputer(add_indicator=True, verbose=1)\n",
        "scaler = StandardScaler()\n",
        "clf = DecisionTreeClassifier()\n",
        "# Make Transformer\n",
        "preprocessing = make_column_transformer(\n",
        "(make_pipeline(imputer,scaler),['Age','Siblings/Spouses Aboard','Parents/Children Aboard','Fare'])\n",
        ",(ohe, ['Pclass','Sex','Name'])\n",
        ",remainder='passthrough')\n",
        "# Make pipeline\n",
        "pipe = make_pipeline(preprocessing, clf)\n",
        "# Fit model\n",
        "pipe.fit(X_train, y_train.values.ravel())\n",
        "print(\"Best score : %f\" % pipe.score(X_test, y_test.values.ravel()))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best score : 0.788396\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yk26O3o-fRM7",
        "colab_type": "text"
      },
      "source": [
        "# 4. KNNImputer or IterativeImputer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWr9aIehfMIQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load Python Package\n",
        "from sklearn.experimental import enable_iterative_imputer, enable_hist_gradient_boosting\n",
        "from sklearn.impute import SimpleImputer, IterativeImputer, KNNImputer"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qoQGTK6OfUBa",
        "colab_type": "text"
      },
      "source": [
        "# 5. Cross-validate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_D7KPkDhfTn3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "faf56219-e696-4a7b-c059-824956bfd44a"
      },
      "source": [
        "# Load Python Package\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import make_column_transformer\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "# Load data (loading Titanic dataset)\n",
        "data = pd.read_csv('https://web.stanford.edu/class/archive/cs/cs109/cs109.1166/stuff/titanic.csv')\n",
        "# Set X and y\n",
        "X = data.drop('Survived',axis=1)\n",
        "y = data[['Survived']]\n",
        "# Set variables\n",
        "ohe = OneHotEncoder(handle_unknown='ignore', sparse=True)\n",
        "imputer = SimpleImputer(add_indicator=True, verbose=1)\n",
        "clf = DecisionTreeClassifier()\n",
        "# Make Transformer\n",
        "preprocessing = make_column_transformer(\n",
        "(make_pipeline(imputer),['Age','Siblings/Spouses Aboard','Parents/Children Aboard','Fare']),\n",
        "(ohe, ['Pclass','Sex','Name']),remainder='passthrough')\n",
        "# Make pipeline\n",
        "pipe = make_pipeline(preprocessing, clf)\n",
        "# Cross-validation\n",
        "cross_val_score(pipe, X, y, cv=5, scoring='accuracy').mean()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8275820478638989"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNUOMjQffZW0",
        "colab_type": "text"
      },
      "source": [
        "# 6. Grid search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfLB5kKLfYAA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c96d60fe-3d4d-4cad-8841-8de3ad697e3d"
      },
      "source": [
        "# Import Python Package\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import make_column_transformer\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "# Load data (loading Titanic dataset)\n",
        "data = pd.read_csv('https://web.stanford.edu/class/archive/cs/cs109/cs109.1166/stuff/titanic.csv')\n",
        "# Set X and y\n",
        "X = data.drop('Survived',axis=1)\n",
        "y = data[['Survived']]\n",
        "# Set variables\n",
        "clf = LogisticRegression()\n",
        "ohe = OneHotEncoder()\n",
        "scaler = StandardScaler()\n",
        "imputer = SimpleImputer()\n",
        "# Make Transformer\n",
        "preprocessing = make_column_transformer((make_pipeline(imputer,scaler),['Age','Siblings/Spouses Aboard','Parents/Children Aboard','Fare']),(ohe, ['Sex']),remainder='drop')\n",
        "# Make pipeline\n",
        "pipe = make_pipeline(preprocessing, clf)\n",
        "# Set params for Grid Search\n",
        "params = {}\n",
        "params['logisticregression__C'] = [0.1,0.2,0.3]\n",
        "params['logisticregression__max_iter'] = [200,500]\n",
        "# Run grid search\n",
        "grid = GridSearchCV(pipe, params, cv=5, scoring='accuracy')\n",
        "grid.fit(X,y.values.ravel())\n",
        "print(grid.best_score_)\n",
        "# print(grid.best)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7868977337649972\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jqsmJYhZfilY",
        "colab_type": "text"
      },
      "source": [
        "# 7. Imbalanced dataset "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AmnyIS7wfhP0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import Python Package\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "# Load data (loading Titanic dataset)\n",
        "data = pd.read_csv('https://web.stanford.edu/class/archive/cs/cs109/cs109.1166/stuff/titanic.csv')\n",
        "# Set X and y\n",
        "X = data.drop('Survived',axis=1)\n",
        "y = data[['Survived']]\n",
        "# Split Train Test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, stratify=y)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7yxZyMxfw9k",
        "colab_type": "text"
      },
      "source": [
        "# 8. Use three datasets (Train, Validation and Test)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uSgW4nCJfvz5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "44b4931a-94a0-4d9f-f754-a23e96690ead"
      },
      "source": [
        "# Import Python Package\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "# Load data (loading Titanic dataset)\n",
        "data = pd.read_csv('https://web.stanford.edu/class/archive/cs/cs109/cs109.1166/stuff/titanic.csv')\n",
        "# Set X and y\n",
        "X = data.drop('Survived',axis=1)\n",
        "y = data[['Survived']]\n",
        "# Split Train, Val and Test \n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25)\n",
        "# Print dataFrames size\n",
        "print(X_train.shape)\n",
        "print(X_val.shape)\n",
        "print(X_test.shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(531, 7)\n",
            "(178, 7)\n",
            "(178, 7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0iAcZ5GXf8LE",
        "colab_type": "text"
      },
      "source": [
        "# 9. Use ColumnTransformer or Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rl7OcWHlf6yP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "e5dc45d2-6d02-45d3-963c-81d49e65e3fc"
      },
      "source": [
        "# Import Python Package\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "from sklearn.compose import make_column_transformer\n",
        "from sklearn.pipeline import make_pipeline\n",
        "imputer = SimpleImputer()\n",
        "# Load data (loading Titanic dataset)\n",
        "data = pd.read_csv('https://web.stanford.edu/class/archive/cs/cs109/cs109.1166/stuff/titanic.csv')\n",
        "# Set X and y\n",
        "X = data.drop('Survived',axis=1)\n",
        "y = data[['Survived']]\n",
        "# Write function\n",
        "def lower_letter(df):\n",
        "   return df.apply(lambda x : x.str.lower())\n",
        "# Convert function\n",
        "get_lower_letter = FunctionTransformer(lower_letter)\n",
        "# Make Pipeline\n",
        "preprocess = make_column_transformer((imputer, ['Age']),(get_lower_letter,['Name']),remainder='drop')\n",
        "preprocess.fit_transform(X)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[22.0, 'mr. owen harris braund'],\n",
              "       [38.0, 'mrs. john bradley (florence briggs thayer) cumings'],\n",
              "       [26.0, 'miss. laina heikkinen'],\n",
              "       ...,\n",
              "       [7.0, 'miss. catherine helen johnston'],\n",
              "       [26.0, 'mr. karl howell behr'],\n",
              "       [32.0, 'mr. patrick dooley']], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    }
  ]
}