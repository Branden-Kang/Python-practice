{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP68rX4yLSpwdEwzVsPA51p"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "from typing import Optional, List\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "class TabularTextTransformerModel(BaseNNModel):\n",
        "    \"\"\"\n",
        "    Tabular-Text Transformer (TTT) 단일 클래스 버전.\n",
        "    - 논문/공식 코드 구조를 최대한 따르면서,\n",
        "    - BaseNNModel을 상속해 DeepLearningBinaryClassifier에서 바로 쓸 수 있게 래핑.\n",
        "\n",
        "    가정:\n",
        "        X shape: (B, input_dim_total)\n",
        "        앞쪽 input_dim_tab 열: tabular (수치 + 범주)\n",
        "        뒤쪽 text_seq_len 열: text token id (정수, float32여도 long으로 캐스팅)\n",
        "\n",
        "        num_features, cat_features 인덱스는 [0 .. input_dim_tab-1] 범위 안에서 사용.\n",
        "\n",
        "    forward:\n",
        "        logits = model(X)   # (B, 1)  (binary classification logit)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        # ---- 전체 입력 구조 ----\n",
        "        input_dim_total: int,\n",
        "        input_dim_tab: int,           # 앞쪽 tabular feature 개수\n",
        "        num_features: List[int],      # tab 안에서 수치형 인덱스\n",
        "        cat_features: List[int],      # tab 안에서 범주형 인덱스\n",
        "        cat_dims: List[int],          # 각 범주형 cardinality\n",
        "        # ---- 텍스트 쪽 설정 ----\n",
        "        text_vocab_size: int,\n",
        "        text_pad_idx: int,\n",
        "        text_seq_len: int,\n",
        "        # ---- 공통 Transformer 설정 ----\n",
        "        d_model: int = 64,\n",
        "        n_heads: int = 4,\n",
        "        n_layers_overall: int = 2,\n",
        "        n_layers_self: int = 2,\n",
        "        d_ff: Optional[int] = None,\n",
        "        dropout: float = 0.1,\n",
        "        d_fc: int = 128,\n",
        "        # ---- 수치형 encoding 설정 ----\n",
        "        numeric_embedding: str = \"dq\",  # \"dq\" (distance-to-quantile) or \"linear\"\n",
        "        num_quantiles: int = 6,\n",
        "        # quantiles: (n_num_features, num_quantiles) float32 or np.ndarray\n",
        "        quantiles: Optional[torch.Tensor] = None,\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        # ===== 입력 관련 설정 =====\n",
        "        self.input_dim_total = input_dim_total\n",
        "        self.input_dim_tab = input_dim_tab\n",
        "        self.text_seq_len = text_seq_len\n",
        "\n",
        "        assert input_dim_tab + text_seq_len == input_dim_total, \\\n",
        "            \"input_dim_tab + text_seq_len != input_dim_total\"\n",
        "\n",
        "        self.num_features = num_features\n",
        "        self.cat_features = cat_features\n",
        "        self.cat_dims = cat_dims\n",
        "\n",
        "        self.n_num = len(num_features)\n",
        "        self.n_cat = len(cat_features)\n",
        "\n",
        "        # tab 인덱스를 buffer로 등록 (0~input_dim_tab-1 내부 기준)\n",
        "        num_idx = torch.tensor(num_features, dtype=torch.long)\n",
        "        cat_idx = torch.tensor(cat_features, dtype=torch.long)\n",
        "        self.register_buffer(\"num_idx_tensor\", num_idx, persistent=False)\n",
        "        self.register_buffer(\"cat_idx_tensor\", cat_idx, persistent=False)\n",
        "\n",
        "        # ===== 하이퍼파라미터 저장 =====\n",
        "        self.text_vocab_size = text_vocab_size\n",
        "        self.text_pad_idx = text_pad_idx\n",
        "        self.d_model = d_model\n",
        "        self.n_heads = n_heads\n",
        "        self.n_layers_overall = n_layers_overall\n",
        "        self.n_layers_self = n_layers_self\n",
        "        self.d_ff = d_ff or (4 * d_model)\n",
        "        self.dropout_p = dropout\n",
        "        self.d_fc = d_fc\n",
        "\n",
        "        self.numeric_embedding = numeric_embedding\n",
        "        self.num_quantiles = num_quantiles\n",
        "        self.n_classes = 1  # binary logit 하나\n",
        "\n",
        "        # ===== 네트워크 구성 =====\n",
        "        self.build_network(quantiles)\n",
        "\n",
        "    # ------------------------------------------------------------------\n",
        "    # Sinusoidal Positional Encoding (텍스트용, 별도 클래스 없이 내부 구현)\n",
        "    # ------------------------------------------------------------------\n",
        "    def _build_text_positional_encoding(self, max_len: int):\n",
        "        position = torch.arange(0, max_len, dtype=torch.float32).unsqueeze(1)  # (L, 1)\n",
        "        div_term = torch.exp(\n",
        "            torch.arange(0, self.d_model, 2, dtype=torch.float32)\n",
        "            * (-math.log(10000.0) / self.d_model)\n",
        "        )  # (d/2,)\n",
        "\n",
        "        pe = torch.zeros(max_len, self.d_model, dtype=torch.float32)\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0)  # (1, L, d)\n",
        "        self.register_buffer(\"pe_text\", pe, persistent=False)\n",
        "\n",
        "    def _add_text_positional_encoding(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        x: (B, L, d_model)\n",
        "        \"\"\"\n",
        "        L = x.size(1)\n",
        "        return x + self.pe_text[:, :L, :]\n",
        "\n",
        "    # ------------------------------------------------------------------\n",
        "    # 네트워크 구성 (OverallAttentionBlock / Core 구조 포함)\n",
        "    # ------------------------------------------------------------------\n",
        "    def build_network(self, quantiles: Optional[torch.Tensor]) -> nn.Module:\n",
        "        dropout = self.dropout_p\n",
        "        d_model = self.d_model\n",
        "\n",
        "        # ---------- 텍스트 임베딩 ----------\n",
        "        self.text_embedding = nn.Embedding(\n",
        "            num_embeddings=self.text_vocab_size,\n",
        "            embedding_dim=d_model,\n",
        "            padding_idx=self.text_pad_idx,\n",
        "        )\n",
        "        nn.init.normal_(self.text_embedding.weight, std=0.02)\n",
        "        self.text_dropout = nn.Dropout(dropout)\n",
        "\n",
        "        # [CLS]_text / [CLS]_tab\n",
        "        self.cls_text = nn.Parameter(torch.zeros(1, 1, d_model))\n",
        "        self.cls_tab = nn.Parameter(torch.zeros(1, 1, d_model))\n",
        "        nn.init.normal_(self.cls_text, std=0.02)\n",
        "        nn.init.normal_(self.cls_tab, std=0.02)\n",
        "\n",
        "        # 텍스트 positional encoding\n",
        "        self._build_text_positional_encoding(self.text_seq_len + 1)\n",
        "\n",
        "        # ---------- 범주형 임베딩 ----------\n",
        "        if self.n_cat > 0:\n",
        "            self.cat_embeddings = nn.ModuleList()\n",
        "            for c in self.cat_dims:\n",
        "                emb = nn.Embedding(num_embeddings=c, embedding_dim=d_model)\n",
        "                nn.init.normal_(emb.weight, std=0.02)\n",
        "                self.cat_embeddings.append(emb)\n",
        "            self.cat_dropout = nn.Dropout(dropout)\n",
        "        else:\n",
        "            self.cat_embeddings = nn.ModuleList()\n",
        "            self.cat_dropout = nn.Identity()\n",
        "\n",
        "        # ---------- 수치형 encoding ----------\n",
        "        self.use_dq = (self.numeric_embedding == \"dq\") and (self.n_num > 0)\n",
        "\n",
        "        if self.n_num > 0:\n",
        "            if self.use_dq:\n",
        "                # distance-to-quantile 용 quantiles 등록\n",
        "                if quantiles is None:\n",
        "                    raise ValueError(\n",
        "                        \"numeric_embedding='dq' 인 경우 quantiles 텐서를 넣어주세요.\"\n",
        "                    )\n",
        "                if isinstance(quantiles, np.ndarray):\n",
        "                    quantiles = torch.from_numpy(quantiles.astype(\"float32\"))\n",
        "\n",
        "                assert quantiles.shape == (\n",
        "                    self.n_num,\n",
        "                    self.num_quantiles,\n",
        "                ), \"quantiles shape must be (n_num_features, num_quantiles)\"\n",
        "\n",
        "                self.register_buffer(\n",
        "                    \"num_quantiles_tensor\",\n",
        "                    quantiles.clone().detach().float(),\n",
        "                    persistent=False,\n",
        "                )\n",
        "                # S_{j,k} embedding\n",
        "                self.num_quantile_embeddings = nn.Parameter(\n",
        "                    torch.randn(self.n_num, self.num_quantiles, d_model) * 0.02\n",
        "                )\n",
        "            else:\n",
        "                # feature별 Linear(1 -> d_model)\n",
        "                self.num_linears = nn.ModuleList(\n",
        "                    [nn.Linear(1, d_model) for _ in range(self.n_num)]\n",
        "                )\n",
        "                for lin in self.num_linears:\n",
        "                    nn.init.zeros_(lin.bias)\n",
        "                    nn.init.kaiming_uniform_(lin.weight)\n",
        "                # dummy buffers (사용 안 함)\n",
        "                self.register_buffer(\n",
        "                    \"num_quantiles_tensor\",\n",
        "                    torch.zeros(0, self.num_quantiles),\n",
        "                    persistent=False,\n",
        "                )\n",
        "                self.num_quantile_embeddings = None\n",
        "        else:\n",
        "            self.register_buffer(\n",
        "                \"num_quantiles_tensor\",\n",
        "                torch.zeros(0, self.num_quantiles),\n",
        "                persistent=False,\n",
        "            )\n",
        "            self.num_quantile_embeddings = None\n",
        "            self.num_linears = nn.ModuleList()\n",
        "\n",
        "        # ---------- Overall Attention blocks (각 레이어별 구성) ----------\n",
        "        # 따로 OverallAttentionBlock 클래스를 만들지 않고, 모듈리스트에 구성 요소 저장\n",
        "        self.over_text_attn = nn.ModuleList()\n",
        "        self.over_text_ln_q = nn.ModuleList()\n",
        "        self.over_text_ln_kv = nn.ModuleList()\n",
        "        self.over_text_ln_ff = nn.ModuleList()\n",
        "        self.over_text_ffn = nn.ModuleList()\n",
        "\n",
        "        self.over_tab_attn = nn.ModuleList()\n",
        "        self.over_tab_ln_q = nn.ModuleList()\n",
        "        self.over_tab_ln_kv = nn.ModuleList()\n",
        "        self.over_tab_ln_ff = nn.ModuleList()\n",
        "        self.over_tab_ffn = nn.ModuleList()\n",
        "\n",
        "        for _ in range(self.n_layers_overall):\n",
        "            # text stream\n",
        "            self.over_text_attn.append(\n",
        "                nn.MultiheadAttention(\n",
        "                    embed_dim=d_model,\n",
        "                    num_heads=self.n_heads,\n",
        "                    dropout=dropout,\n",
        "                    batch_first=True,\n",
        "                )\n",
        "            )\n",
        "            self.over_text_ln_q.append(nn.LayerNorm(d_model))\n",
        "            self.over_text_ln_kv.append(nn.LayerNorm(d_model))\n",
        "            self.over_text_ln_ff.append(nn.LayerNorm(d_model))\n",
        "            self.over_text_ffn.append(\n",
        "                nn.Sequential(\n",
        "                    nn.Linear(d_model, self.d_ff),\n",
        "                    nn.ReLU(),\n",
        "                    nn.Dropout(dropout),\n",
        "                    nn.Linear(self.d_ff, d_model),\n",
        "                )\n",
        "            )\n",
        "\n",
        "            # tab stream\n",
        "            self.over_tab_attn.append(\n",
        "                nn.MultiheadAttention(\n",
        "                    embed_dim=d_model,\n",
        "                    num_heads=self.n_heads,\n",
        "                    dropout=dropout,\n",
        "                    batch_first=True,\n",
        "                )\n",
        "            )\n",
        "            self.over_tab_ln_q.append(nn.LayerNorm(d_model))\n",
        "            self.over_tab_ln_kv.append(nn.LayerNorm(d_model))\n",
        "            self.over_tab_ln_ff.append(nn.LayerNorm(d_model))\n",
        "            self.over_tab_ffn.append(\n",
        "                nn.Sequential(\n",
        "                    nn.Linear(d_model, self.d_ff),\n",
        "                    nn.ReLU(),\n",
        "                    nn.Dropout(dropout),\n",
        "                    nn.Linear(self.d_ff, d_model),\n",
        "                )\n",
        "            )\n",
        "\n",
        "        self.over_dropout_attn = nn.Dropout(dropout)\n",
        "        self.over_dropout_ffn = nn.Dropout(dropout)\n",
        "\n",
        "        # ---------- Self-Attention encoders ----------\n",
        "        encoder_layer_text = nn.TransformerEncoderLayer(\n",
        "            d_model=d_model,\n",
        "            nhead=self.n_heads,\n",
        "            dim_feedforward=self.d_ff,\n",
        "            dropout=dropout,\n",
        "            batch_first=True,\n",
        "        )\n",
        "        self.text_transformer_encoder = nn.TransformerEncoder(\n",
        "            encoder_layer_text,\n",
        "            num_layers=self.n_layers_self,\n",
        "        )\n",
        "\n",
        "        encoder_layer_tab = nn.TransformerEncoderLayer(\n",
        "            d_model=d_model,\n",
        "            nhead=self.n_heads,\n",
        "            dim_feedforward=self.d_ff,\n",
        "            dropout=dropout,\n",
        "            batch_first=True,\n",
        "        )\n",
        "        self.tab_transformer_encoder = nn.TransformerEncoder(\n",
        "            encoder_layer_tab,\n",
        "            num_layers=self.n_layers_self,\n",
        "        )\n",
        "\n",
        "        # ---------- 최종 FC Head ----------\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(2 * d_model, self.d_fc),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(self.d_fc, self.n_classes),\n",
        "        )\n",
        "        nn.init.zeros_(self.fc[0].bias)\n",
        "        nn.init.kaiming_uniform_(self.fc[0].weight)\n",
        "        nn.init.zeros_(self.fc[3].bias)\n",
        "        nn.init.kaiming_uniform_(self.fc[3].weight)\n",
        "\n",
        "        return self\n",
        "\n",
        "    # ------------------------------------------------------------------\n",
        "    # 수치형 distance-to-quantile embedding\n",
        "    # ------------------------------------------------------------------\n",
        "    def _embed_numerical_dq(self, x_num: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        x_num: (B, n_num)\n",
        "        return: (B, n_num, d_model)\n",
        "        \"\"\"\n",
        "        B = x_num.size(0)\n",
        "        if self.n_num == 0:\n",
        "            return torch.zeros(\n",
        "                B, 0, self.d_model, device=x_num.device, dtype=torch.float32\n",
        "            )\n",
        "\n",
        "        v = x_num.unsqueeze(-1)  # (B, n_num, 1)\n",
        "        q = self.num_quantiles_tensor.unsqueeze(0)  # (1, n_num, s)\n",
        "\n",
        "        dist = torch.abs(v - q)  # (B, n_num, s)\n",
        "        eps = 1e-8\n",
        "\n",
        "        eq_mask = dist < 1e-6              # (B, n_num, s)\n",
        "        has_eq = eq_mask.any(dim=-1, keepdim=True)  # (B, n_num, 1)\n",
        "\n",
        "        inv_dist = 1.0 / (dist + eps)\n",
        "        weights = torch.where(has_eq, eq_mask.float(), inv_dist)\n",
        "        weights = weights / (weights.sum(dim=-1, keepdim=True) + eps)\n",
        "\n",
        "        S = self.num_quantile_embeddings.unsqueeze(0)  # (1, n_num, s, d)\n",
        "        emb = (weights.unsqueeze(-1) * S).sum(dim=2)   # (B, n_num, d)\n",
        "        return emb\n",
        "\n",
        "    # ------------------------------------------------------------------\n",
        "    # OverallAttentionBlock 한 층 수행 (text/tab 공용 내부 함수)\n",
        "    # ------------------------------------------------------------------\n",
        "    def _overall_block(\n",
        "        self,\n",
        "        x_q: torch.Tensor,\n",
        "        x_kv: torch.Tensor,\n",
        "        attn: nn.MultiheadAttention,\n",
        "        ln_q: nn.LayerNorm,\n",
        "        ln_kv: nn.LayerNorm,\n",
        "        ln_ff: nn.LayerNorm,\n",
        "        ffn: nn.Sequential,\n",
        "        key_padding_mask: Optional[torch.Tensor] = None,\n",
        "    ) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        x_q: query 시퀀스 (B, T_q, d)\n",
        "        x_kv: key/value 시퀀스 (B, T_kv, d)\n",
        "        \"\"\"\n",
        "        q = ln_q(x_q)\n",
        "        kv = ln_kv(x_kv)\n",
        "\n",
        "        attn_out, _ = attn(\n",
        "            q, kv, kv, key_padding_mask=key_padding_mask\n",
        "        )  # (B, T_q, d)\n",
        "\n",
        "        x = x_q + self.over_dropout_attn(attn_out)  # residual 1\n",
        "\n",
        "        y = ln_ff(x)\n",
        "        y = ffn(y)\n",
        "        out = x + self.over_dropout_ffn(y)          # residual 2\n",
        "        return out\n",
        "\n",
        "    # ------------------------------------------------------------------\n",
        "    # forward\n",
        "    # ------------------------------------------------------------------\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        x: (B, input_dim_total) float32\n",
        "        1) 앞쪽 input_dim_tab -> tab (수치/범주)\n",
        "        2) 나머지 text_seq_len -> text 토큰\n",
        "        반환: logits (B, 1)\n",
        "        \"\"\"\n",
        "        B, D = x.shape\n",
        "        device = x.device\n",
        "\n",
        "        # ===== 1. tab / text split =====\n",
        "        x_tab = x[:, : self.input_dim_tab]  # (B, input_dim_tab)\n",
        "        x_text = x[:, self.input_dim_tab : self.input_dim_tab + self.text_seq_len]  # (B, L)\n",
        "\n",
        "        # --- tab: numerical / categorical ---\n",
        "        if self.n_num > 0:\n",
        "            x_num = x_tab.index_select(1, self.num_idx_tensor).float()  # (B, n_num)\n",
        "        else:\n",
        "            x_num = None\n",
        "\n",
        "        if self.n_cat > 0:\n",
        "            x_cat = x_tab.index_select(1, self.cat_idx_tensor).long()   # (B, n_cat)\n",
        "        else:\n",
        "            x_cat = None\n",
        "\n",
        "        # --- text: long + padding mask ---\n",
        "        x_text_long = x_text.long()                     # (B, L)\n",
        "        text_padding_mask = x_text_long.eq(self.text_pad_idx)  # (B, L), True=PAD\n",
        "\n",
        "        # ===== 2. 텍스트 임베딩 =====\n",
        "        z_text = self.text_embedding(x_text_long)    # (B, L, d)\n",
        "        z_text = self.text_dropout(z_text)\n",
        "\n",
        "        cls_text = self.cls_text.expand(B, 1, -1)    # (B,1,d)\n",
        "        z_text = torch.cat([cls_text, z_text], dim=1) * math.sqrt(self.d_model)  # (B, L+1, d)\n",
        "        z_text = self._add_text_positional_encoding(z_text)\n",
        "\n",
        "        # 텍스트 key_padding_mask (CLS 앞에 False)\n",
        "        text_kpm = torch.cat(\n",
        "            [\n",
        "                torch.zeros(B, 1, dtype=torch.bool, device=device),\n",
        "                text_padding_mask,\n",
        "            ],\n",
        "            dim=1,\n",
        "        )  # (B, L+1)\n",
        "\n",
        "        # ===== 3. 탭 임베딩 =====\n",
        "        # --- 범주형 ---\n",
        "        if self.n_cat > 0 and x_cat is not None:\n",
        "            cat_emb_list = [emb(x_cat[:, j]) for j, emb in enumerate(self.cat_embeddings)]  # (B,d)\n",
        "            z_cat = torch.stack(cat_emb_list, dim=1)  # (B, n_cat, d)\n",
        "            z_cat = self.cat_dropout(z_cat)\n",
        "        else:\n",
        "            z_cat = torch.zeros(B, 0, self.d_model, device=device)\n",
        "\n",
        "        # --- 수치형 ---\n",
        "        if self.n_num > 0 and x_num is not None:\n",
        "            if self.use_dq:\n",
        "                z_num = self._embed_numerical_dq(x_num)  # (B, n_num, d)\n",
        "            else:\n",
        "                num_emb_list = []\n",
        "                for j, lin in enumerate(self.num_linears):\n",
        "                    num_emb_list.append(\n",
        "                        lin(x_num[:, j].view(B, 1, 1))\n",
        "                    )  # (B,1,d)\n",
        "                z_num = torch.cat(num_emb_list, dim=1)  # (B, n_num, d)\n",
        "        else:\n",
        "            z_num = torch.zeros(B, 0, self.d_model, device=device)\n",
        "\n",
        "        # --- 탭 concat + [CLS]_tab ---\n",
        "        z_tab_feats = torch.cat([z_cat, z_num], dim=1)  # (B, t_tab, d)\n",
        "        cls_tab = self.cls_tab.expand(B, 1, -1)         # (B,1,d)\n",
        "        z_tab = torch.cat([cls_tab, z_tab_feats], dim=1) * math.sqrt(self.d_model)\n",
        "\n",
        "        # padding 개념 없음\n",
        "        tab_kpm = None\n",
        "\n",
        "        # 초기 상태 저장 (cross-modal key용)\n",
        "        z_text_init = z_text\n",
        "        z_tab_init = z_tab\n",
        "\n",
        "        # ===== 4. Dual Overall Attention (L_overall 층) =====\n",
        "        for i in range(self.n_layers_overall):\n",
        "            # 텍스트 스트림\n",
        "            kv_text = torch.cat([z_text, z_tab_init], dim=1)\n",
        "            z_text = self._overall_block(\n",
        "                x_q=z_text,\n",
        "                x_kv=kv_text,\n",
        "                attn=self.over_text_attn[i],\n",
        "                ln_q=self.over_text_ln_q[i],\n",
        "                ln_kv=self.over_text_ln_kv[i],\n",
        "                ln_ff=self.over_text_ln_ff[i],\n",
        "                ffn=self.over_text_ffn[i],\n",
        "                key_padding_mask=None,  # 간단 버전: 전체 사용\n",
        "            )\n",
        "\n",
        "            # 탭 스트림\n",
        "            kv_tab = torch.cat([z_tab, z_text_init], dim=1)\n",
        "            z_tab = self._overall_block(\n",
        "                x_q=z_tab,\n",
        "                x_kv=kv_tab,\n",
        "                attn=self.over_tab_attn[i],\n",
        "                ln_q=self.over_tab_ln_q[i],\n",
        "                ln_kv=self.over_tab_ln_kv[i],\n",
        "                ln_ff=self.over_tab_ln_ff[i],\n",
        "                ffn=self.over_tab_ffn[i],\n",
        "                key_padding_mask=None,\n",
        "            )\n",
        "\n",
        "        # ===== 5. Self-Attention Encoders =====\n",
        "        z_text = self.text_transformer_encoder(\n",
        "            z_text, src_key_padding_mask=text_kpm\n",
        "        )  # (B, L+1, d)\n",
        "        z_tab = self.tab_transformer_encoder(z_tab)   # (B, t_tab+1, d)\n",
        "\n",
        "        # [CLS] 추출 후 concat\n",
        "        cls_text_out = z_text[:, 0, :]  # (B, d)\n",
        "        cls_tab_out = z_tab[:, 0, :]    # (B, d)\n",
        "        mm_feat = torch.cat([cls_text_out, cls_tab_out], dim=-1)  # (B, 2d)\n",
        "\n",
        "        logits = self.fc(mm_feat)  # (B,1)\n",
        "        if logits.ndim == 1:\n",
        "            logits = logits.view(-1, 1)\n",
        "        elif logits.size(1) != 1:\n",
        "            logits = logits[:, :1]\n",
        "\n",
        "        return logits"
      ],
      "metadata": {
        "id": "tOUw_QawUYdd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "# ===========================================================\n",
        "# Tabular-Text Transformer (TTT, text optional) + Demo\n",
        "# ===========================================================\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "import math\n",
        "from abc import ABC, abstractmethod\n",
        "from typing import Optional, List\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.base import BaseEstimator, ClassifierMixin\n",
        "from sklearn.metrics import log_loss, roc_auc_score\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# Base Neural Network Model\n",
        "# -----------------------------------------------------------\n",
        "class BaseNNModel(nn.Module, ABC):\n",
        "    def __init__(self, **kwargs):\n",
        "        super().__init__()\n",
        "\n",
        "    @abstractmethod\n",
        "    def build_network(self) -> nn.Module:\n",
        "        ...\n",
        "\n",
        "    @abstractmethod\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        ...\n",
        "\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# Tabular-Text Transformer (TTT) - text optional\n",
        "# -----------------------------------------------------------\n",
        "class TabularTextTransformerModel(BaseNNModel):\n",
        "    \"\"\"\n",
        "    Tabular-Text Transformer (TTT) 단일 클래스 버전.\n",
        "    - 탭 + (옵션) 텍스트를 함께 처리.\n",
        "    - 텍스트가 없어도(text_seq_len=0) 돌아가도록 구현.\n",
        "\n",
        "    입력 X 형태:\n",
        "        X: (B, input_dim_total) float32\n",
        "\n",
        "        * 앞쪽 input_dim_tab 열: tabular (수치 + 범주)\n",
        "        * 뒤쪽 text_seq_len 열: text token id (정수, float32여도 long 캐스팅)\n",
        "\n",
        "        num_features, cat_features 인덱스는 [0 .. input_dim_tab-1] 범위 안에서 사용.\n",
        "\n",
        "    사용 예 (텍스트 O):\n",
        "        input_dim_tab = 11\n",
        "        text_seq_len = 16\n",
        "        input_dim_total = 27 = 11 + 16\n",
        "\n",
        "    사용 예 (텍스트 X):\n",
        "        input_dim_tab = input_dim_total = 11\n",
        "        text_seq_len = 0\n",
        "\n",
        "    forward:\n",
        "        logits = model(X)   # (B, 1)  (binary classification logit)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        # ---- 전체 입력 구조 ----\n",
        "        input_dim_total: int,\n",
        "        input_dim_tab: int,           # 앞쪽 tabular feature 개수\n",
        "        num_features: List[int],      # tab 안에서 수치형 인덱스\n",
        "        cat_features: List[int],      # tab 안에서 범주형 인덱스\n",
        "        cat_dims: List[int],          # 각 범주형 cardinality\n",
        "        # ---- 텍스트 쪽 설정 ----\n",
        "        text_vocab_size: int,\n",
        "        text_pad_idx: int,\n",
        "        text_seq_len: int,            # 0이면 텍스트 없음\n",
        "        # ---- 공통 Transformer 설정 ----\n",
        "        d_model: int = 64,\n",
        "        n_heads: int = 4,\n",
        "        n_layers_overall: int = 2,\n",
        "        n_layers_self: int = 2,\n",
        "        d_ff: Optional[int] = None,\n",
        "        dropout: float = 0.1,\n",
        "        d_fc: int = 128,\n",
        "        # ---- 수치형 encoding 설정 ----\n",
        "        numeric_embedding: str = \"dq\",  # \"dq\" (distance-to-quantile) or \"linear\"\n",
        "        num_quantiles: int = 6,\n",
        "        # quantiles: (n_num_features, num_quantiles) float32 or np.ndarray\n",
        "        quantiles: Optional[torch.Tensor] = None,\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        # ===== 입력 관련 설정 =====\n",
        "        self.input_dim_total = input_dim_total\n",
        "        self.input_dim_tab = input_dim_tab\n",
        "        self.text_seq_len = text_seq_len\n",
        "\n",
        "        # 텍스트가 없으면: input_dim_total == input_dim_tab, text_seq_len=0\n",
        "        assert input_dim_tab + text_seq_len == input_dim_total, \\\n",
        "            \"input_dim_tab + text_seq_len != input_dim_total\"\n",
        "\n",
        "        self.num_features = num_features\n",
        "        self.cat_features = cat_features\n",
        "        self.cat_dims = cat_dims\n",
        "\n",
        "        self.n_num = len(num_features)\n",
        "        self.n_cat = len(cat_features)\n",
        "\n",
        "        # tab 인덱스를 buffer로 등록 (0~input_dim_tab-1 내부 기준)\n",
        "        num_idx = torch.tensor(num_features, dtype=torch.long)\n",
        "        cat_idx = torch.tensor(cat_features, dtype=torch.long)\n",
        "        self.register_buffer(\"num_idx_tensor\", num_idx, persistent=False)\n",
        "        self.register_buffer(\"cat_idx_tensor\", cat_idx, persistent=False)\n",
        "\n",
        "        # ===== 하이퍼파라미터 저장 =====\n",
        "        self.text_vocab_size = text_vocab_size\n",
        "        self.text_pad_idx = text_pad_idx\n",
        "        self.d_model = d_model\n",
        "        self.n_heads = n_heads\n",
        "        self.n_layers_overall = n_layers_overall\n",
        "        self.n_layers_self = n_layers_self\n",
        "        self.d_ff = d_ff or (4 * d_model)\n",
        "        self.dropout_p = dropout\n",
        "        self.d_fc = d_fc\n",
        "\n",
        "        self.numeric_embedding = numeric_embedding\n",
        "        self.num_quantiles = num_quantiles\n",
        "        self.n_classes = 1  # binary logit 하나\n",
        "        self.scale = d_model ** 0.5\n",
        "\n",
        "        # quantiles를 build_network에서 쓰기 위해 일단 저장\n",
        "        self._init_quantiles = quantiles\n",
        "\n",
        "        # ===== 네트워크 구성 =====\n",
        "        self.build_network()\n",
        "\n",
        "    # ------------------------------------------------------------------\n",
        "    # Sinusoidal Positional Encoding (텍스트용)\n",
        "    # ------------------------------------------------------------------\n",
        "    def _build_text_positional_encoding(self, max_len: int):\n",
        "        pe = torch.zeros(max_len, self.d_model, dtype=torch.float32)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float32).unsqueeze(1)\n",
        "        div_term = torch.exp(\n",
        "            torch.arange(0, self.d_model, 2, dtype=torch.float32)\n",
        "            * (-math.log(10000.0) / self.d_model)\n",
        "        )\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0)\n",
        "        self.register_buffer(\"pe_text\", pe, persistent=False)\n",
        "\n",
        "    def _add_text_positional_encoding(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        x: (B, L, d_model)\n",
        "        \"\"\"\n",
        "        L = x.size(1)\n",
        "        return x + self.pe_text[:, :L, :]\n",
        "\n",
        "    # ------------------------------------------------------------------\n",
        "    # 네트워크 구성 (OverallAttentionBlock / Core 구조 포함)\n",
        "    # ------------------------------------------------------------------\n",
        "    def build_network(self) -> nn.Module:\n",
        "        dropout = self.dropout_p\n",
        "        d_model = self.d_model\n",
        "\n",
        "        # ---------- 텍스트 임베딩 ----------\n",
        "        self.text_embedding = nn.Embedding(\n",
        "            num_embeddings=self.text_vocab_size,\n",
        "            embedding_dim=d_model,\n",
        "            padding_idx=self.text_pad_idx,\n",
        "        )\n",
        "        nn.init.normal_(self.text_embedding.weight, std=0.02)\n",
        "        self.text_dropout = nn.Dropout(dropout)\n",
        "\n",
        "        # [CLS]_text / [CLS]_tab\n",
        "        self.cls_text = nn.Parameter(torch.zeros(1, 1, d_model))\n",
        "        self.cls_tab = nn.Parameter(torch.zeros(1, 1, d_model))\n",
        "        nn.init.normal_(self.cls_text, std=0.02)\n",
        "        nn.init.normal_(self.cls_tab, std=0.02)\n",
        "\n",
        "        # 텍스트 positional encoding\n",
        "        max_len_for_pe = (self.text_seq_len + 1) if self.text_seq_len > 0 else 1\n",
        "        self._build_text_positional_encoding(max_len_for_pe)\n",
        "\n",
        "        # ---------- 범주형 임베딩 ----------\n",
        "        if self.n_cat > 0:\n",
        "            self.cat_embeddings = nn.ModuleList()\n",
        "            for c in self.cat_dims:\n",
        "                emb = nn.Embedding(num_embeddings=c, embedding_dim=d_model)\n",
        "                nn.init.normal_(emb.weight, std=0.02)\n",
        "                self.cat_embeddings.append(emb)\n",
        "            self.cat_dropout = nn.Dropout(dropout)\n",
        "        else:\n",
        "            self.cat_embeddings = nn.ModuleList()\n",
        "            self.cat_dropout = nn.Identity()\n",
        "\n",
        "        # ---------- 수치형 encoding ----------\n",
        "        self.use_dq = (self.numeric_embedding == \"dq\") and (self.n_num > 0)\n",
        "\n",
        "        quantiles = self._init_quantiles\n",
        "\n",
        "        if self.n_num > 0:\n",
        "            if self.use_dq:\n",
        "                # distance-to-quantile 용 quantiles 등록\n",
        "                if quantiles is None:\n",
        "                    raise ValueError(\n",
        "                        \"numeric_embedding='dq' 인 경우 quantiles 텐서를 넣어주세요.\"\n",
        "                    )\n",
        "                if isinstance(quantiles, np.ndarray):\n",
        "                    quantiles = torch.from_numpy(quantiles.astype(\"float32\"))\n",
        "\n",
        "                assert quantiles.shape == (\n",
        "                    self.n_num,\n",
        "                    self.num_quantiles,\n",
        "                ), \"quantiles shape must be (n_num_features, num_quantiles)\"\n",
        "\n",
        "                self.register_buffer(\n",
        "                    \"num_quantiles_tensor\",\n",
        "                    quantiles.clone().detach().float(),\n",
        "                    persistent=False,\n",
        "                )\n",
        "                # S_{j,k} embedding\n",
        "                self.num_quantile_embeddings = nn.Parameter(\n",
        "                    torch.randn(self.n_num, self.num_quantiles, d_model) * 0.02\n",
        "                )\n",
        "                # linear path는 사용 안 함\n",
        "                self.num_linears = nn.ModuleList()\n",
        "            else:\n",
        "                # feature별 Linear(1 -> d_model)\n",
        "                self.num_linears = nn.ModuleList(\n",
        "                    [nn.Linear(1, d_model) for _ in range(self.n_num)]\n",
        "                )\n",
        "                for lin in self.num_linears:\n",
        "                    nn.init.zeros_(lin.bias)\n",
        "                    nn.init.kaiming_uniform_(lin.weight)\n",
        "                # dummy buffers (DQ용은 사용 안 함)\n",
        "                self.register_buffer(\n",
        "                    \"num_quantiles_tensor\",\n",
        "                    torch.zeros(0, self.num_quantiles),\n",
        "                    persistent=False,\n",
        "                )\n",
        "                self.num_quantile_embeddings = None\n",
        "        else:\n",
        "            self.register_buffer(\n",
        "                \"num_quantiles_tensor\",\n",
        "                torch.zeros(0, self.num_quantiles),\n",
        "                persistent=False,\n",
        "            )\n",
        "            self.num_quantile_embeddings = None\n",
        "            self.num_linears = nn.ModuleList()\n",
        "\n",
        "        # ---------- Overall Attention blocks ----------\n",
        "        self.over_text_attn = nn.ModuleList()\n",
        "        self.over_text_ln_q = nn.ModuleList()\n",
        "        self.over_text_ln_kv = nn.ModuleList()\n",
        "        self.over_text_ln_ff = nn.ModuleList()\n",
        "        self.over_text_ffn = nn.ModuleList()\n",
        "\n",
        "        self.over_tab_attn = nn.ModuleList()\n",
        "        self.over_tab_ln_q = nn.ModuleList()\n",
        "        self.over_tab_ln_kv = nn.ModuleList()\n",
        "        self.over_tab_ln_ff = nn.ModuleList()\n",
        "        self.over_tab_ffn = nn.ModuleList()\n",
        "\n",
        "        for _ in range(self.n_layers_overall):\n",
        "            # text stream\n",
        "            self.over_text_attn.append(\n",
        "                nn.MultiheadAttention(\n",
        "                    embed_dim=d_model,\n",
        "                    num_heads=self.n_heads,\n",
        "                    dropout=dropout,\n",
        "                    batch_first=True,\n",
        "                )\n",
        "            )\n",
        "            self.over_text_ln_q.append(nn.LayerNorm(d_model))\n",
        "            self.over_text_ln_kv.append(nn.LayerNorm(d_model))\n",
        "            self.over_text_ln_ff.append(nn.LayerNorm(d_model))\n",
        "            self.over_text_ffn.append(\n",
        "                nn.Sequential(\n",
        "                    nn.Linear(d_model, self.d_ff),\n",
        "                    nn.ReLU(),\n",
        "                    nn.Dropout(dropout),\n",
        "                    nn.Linear(self.d_ff, d_model),\n",
        "                )\n",
        "            )\n",
        "\n",
        "            # tab stream\n",
        "            self.over_tab_attn.append(\n",
        "                nn.MultiheadAttention(\n",
        "                    embed_dim=d_model,\n",
        "                    num_heads=self.n_heads,\n",
        "                    dropout=dropout,\n",
        "                    batch_first=True,\n",
        "                )\n",
        "            )\n",
        "            self.over_tab_ln_q.append(nn.LayerNorm(d_model))\n",
        "            self.over_tab_ln_kv.append(nn.LayerNorm(d_model))\n",
        "            self.over_tab_ln_ff.append(nn.LayerNorm(d_model))\n",
        "            self.over_tab_ffn.append(\n",
        "                nn.Sequential(\n",
        "                    nn.Linear(d_model, self.d_ff),\n",
        "                    nn.ReLU(),\n",
        "                    nn.Dropout(dropout),\n",
        "                    nn.Linear(self.d_ff, d_model),\n",
        "                )\n",
        "            )\n",
        "\n",
        "        self.over_dropout_attn = nn.Dropout(dropout)\n",
        "        self.over_dropout_ffn = nn.Dropout(dropout)\n",
        "\n",
        "        # ---------- Self-Attention encoders ----------\n",
        "        encoder_layer_text = nn.TransformerEncoderLayer(\n",
        "            d_model=d_model,\n",
        "            nhead=self.n_heads,\n",
        "            dim_feedforward=self.d_ff,\n",
        "            dropout=dropout,\n",
        "            batch_first=True,\n",
        "        )\n",
        "        self.text_transformer_encoder = nn.TransformerEncoder(\n",
        "            encoder_layer_text,\n",
        "            num_layers=self.n_layers_self,\n",
        "        )\n",
        "\n",
        "        encoder_layer_tab = nn.TransformerEncoderLayer(\n",
        "            d_model=d_model,\n",
        "            nhead=self.n_heads,\n",
        "            dim_feedforward=self.d_ff,\n",
        "            dropout=dropout,\n",
        "            batch_first=True,\n",
        "        )\n",
        "        self.tab_transformer_encoder = nn.TransformerEncoder(\n",
        "            encoder_layer_tab,\n",
        "            num_layers=self.n_layers_self,\n",
        "        )\n",
        "\n",
        "        # ---------- 최종 FC Head ----------\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(2 * d_model, self.d_fc),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(self.d_fc, self.n_classes),\n",
        "        )\n",
        "        nn.init.zeros_(self.fc[0].bias)\n",
        "        nn.init.kaiming_uniform_(self.fc[0].weight)\n",
        "        nn.init.zeros_(self.fc[3].bias)\n",
        "        nn.init.kaiming_uniform_(self.fc[3].weight)\n",
        "\n",
        "        return self\n",
        "\n",
        "    # ------------------------------------------------------------------\n",
        "    # 수치형 distance-to-quantile embedding\n",
        "    # ------------------------------------------------------------------\n",
        "    def _embed_numerical_dq(self, x_num: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        x_num: (B, n_num)\n",
        "        return: (B, n_num, d_model)\n",
        "        \"\"\"\n",
        "        B = x_num.size(0)\n",
        "        if self.n_num == 0:\n",
        "            return torch.zeros(B, 0, self.d_model, device=x_num.device)\n",
        "        v = x_num.unsqueeze(-1)\n",
        "        q = self.num_quantiles_tensor.unsqueeze(0)\n",
        "        dist = torch.abs(v - q)\n",
        "        eps = 1e-8\n",
        "        eq_mask = dist < 1e-6\n",
        "        has_eq = eq_mask.any(dim=-1, keepdim=True)\n",
        "        inv_dist = 1.0 / (dist + eps)\n",
        "        weights = torch.where(has_eq, eq_mask.float(), inv_dist)\n",
        "        weights = weights / (weights.sum(dim=-1, keepdim=True) + eps)\n",
        "        S = self.num_quantile_embeddings.unsqueeze(0)\n",
        "        emb = (weights.unsqueeze(-1) * S).sum(dim=2)\n",
        "        return emb\n",
        "\n",
        "    # ------------------------------------------------------------------\n",
        "    # OverallAttentionBlock 한 층 수행 (text/tab 공용 내부 함수)\n",
        "    # ------------------------------------------------------------------\n",
        "    def _overall_block(\n",
        "        self,\n",
        "        x_q: torch.Tensor,\n",
        "        x_kv: torch.Tensor,\n",
        "        attn: nn.MultiheadAttention,\n",
        "        ln_q: nn.LayerNorm,\n",
        "        ln_kv: nn.LayerNorm,\n",
        "        ln_ff: nn.LayerNorm,\n",
        "        ffn: nn.Sequential,\n",
        "        key_padding_mask: Optional[torch.Tensor] = None,\n",
        "    ) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        x_q: query 시퀀스 (B, T_q, d)\n",
        "        x_kv: key/value 시퀀스 (B, T_kv, d)\n",
        "        \"\"\"\n",
        "        q = ln_q(x_q)\n",
        "        kv = ln_kv(x_kv)\n",
        "        attn_out, _ = attn(q, kv, kv, key_padding_mask=key_padding_mask)\n",
        "        x = x_q + self.over_dropout_attn(attn_out)\n",
        "        y = ln_ff(x)\n",
        "        y = ffn(y)\n",
        "        out = x + self.over_dropout_ffn(y)\n",
        "        return out\n",
        "\n",
        "    # ------------------------------------------------------------------\n",
        "    # forward\n",
        "    # ------------------------------------------------------------------\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        x: (B, input_dim_total) float32\n",
        "\n",
        "        1) 앞쪽 input_dim_tab -> tab (수치/범주)\n",
        "        2) 나머지 text_seq_len -> text 토큰 (text_seq_len>0일 때만)\n",
        "        반환: logits (B, 1)\n",
        "        \"\"\"\n",
        "        B, D = x.shape\n",
        "        device = x.device\n",
        "\n",
        "        # ===== 1. tab / text split =====\n",
        "        x_tab = x[:, : self.input_dim_tab]  # (B, input_dim_tab)\n",
        "\n",
        "        # --- 텍스트 처리 (옵션) ---\n",
        "        if self.text_seq_len > 0:\n",
        "            x_text = x[:, self.input_dim_tab : self.input_dim_tab + self.text_seq_len]  # (B, L)\n",
        "            x_text_long = x_text.long()                     # (B, L)\n",
        "            text_padding_mask = x_text_long.eq(self.text_pad_idx)  # (B, L), True=PAD\n",
        "\n",
        "            # 텍스트 임베딩\n",
        "            z_text = self.text_embedding(x_text_long)    # (B, L, d)\n",
        "            z_text = self.text_dropout(z_text)\n",
        "\n",
        "            cls_text = self.cls_text.expand(B, 1, -1)    # (B,1,d)\n",
        "            z_text = torch.cat([cls_text, z_text], dim=1) * self.scale  # (B, L+1, d)\n",
        "            z_text = self._add_text_positional_encoding(z_text)\n",
        "\n",
        "            # 텍스트 key_padding_mask (CLS 앞에 False)\n",
        "            text_kpm = torch.cat(\n",
        "                [\n",
        "                    torch.zeros(B, 1, dtype=torch.bool, device=device),\n",
        "                    text_padding_mask,\n",
        "                ],\n",
        "                dim=1,\n",
        "            )  # (B, L+1)\n",
        "        else:\n",
        "            # 텍스트 컬럼이 전혀 없는 경우:\n",
        "            # z_text는 CLS 하나짜리 더미 시퀀스로 만든다.\n",
        "            x_text_long = None\n",
        "            text_kpm = torch.zeros(B, 1, dtype=torch.bool, device=device)  # (B,1)\n",
        "\n",
        "            cls_text = self.cls_text.expand(B, 1, -1) * self.scale  # (B,1,d)\n",
        "            # positional encoding도 길이 1짜리만 적용\n",
        "            z_text = self._add_text_positional_encoding(cls_text)  # (B,1,d)\n",
        "\n",
        "        # --- tab: numerical / categorical ---\n",
        "        if self.n_num > 0:\n",
        "            x_num = x_tab.index_select(1, self.num_idx_tensor).float()  # (B, n_num)\n",
        "        else:\n",
        "            x_num = None\n",
        "\n",
        "        if self.n_cat > 0:\n",
        "            x_cat = x_tab.index_select(1, self.cat_idx_tensor).long()   # (B, n_cat)\n",
        "        else:\n",
        "            x_cat = None\n",
        "\n",
        "        # ===== 2. 탭 임베딩 =====\n",
        "        # --- 범주형 ---\n",
        "        if self.n_cat > 0 and x_cat is not None:\n",
        "            cat_emb_list = [emb(x_cat[:, j]) for j, emb in enumerate(self.cat_embeddings)]\n",
        "            z_cat = torch.stack(cat_emb_list, dim=1)  # (B, n_cat, d)\n",
        "            z_cat = self.cat_dropout(z_cat)\n",
        "        else:\n",
        "            z_cat = torch.zeros(B, 0, self.d_model, device=device)\n",
        "\n",
        "        # --- 수치형 ---\n",
        "        if self.n_num > 0 and x_num is not None:\n",
        "            if self.use_dq:\n",
        "                z_num = self._embed_numerical_dq(x_num)  # (B, n_num, d)\n",
        "            else:\n",
        "                num_emb_list = []\n",
        "                for j, lin in enumerate(self.num_linears):\n",
        "                    num_emb_list.append(\n",
        "                        lin(x_num[:, j].view(B, 1, 1))\n",
        "                    )  # (B,1,d)\n",
        "                z_num = torch.cat(num_emb_list, dim=1)  # (B, n_num, d)\n",
        "        else:\n",
        "            z_num = torch.zeros(B, 0, self.d_model, device=device)\n",
        "\n",
        "        # --- 탭 concat + [CLS]_tab ---\n",
        "        z_tab_feats = torch.cat([z_cat, z_num], dim=1)  # (B, t_tab, d)\n",
        "        cls_tab = self.cls_tab.expand(B, 1, -1)         # (B,1,d)\n",
        "        z_tab = torch.cat([cls_tab, z_tab_feats], dim=1) * self.scale  # (B, t_tab+1, d)\n",
        "\n",
        "        # 초기 상태 저장 (cross-modal key용)\n",
        "        z_text_init = z_text\n",
        "        z_tab_init = z_tab\n",
        "\n",
        "        # ===== 3. Dual Overall Attention (L_overall 층) =====\n",
        "        for i in range(self.n_layers_overall):\n",
        "            # 텍스트 스트림\n",
        "            kv_text = torch.cat([z_text, z_tab_init], dim=1)\n",
        "            z_text = self._overall_block(\n",
        "                x_q=z_text,\n",
        "                x_kv=kv_text,\n",
        "                attn=self.over_text_attn[i],\n",
        "                ln_q=self.over_text_ln_q[i],\n",
        "                ln_kv=self.over_text_ln_kv[i],\n",
        "                ln_ff=self.over_text_ln_ff[i],\n",
        "                ffn=self.over_text_ffn[i],\n",
        "                key_padding_mask=None,  # 간단 버전: 전체 사용\n",
        "            )\n",
        "\n",
        "            # 탭 스트림\n",
        "            kv_tab = torch.cat([z_tab, z_text_init], dim=1)\n",
        "            z_tab = self._overall_block(\n",
        "                x_q=z_tab,\n",
        "                x_kv=kv_tab,\n",
        "                attn=self.over_tab_attn[i],\n",
        "                ln_q=self.over_tab_ln_q[i],\n",
        "                ln_kv=self.over_tab_ln_kv[i],\n",
        "                ln_ff=self.over_tab_ln_ff[i],\n",
        "                ffn=self.over_tab_ffn[i],\n",
        "                key_padding_mask=None,\n",
        "            )\n",
        "\n",
        "        # ===== 4. Self-Attention Encoders =====\n",
        "        z_text = self.text_transformer_encoder(\n",
        "            z_text, src_key_padding_mask=text_kpm\n",
        "        )  # (B, L_text, d)  (L_text = L+1 or 1)\n",
        "        z_tab = self.tab_transformer_encoder(z_tab)   # (B, t_tab+1, d)\n",
        "\n",
        "        # [CLS] 추출 후 concat\n",
        "        cls_text_out = z_text[:, 0, :]  # (B, d)\n",
        "        cls_tab_out = z_tab[:, 0, :]    # (B, d)\n",
        "        mm_feat = torch.cat([cls_text_out, cls_tab_out], dim=-1)  # (B, 2d)\n",
        "\n",
        "        logits = self.fc(mm_feat)  # (B,1)\n",
        "        if logits.ndim == 1:\n",
        "            logits = logits.view(-1, 1)\n",
        "        elif logits.size(1) != 1:\n",
        "            logits = logits[:, :1]\n",
        "\n",
        "        return logits\n",
        "\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# Deep Learning Binary Classifier\n",
        "# -----------------------------------------------------------\n",
        "class DeepLearningBinaryClassifier(BaseEstimator, ClassifierMixin):\n",
        "    def __init__(\n",
        "        self,\n",
        "        model_type: str = \"tabtexttransformer\",\n",
        "        model_params: dict | None = None,\n",
        "    ):\n",
        "        self.model_type = model_type\n",
        "        self.model_params = model_params or {}\n",
        "        self.model = None\n",
        "\n",
        "    @property\n",
        "    def device(self) -> torch.device:\n",
        "        return torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    def _build_model(self) -> BaseNNModel:\n",
        "        model_registry = {\n",
        "            \"tabtexttransformer\": TabularTextTransformerModel,\n",
        "            # 필요 시 다른 모델들도 추가 가능\n",
        "        }\n",
        "\n",
        "        if self.model_type not in model_registry:\n",
        "            raise ValueError(f\"Unknown model type: {self.model_type}\")\n",
        "\n",
        "        # lr, loss_fn은 여기서 제거\n",
        "        valid_params = {\n",
        "            k: v for k, v in self.model_params.items() if k not in [\"loss_fn\", \"lr\"]\n",
        "        }\n",
        "\n",
        "        model_class = model_registry[self.model_type](**valid_params)\n",
        "        return model_class\n",
        "\n",
        "    def _get_loss_fn(self) -> nn.Module:\n",
        "        loss_name = self.model_params.get(\"loss_fn\", \"logloss\")\n",
        "        if loss_name == \"logloss\":\n",
        "            return nn.BCEWithLogitsLoss(reduction=\"none\")\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown loss function: {loss_name}\")\n",
        "\n",
        "    def fit(\n",
        "        self,\n",
        "        X: np.ndarray,\n",
        "        y: np.ndarray,\n",
        "        sample_weight: np.ndarray | None = None,\n",
        "        eval_set: list[tuple[np.ndarray, np.ndarray]] | None = None,\n",
        "        eval_metric: list[str] | None = None,\n",
        "        max_epochs: int = 10,\n",
        "        patience: int | None = None,\n",
        "        batch_size: int = 128,\n",
        "        verbose: bool = True,\n",
        "    ) -> \"DeepLearningBinaryClassifier\":\n",
        "\n",
        "        lr = self.model_params.get(\"lr\", 0.001)\n",
        "        eval_metric = eval_metric or [\"logloss\"]\n",
        "\n",
        "        X_tensor = torch.tensor(X, dtype=torch.float32).to(self.device)\n",
        "        y_tensor = torch.tensor(y, dtype=torch.float32).view(-1, 1).to(self.device)\n",
        "\n",
        "        if eval_set is not None:\n",
        "            x_eval_tensor = torch.tensor(\n",
        "                eval_set[0][0], dtype=torch.float32\n",
        "            ).to(self.device)\n",
        "            y_eval_true = eval_set[0][1]\n",
        "        else:\n",
        "            x_eval_tensor = None\n",
        "            y_eval_true = None\n",
        "\n",
        "        if sample_weight is not None:\n",
        "            sample_weight_tensor = torch.tensor(\n",
        "                sample_weight, dtype=torch.float32\n",
        "            ).to(self.device)\n",
        "        else:\n",
        "            sample_weight_tensor = torch.ones_like(y_tensor, dtype=torch.float32)\n",
        "\n",
        "        train_dataset = TensorDataset(X_tensor, y_tensor, sample_weight_tensor)\n",
        "        train_dataloader = DataLoader(\n",
        "            train_dataset, batch_size=batch_size, shuffle=True\n",
        "        )\n",
        "\n",
        "        if self.model is None:\n",
        "            self.model = self._build_model().to(self.device)\n",
        "\n",
        "        loss_fn = self._get_loss_fn()\n",
        "        optimizer = optim.Adam(self.model.parameters(), lr=lr, weight_decay=1e-4)\n",
        "\n",
        "        patience_counter = 0\n",
        "        best_metric = float(\"inf\")\n",
        "        best_model_weights = None\n",
        "\n",
        "        for epoch in range(max_epochs):\n",
        "            self.model.train()\n",
        "            epoch_loss = 0.0\n",
        "            n_batches = 0\n",
        "\n",
        "            for x_batch, y_batch, weight_batch in train_dataloader:\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                y_pred_logits = self.model(x_batch)\n",
        "                loss = loss_fn(y_pred_logits, y_batch)\n",
        "                weighted_loss = (loss * weight_batch).sum() / weight_batch.sum()\n",
        "\n",
        "                weighted_loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                epoch_loss += weighted_loss.item()\n",
        "                n_batches += 1\n",
        "\n",
        "            if verbose:\n",
        "                print(\n",
        "                    f\"Epoch {epoch + 1}/{max_epochs} \"\n",
        "                    f\"- [train] loss: {epoch_loss / max(1, n_batches):.6f}\"\n",
        "                )\n",
        "\n",
        "            # evaluation\n",
        "            if eval_set is not None:\n",
        "                self.model.eval()\n",
        "                with torch.no_grad():\n",
        "                    y_eval_logits = self.model(x_eval_tensor)\n",
        "                    y_eval_pred = torch.sigmoid(y_eval_logits).cpu().numpy().ravel()\n",
        "\n",
        "                eval_metrics = {}\n",
        "                for metric in eval_metric:\n",
        "                    if metric == \"logloss\":\n",
        "                        eval_metrics[\"logloss\"] = log_loss(y_eval_true, y_eval_pred)\n",
        "                    elif metric == \"auc\":\n",
        "                        eval_metrics[\"auc\"] = -roc_auc_score(y_eval_true, y_eval_pred)\n",
        "                    else:\n",
        "                        raise ValueError(f\"Unknown metric: {metric}\")\n",
        "\n",
        "                if verbose:\n",
        "                    metrics_str = \", \".join(\n",
        "                        [f\"{k}: {v:.4f}\" for k, v in eval_metrics.items()]\n",
        "                    )\n",
        "                    print(f\"  - [eval] {metrics_str}\")\n",
        "\n",
        "                # early stopping (기준 metric은 리스트의 첫 번째)\n",
        "                main_metric_name = eval_metric[0]\n",
        "                current_metric = eval_metrics.get(\n",
        "                    main_metric_name, eval_metrics[\"logloss\"]\n",
        "                )\n",
        "\n",
        "                if verbose:\n",
        "                    print(\n",
        "                        f\"    -- (early_stopping) current_metric: {current_metric:.6f}, \"\n",
        "                        f\"best_metric: {best_metric:.6f}\"\n",
        "                    )\n",
        "\n",
        "                if current_metric < best_metric:\n",
        "                    best_metric = current_metric\n",
        "                    patience_counter = 0\n",
        "                    best_model_weights = self.model.state_dict()\n",
        "                else:\n",
        "                    patience_counter += 1\n",
        "                    if patience is not None and patience_counter >= patience:\n",
        "                        if verbose:\n",
        "                            print(f\"Early stopping at epoch {epoch + 1}\")\n",
        "                        break\n",
        "\n",
        "        if best_model_weights is not None:\n",
        "            self.model.load_state_dict(best_model_weights)\n",
        "\n",
        "        return self\n",
        "\n",
        "    def predict_proba(self, X: np.ndarray) -> np.ndarray:\n",
        "        self.model = self.model.to(self.device)\n",
        "        X_tensor = torch.tensor(X, dtype=torch.float32).to(self.device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            self.model.eval()\n",
        "            logits = self.model(X_tensor)\n",
        "            probs1 = torch.sigmoid(logits).cpu().numpy()\n",
        "\n",
        "        if probs1.shape[1] == 1:\n",
        "            probs1 = probs1.reshape(-1, 1)\n",
        "\n",
        "        probs0 = 1.0 - probs1\n",
        "        probs = np.hstack((probs0, probs1))\n",
        "        return probs.astype(\"float\")\n",
        "\n",
        "    def predict(self, X: np.ndarray) -> np.ndarray:\n",
        "        probs = self.predict_proba(X)\n",
        "        return probs.argmax(axis=1)\n",
        "\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# 한국형 피처 스키마(연령/성별/OS/점수형) 데모 데이터 생성 (탭만)\n",
        "# -----------------------------------------------------------\n",
        "def make_kor_feature_demo_data(\n",
        "    n_samples: int = 5000,\n",
        "    seed: int = 42,\n",
        "):\n",
        "    rng = np.random.RandomState(seed)\n",
        "    n = n_samples\n",
        "\n",
        "    # --- 1) 각 피처 생성 ---\n",
        "    age = np.clip(rng.normal(loc=40, scale=12, size=n), 18, 80).astype(\"float32\")\n",
        "    gender = rng.randint(0, 3, size=n).astype(\"int64\")\n",
        "    app_join_cnt = rng.poisson(lam=2.0, size=n).astype(\"float32\")\n",
        "    last_login_days = rng.exponential(scale=10.0, size=n).astype(\"float32\")\n",
        "    os_cat = rng.randint(0, 4, size=n).astype(\"int64\")\n",
        "    app_join_days = rng.exponential(scale=200.0, size=n).astype(\"float32\")\n",
        "\n",
        "    biz_owner_score = (rng.binomial(1, 0.3, size=n) * rng.uniform(0.5, 1.0, size=n)).astype(\"float32\")\n",
        "    home_owner_score = (rng.binomial(1, 0.4, size=n) * rng.uniform(0.5, 1.0, size=n)).astype(\"float32\")\n",
        "    car_owner_score = (rng.binomial(1, 0.5, size=n) * rng.uniform(0.5, 1.0, size=n)).astype(\"float32\")\n",
        "    married_score   = (rng.binomial(1, 0.5, size=n) * rng.uniform(0.5, 1.0, size=n)).astype(\"float32\")\n",
        "    child_score     = (rng.binomial(1, 0.4, size=n) * rng.uniform(0.5, 1.0, size=n)).astype(\"float32\")\n",
        "\n",
        "    # --- 2) 라벨 생성용 latent score ---\n",
        "    w_gender = rng.uniform(-0.3, 0.3, size=3)   # gender 0/1/2\n",
        "    w_os     = rng.uniform(-0.2, 0.2, size=4)   # os 0~3\n",
        "\n",
        "    score = np.zeros(n, dtype=\"float32\")\n",
        "\n",
        "    score += 0.05 * (age - 40) / 10.0\n",
        "    score += 0.25 * app_join_cnt\n",
        "    score -= 0.03 * last_login_days\n",
        "    score -= 0.002 * app_join_days\n",
        "    score += 0.8 * biz_owner_score\n",
        "    score += 0.6 * home_owner_score\n",
        "    score += 0.7 * car_owner_score\n",
        "    score += 0.9 * married_score\n",
        "    score += 1.0 * child_score\n",
        "\n",
        "    score += w_gender[gender]\n",
        "    score += w_os[os_cat]\n",
        "\n",
        "    noise = rng.normal(scale=0.5, size=n).astype(\"float32\")\n",
        "    bias = -0.2\n",
        "    logit = score + bias + noise\n",
        "    prob = 1.0 / (1.0 + np.exp(-logit))\n",
        "    y = (prob > 0.5).astype(\"int64\")\n",
        "\n",
        "    # --- 3) 최종 Tab X 매트릭스 ---\n",
        "    X_tab = np.column_stack(\n",
        "        [\n",
        "            age,                        # 0\n",
        "            gender.astype(\"float32\"),   # 1\n",
        "            app_join_cnt,               # 2\n",
        "            last_login_days,            # 3\n",
        "            os_cat.astype(\"float32\"),   # 4\n",
        "            app_join_days,              # 5\n",
        "            biz_owner_score,            # 6\n",
        "            home_owner_score,           # 7\n",
        "            car_owner_score,            # 8\n",
        "            married_score,              # 9\n",
        "            child_score,                # 10\n",
        "        ]\n",
        "    ).astype(\"float32\")\n",
        "\n",
        "    cat_feature_indices = [1, 4]   # 성별, OS\n",
        "    cat_dims = [3, 4]              # gender:3, os:4\n",
        "\n",
        "    return X_tab, y, cat_feature_indices, cat_dims\n",
        "\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# 수치형 quantile 계산 유틸 (DQ embedding용)\n",
        "# -----------------------------------------------------------\n",
        "def compute_numeric_quantiles(\n",
        "    X: np.ndarray,\n",
        "    numeric_indices: List[int],\n",
        "    num_quantiles: int = 6,\n",
        "    quantile_grid: Optional[np.ndarray] = None,\n",
        ") -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    X: feature matrix (N, D) - 여기서는 tab 부분만 넘기는 걸 추천\n",
        "    numeric_indices: 수치형 feature column index 리스트\n",
        "    num_quantiles: quantile 개수\n",
        "    quantile_grid: np.ndarray shape (num_quantiles,) 0~1 사이 값 (None이면 균등)\n",
        "\n",
        "    return: torch.Tensor (n_num_features, num_quantiles) float32\n",
        "    \"\"\"\n",
        "    X_num = X[:, numeric_indices].astype(\"float32\")\n",
        "    n_num = X_num.shape[1]\n",
        "\n",
        "    if quantile_grid is None:\n",
        "        quantile_grid = np.linspace(0.0, 1.0, num_quantiles, dtype=np.float32)\n",
        "\n",
        "    q_list = []\n",
        "    for j in range(n_num):\n",
        "        col = X_num[:, j]\n",
        "        q_col = np.quantile(col, quantile_grid, method=\"linear\").astype(\"float32\")\n",
        "        q_list.append(q_col)\n",
        "\n",
        "    quantiles = np.stack(q_list, axis=0)  # (n_num, num_quantiles)\n",
        "    return torch.from_numpy(quantiles)\n",
        "\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# Tabular-Text Transformer 데모 (텍스트 있는 버전)\n",
        "# -----------------------------------------------------------\n",
        "def demo_train_tabtexttransformer():\n",
        "    print(\"\\n===== Tabular-Text Transformer Demo (with text) =====\")\n",
        "\n",
        "    # 1) Tab 데이터 생성\n",
        "    X_tab, y, cat_features, cat_dims = make_kor_feature_demo_data(\n",
        "        n_samples=2000,\n",
        "        seed=123,\n",
        "    )\n",
        "\n",
        "    print(\"Tab X shape:\", X_tab.shape, \"| y shape:\", y.shape)\n",
        "    print(\"Categorical feature indices:\", cat_features)\n",
        "    print(\"Categorical dims:\", cat_dims)\n",
        "\n",
        "    # 2) 텍스트 토큰 생성 (간단 랜덤 토큰)\n",
        "    n_samples = X_tab.shape[0]\n",
        "    text_seq_len = 16\n",
        "    text_vocab_size = 50\n",
        "    text_pad_idx = 0\n",
        "\n",
        "    rng = np.random.RandomState(999)\n",
        "    X_text = rng.randint(1, text_vocab_size, size=(n_samples, text_seq_len)).astype(\"int64\")\n",
        "\n",
        "    # 일부 위치를 pad(0)로 설정\n",
        "    pad_mask = rng.rand(n_samples, text_seq_len) < 0.1  # 10% 정도 pad\n",
        "    X_text[pad_mask] = text_pad_idx\n",
        "\n",
        "    # 3) Tab + Text 합치기\n",
        "    X_total = np.concatenate(\n",
        "        [X_tab, X_text.astype(\"float32\")],\n",
        "        axis=1,\n",
        "    ).astype(\"float32\")\n",
        "\n",
        "    input_dim_tab = X_tab.shape[1]\n",
        "    input_dim_total = X_total.shape[1]\n",
        "\n",
        "    # 4) train / val / test split\n",
        "    N = X_total.shape[0]\n",
        "    idx = np.arange(N)\n",
        "    np.random.shuffle(idx)\n",
        "\n",
        "    tr_end = int(N * 0.7)\n",
        "    va_end = int(N * 0.85)\n",
        "    tr_idx, va_idx, te_idx = idx[:tr_end], idx[tr_end:va_end], idx[va_end:]\n",
        "\n",
        "    X_tr, y_tr = X_total[tr_idx], y[tr_idx]\n",
        "    X_va, y_va = X_total[va_idx], y[va_idx]\n",
        "    X_te, y_te = X_total[te_idx], y[te_idx]\n",
        "\n",
        "    sample_weight = np.ones_like(y_tr, dtype=\"float32\")\n",
        "\n",
        "    # 5) 수치형/범주형 인덱스 (tab 부분 기준)\n",
        "    num_features = [i for i in range(input_dim_tab) if i not in cat_features]\n",
        "\n",
        "    # 6) DQ embedding용 quantiles (train tab 부분에서 계산)\n",
        "    quantile_grid = np.array([0.0, 0.2, 0.4, 0.6, 0.8, 1.0], dtype=np.float32)\n",
        "    X_tr_tab = X_tr[:, :input_dim_tab]  # tab 부분만\n",
        "    quantiles = compute_numeric_quantiles(\n",
        "        X_tr_tab,\n",
        "        numeric_indices=num_features,\n",
        "        num_quantiles=len(quantile_grid),\n",
        "        quantile_grid=quantile_grid,\n",
        "    )\n",
        "\n",
        "    print(\"Numeric feature indices:\", num_features)\n",
        "    print(\"Quantiles shape:\", quantiles.shape)\n",
        "\n",
        "    # 7) 모델 파라미터 구성\n",
        "    model_params = {\n",
        "        \"input_dim_total\": input_dim_total,\n",
        "        \"input_dim_tab\": input_dim_tab,\n",
        "        \"num_features\": num_features,\n",
        "        \"cat_features\": cat_features,\n",
        "        \"cat_dims\": cat_dims,\n",
        "        \"text_vocab_size\": text_vocab_size,\n",
        "        \"text_pad_idx\": text_pad_idx,\n",
        "        \"text_seq_len\": text_seq_len,   # ← 텍스트가 있으므로 >0\n",
        "        \"d_model\": 64,\n",
        "        \"n_heads\": 4,\n",
        "        \"n_layers_overall\": 2,\n",
        "        \"n_layers_self\": 2,\n",
        "        \"d_ff\": None,          # None이면 4*d_model\n",
        "        \"dropout\": 0.1,\n",
        "        \"d_fc\": 128,\n",
        "        \"numeric_embedding\": \"dq\",  # distance-to-quantile\n",
        "        \"num_quantiles\": quantiles.shape[1],\n",
        "        \"quantiles\": quantiles,\n",
        "        \"lr\": 1e-3,\n",
        "        \"loss_fn\": \"logloss\",\n",
        "    }\n",
        "\n",
        "    clf = DeepLearningBinaryClassifier(\n",
        "        model_type=\"tabtexttransformer\",\n",
        "        model_params=model_params,\n",
        "    )\n",
        "\n",
        "    clf.fit(\n",
        "        X_tr,\n",
        "        y_tr,\n",
        "        sample_weight=sample_weight,\n",
        "        eval_set=[(X_va, y_va)],\n",
        "        eval_metric=[\"logloss\"],\n",
        "        max_epochs=5,      # 데모용\n",
        "        patience=2,\n",
        "        batch_size=256,\n",
        "        verbose=True,\n",
        "    )\n",
        "\n",
        "    # 8) 평가\n",
        "    probs_te = clf.predict_proba(X_te)[:, 1]\n",
        "    preds_te = (probs_te >= 0.5).astype(\"int64\")\n",
        "\n",
        "    acc = (preds_te == y_te).mean()\n",
        "    auc = roc_auc_score(y_te, probs_te)\n",
        "    ll = log_loss(y_te, probs_te)\n",
        "\n",
        "    print(\"\\n===== Tabular-Text Transformer Test Metrics =====\")\n",
        "    print(f\"Accuracy : {acc:.4f}\")\n",
        "    print(f\"ROC-AUC  : {auc:.4f}\")\n",
        "    print(f\"Logloss  : {ll:.4f}\")\n",
        "    print(\"Sample probs (first 10):\", np.round(probs_te[:10], 4))\n",
        "\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# 메인\n",
        "# -----------------------------------------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    demo_train_tabtexttransformer()\n",
        "    # 텍스트 없이 쓰고 싶다면:\n",
        "    #  - X_total 대신 X_tab만 사용\n",
        "    #  - input_dim_total = input_dim_tab = X_tab.shape[1]\n",
        "    #  - text_seq_len = 0\n",
        "    #  - text_vocab_size는 1, text_pad_idx=0 정도로 두면 됩니다."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8U8Gy1S5UbwL",
        "outputId": "ea290b36-2c9e-4bdb-d61a-edf4b4c0139d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===== Tabular-Text Transformer Demo (with text) =====\n",
            "Tab X shape: (2000, 11) | y shape: (2000,)\n",
            "Categorical feature indices: [1, 4]\n",
            "Categorical dims: [3, 4]\n",
            "Numeric feature indices: [0, 2, 3, 5, 6, 7, 8, 9, 10]\n",
            "Quantiles shape: torch.Size([9, 6])\n",
            "Epoch 1/5 - [train] loss: 226.742945\n",
            "  - [eval] logloss: 0.6107\n",
            "    -- (early_stopping) current_metric: 0.610688, best_metric: inf\n",
            "Epoch 2/5 - [train] loss: 130.932189\n",
            "  - [eval] logloss: 0.5732\n",
            "    -- (early_stopping) current_metric: 0.573194, best_metric: 0.610688\n",
            "Epoch 3/5 - [train] loss: 127.385031\n",
            "  - [eval] logloss: 0.6110\n",
            "    -- (early_stopping) current_metric: 0.611009, best_metric: 0.573194\n",
            "Epoch 4/5 - [train] loss: 125.481831\n",
            "  - [eval] logloss: 0.5632\n",
            "    -- (early_stopping) current_metric: 0.563169, best_metric: 0.573194\n",
            "Epoch 5/5 - [train] loss: 121.487501\n",
            "  - [eval] logloss: 0.5738\n",
            "    -- (early_stopping) current_metric: 0.573800, best_metric: 0.563169\n",
            "\n",
            "===== Tabular-Text Transformer Test Metrics =====\n",
            "Accuracy : 0.7800\n",
            "ROC-AUC  : 0.7830\n",
            "Logloss  : 0.5234\n",
            "Sample probs (first 10): [0.7973 0.7992 0.8087 0.8121 0.81   0.8034 0.8013 0.7987 0.8097 0.8068]\n"
          ]
        }
      ]
    }
  ]
}