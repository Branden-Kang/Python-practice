{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN9MfvYPchojtD2823jGfI0"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[Reference](https://medium.com/@francescofranco_39234/adam-optimization-in-machine-learning-cfeb10a27a86)"
      ],
      "metadata": {
        "id": "KofIfKH3mqgN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pwa6Ly10mKpL",
        "outputId": "e769fb53-7cff-441c-beba-28b6d681b23c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8774 - loss: 0.4345 - val_accuracy: 0.9608 - val_loss: 0.1359\n",
            "Epoch 2/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9663 - loss: 0.1182 - val_accuracy: 0.9727 - val_loss: 0.0939\n",
            "Epoch 3/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.9768 - loss: 0.0769 - val_accuracy: 0.9735 - val_loss: 0.0807\n",
            "Epoch 4/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.9837 - loss: 0.0542 - val_accuracy: 0.9760 - val_loss: 0.0741\n",
            "Epoch 5/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9856 - loss: 0.0457 - val_accuracy: 0.9768 - val_loss: 0.0786\n",
            "Epoch 6/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.9903 - loss: 0.0325 - val_accuracy: 0.9752 - val_loss: 0.0809\n",
            "Epoch 7/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.9918 - loss: 0.0265 - val_accuracy: 0.9758 - val_loss: 0.0827\n",
            "Epoch 8/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.9937 - loss: 0.0206 - val_accuracy: 0.9778 - val_loss: 0.0783\n",
            "Epoch 9/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9954 - loss: 0.0154 - val_accuracy: 0.9792 - val_loss: 0.0756\n",
            "Epoch 10/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.9960 - loss: 0.0136 - val_accuracy: 0.9764 - val_loss: 0.0881\n",
            "Epoch 1/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9980 - loss: 0.0082 - val_accuracy: 0.9809 - val_loss: 0.0725\n",
            "Epoch 2/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0041 - val_accuracy: 0.9813 - val_loss: 0.0730\n",
            "Epoch 3/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.9997 - loss: 0.0035 - val_accuracy: 0.9809 - val_loss: 0.0738\n",
            "Epoch 4/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 0.0031 - val_accuracy: 0.9804 - val_loss: 0.0742\n",
            "Epoch 5/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9999 - loss: 0.0025 - val_accuracy: 0.9808 - val_loss: 0.0748\n",
            "Epoch 6/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9999 - loss: 0.0023 - val_accuracy: 0.9804 - val_loss: 0.0754\n",
            "Epoch 7/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9999 - loss: 0.0020 - val_accuracy: 0.9809 - val_loss: 0.0752\n",
            "Epoch 8/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9999 - loss: 0.0020 - val_accuracy: 0.9810 - val_loss: 0.0754\n",
            "Epoch 9/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.9808 - val_loss: 0.0764\n",
            "Epoch 10/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.9809 - val_loss: 0.0768\n",
            "Epoch 1/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9992 - loss: 0.0039 - val_accuracy: 0.9789 - val_loss: 0.0860\n",
            "Epoch 2/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.9990 - loss: 0.0038 - val_accuracy: 0.9812 - val_loss: 0.0808\n",
            "Epoch 3/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.9993 - loss: 0.0028 - val_accuracy: 0.9796 - val_loss: 0.0945\n",
            "Epoch 4/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9994 - loss: 0.0028 - val_accuracy: 0.9800 - val_loss: 0.0970\n",
            "Epoch 5/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9997 - loss: 0.0016 - val_accuracy: 0.9805 - val_loss: 0.0945\n",
            "Epoch 6/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9998 - loss: 0.0012 - val_accuracy: 0.9804 - val_loss: 0.0983\n",
            "Epoch 7/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.9999 - loss: 0.0010 - val_accuracy: 0.9811 - val_loss: 0.0963\n",
            "Epoch 8/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9999 - loss: 6.8143e-04 - val_accuracy: 0.9798 - val_loss: 0.1023\n",
            "Epoch 9/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9999 - loss: 6.5060e-04 - val_accuracy: 0.9813 - val_loss: 0.1012\n",
            "Epoch 10/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9999 - loss: 6.0653e-04 - val_accuracy: 0.9809 - val_loss: 0.1050\n",
            "ADAM optimizer - Accuracy: 0.9953166842460632\n",
            "Momentum optimizer - Accuracy: 0.9999666810035706\n",
            "RMSprop optimizer - Accuracy: 0.9999499917030334\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Load the MNIST dataset\n",
        "mnist = keras.datasets.mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "# Preprocess the data\n",
        "train_images = train_images / 255\n",
        "test_images = test_images / 255\n",
        "\n",
        "# Define the model architecture\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    keras.layers.Dense(128, activation='relu'),\n",
        "    keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Define the optimizers\n",
        "adam_optimizer = tf.keras.optimizers.Adam()\n",
        "momentum_optimizer = tf.keras.optimizers.SGD(0.01, momentum=0.9)\n",
        "rmsprop_optimizer = tf.keras.optimizers.RMSprop()\n",
        "\n",
        "# Compile the model - adam_optimizer\n",
        "model.compile(optimizer=adam_optimizer,\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model - adam_optimizer\n",
        "adam_history = model.fit(train_images, train_labels, epochs=10, validation_data=(test_images, test_labels))\n",
        "\n",
        "# Compile the model - momentum_optimizer\n",
        "model.compile(optimizer=momentum_optimizer,\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model - momentum_optimizer\n",
        "momentum_history = model.fit(train_images, train_labels, epochs=10, validation_data=(test_images, test_labels))\n",
        "\n",
        "\n",
        "# Compile the model - rmsprop_optimizer\n",
        "model.compile(optimizer=rmsprop_optimizer,\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model - rmsprop_optimizer\n",
        "rmsprop_history = model.fit(train_images, train_labels, epochs=10, validation_data=(test_images, test_labels),)\n",
        "\n",
        "# Print the comparison results\n",
        "print(\"ADAM optimizer - Accuracy:\", adam_history.history['accuracy'][-1])\n",
        "print(\"Momentum optimizer - Accuracy:\", momentum_history.history['accuracy'][-1])\n",
        "print(\"RMSprop optimizer - Accuracy:\", rmsprop_history.history['accuracy'][-1])"
      ]
    }
  ]
}