{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPSfKYwlo2atl9WFW5EMVxR"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[Reference](https://medium.com/h7w/kullback-leibler-divergence-with-keras-227ef84f2a1b)"
      ],
      "metadata": {
        "id": "9zFFIaO9nR05"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K-23TEOhnO4N",
        "outputId": "295811b2-6a00-40e0-e613-f92605d33c72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 340ms/step - accuracy: 0.2338 - loss: 2.0634 - val_accuracy: 0.4431 - val_loss: 1.5970\n",
            "Epoch 2/25\n",
            "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 322ms/step - accuracy: 0.4457 - loss: 1.5359 - val_accuracy: 0.5257 - val_loss: 1.3871\n",
            "Epoch 3/25\n",
            "\u001b[1m 72/160\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m24s\u001b[0m 283ms/step - accuracy: 0.5055 - loss: 1.3720"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "# Model configuration\n",
        "img_width, img_height = 32, 32\n",
        "batch_size = 250\n",
        "no_epochs = 25\n",
        "no_classes = 10\n",
        "validation_split = 0.2\n",
        "verbosity = 1\n",
        "\n",
        "# Load CIFAR10 dataset\n",
        "(input_train, target_train), (input_test, target_test) = cifar10.load_data()\n",
        "\n",
        "# Reshape data based on backend image data format\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    input_train = input_train.reshape(input_train.shape[0], 3, img_width, img_height)\n",
        "    input_test = input_test.reshape(input_test.shape[0], 3, img_width, img_height)\n",
        "    input_shape = (3, img_width, img_height)\n",
        "else:\n",
        "    input_train = input_train.reshape(input_train.shape[0], img_width, img_height, 3)\n",
        "    input_test = input_test.reshape(input_test.shape[0], img_width, img_height, 3)\n",
        "    input_shape = (img_width, img_height, 3)\n",
        "\n",
        "# Normalize data\n",
        "input_train = input_train.astype('float32') / 255\n",
        "input_test = input_test.astype('float32') / 255\n",
        "\n",
        "# Convert class vectors to binary class matrices\n",
        "target_train = to_categorical(target_train, no_classes)\n",
        "target_test = to_categorical(target_test, no_classes)\n",
        "\n",
        "# Build the model\n",
        "model = Sequential([\n",
        "    Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Dropout(0.5),\n",
        "    Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Dropout(0.5),\n",
        "    Flatten(),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dense(no_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    loss=tf.keras.losses.KLDivergence(),\n",
        "    optimizer=tf.keras.optimizers.Adam(),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "model.fit(\n",
        "    input_train, target_train,\n",
        "    batch_size=batch_size,\n",
        "    epochs=no_epochs,\n",
        "    verbose=verbosity,\n",
        "    validation_split=validation_split\n",
        ")\n",
        "\n",
        "# Evaluate the model\n",
        "score = model.evaluate(input_test, target_test, verbose=0)\n",
        "print(f'Test loss: {score[0]:.4f} / Test accuracy: {score[1]:.4f}')"
      ]
    }
  ]
}