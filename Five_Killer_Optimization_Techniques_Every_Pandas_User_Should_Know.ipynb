{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Five Killer Optimization Techniques Every Pandas User Should Know.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNBy1oqyTe/ABl6laZb8Uir"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[Reference](https://towardsdatascience.com/five-killer-optimization-techniques-every-pandas-user-should-know-266662bd1163)"
      ],
      "metadata": {
        "id": "o1xd1WL81Doa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Input/Output on CSV\n"
      ],
      "metadata": {
        "id": "Dp1ERIfk1IMt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gD32IsxB1BU1"
      },
      "outputs": [],
      "source": [
        "# import pandas as pd\n",
        "\n",
        "# file_name = \"path/to/csv/file.csv\"\n",
        "# data = pd.read_csv(file_name)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import pandas as pd\n",
        "\n",
        "# data = pd.read_csv(\"path/to/file.csv\")\n",
        "\n",
        "# ## To Pickle\n",
        "# data.to_pickle(\"path/to/file.pickle\")\n",
        "\n",
        "# ## To Parquet\n",
        "# data.to_parquet(\"path/to/file.parquet\")\n",
        "\n",
        "# ## To Feather\n",
        "# data.to_feather(\"path/to/file.feather\")"
      ],
      "metadata": {
        "id": "KnV52nM21LJQ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import pandas as pd\n",
        "\n",
        "# ## From Pickle\n",
        "# pickle_data = pd.read_pickle(\"path/to/file.pickle\")\n",
        "\n",
        "# ## From Parquet\n",
        "# parquet_data = pd.read_parquet(\"path/to/file.parquet\")\n",
        "\n",
        "# ## From Feather\n",
        "# feather_data = pd.read_feather(\"path/to/file.feather\")"
      ],
      "metadata": {
        "id": "RWqGdCUn1PMV"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(\"Pickle DataFrame Type: \", type(pickle_data))\n",
        "# print(\"Parquet DataFrame Type: \", type(parquet_data))\n",
        "# print(\"Feather DataFrame Type: \", type(feather_data))"
      ],
      "metadata": {
        "id": "ku8DIj6p1RFz"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datatable"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bi7W05A81S00",
        "outputId": "f83dcbd8-6fcc-4ae2-eddf-9e6ca974dfbe"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting datatable\n",
            "  Downloading datatable-1.0.0-cp37-cp37m-manylinux_2_12_x86_64.whl (96.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 96.9 MB 83 kB/s \n",
            "\u001b[?25hInstalling collected packages: datatable\n",
            "Successfully installed datatable-1.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import datatable as dt\n",
        "# import pandas as pd\n",
        "\n",
        "# csv_file = \"path/to/file.csv\"\n",
        "\n",
        "# dt_df = dt.fread(csv_file)\n",
        "# pd_df = dt_df.to_pandas()\n",
        "\n",
        "# print(\"Data type of dt_df:\", type(dt_df))\n",
        "# print(\"Data type of pd_df:\", type(pd_df))"
      ],
      "metadata": {
        "id": "IPqspr0m1Xe3"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import datatable as dt\n",
        "# import pandas as pd\n",
        "\n",
        "# df_data = pd.DataFrame([[1, 2], [3, 4]], columns = list(\"AB\"))\n",
        "\n",
        "# dt_data = dt.Frame(df_data)\n",
        "# dt_data.to_csv(\"path/to/file.csv\")\n",
        "\n",
        "# print(\"Data type of df_data:\", type(df_data))\n",
        "# print(\"Data type of dt_data:\", type(dt_data))"
      ],
      "metadata": {
        "id": "V_nDGQRN1ZAV"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Filtering Based on Categorical data\n"
      ],
      "metadata": {
        "id": "LQ5VyWuj1dhx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "city_list = [\"New York\", \"Manchester\", \"California\", \"Munich\", \"Bombay\", \n",
        "             \"Sydeny\", \"London\", \"Moscow\", \"Dubai\", \"Tokyo\"]\n",
        "\n",
        "job_list = [\"Software Development Engineer\", \"Research Engineer\", \n",
        "            \"Test Engineer\", \"Software Development Engineer-II\", \n",
        "            \"Python Developer\", \"Back End Developer\", \n",
        "            \"Front End Developer\", \"Data Scientist\", \n",
        "            \"IOS Developer\", \"Android Developer\"]\n",
        "\n",
        "cmp_list = [\"Amazon\", \"Google\", \"Infosys\", \"Mastercard\", \"Microsoft\", \n",
        "            \"Uber\", \"IBM\", \"Apple\", \"Wipro\", \"Cognizant\"]\n",
        "\n",
        "data = []\n",
        "for i in range(4_096_000):\n",
        "  \n",
        "    company = random.choice(cmp_list)\n",
        "    job = random.choice(job_list)\n",
        "    city = random.choice(city_list)\n",
        "    salary = int(round(np.random.rand(), 3)*10**6)\n",
        "    employment = random.choices([\"Full Time\", \"Intern\"], weights=(80, 20))[0]\n",
        "    rating = round((np.random.rand()*5), 1)\n",
        "    \n",
        "    data.append([company, job, city, salary, employment, rating])\n",
        "    \n",
        "data = pd.DataFrame(data, columns=[\"Company Name\", \"Employee Job Title\",\n",
        "                                   \"Employee Work Location\",  \"Employee Salary\", \n",
        "                                   \"Employment Status\", \"Employee Rating\"])"
      ],
      "metadata": {
        "id": "tJX8pSBn1bXo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%timeit\n",
        "data[data[\"Company Name\"] == \"Amazon\"]"
      ],
      "metadata": {
        "id": "PwmqBIoy1gTw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_grp = data.groupby(\"Company Name\")"
      ],
      "metadata": {
        "id": "fr01c69m1yyi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%timeit\n",
        "data_grp.get_group(\"Amazon\")"
      ],
      "metadata": {
        "id": "ojWnprBv1i74"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Approach 1\n",
        "\n",
        "df1 = data[data[\"Company Name\"] == \"Amazon\"]\n",
        "print(\"df1 type: \", type(df1))\n",
        "\n",
        "## Approach 2\n",
        "\n",
        "df2 = data_grp.get_group(\"Amazon\")\n",
        "print(\"df2 type: \", type(df2))"
      ],
      "metadata": {
        "id": "KLn1y5Ky1mdi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Merging DataFrames\n"
      ],
      "metadata": {
        "id": "js1GISbV1qy2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df1 = pd.DataFrame([[\"A\", 1], [\"B\", 2]], columns = [\"col_a\", \"col_b\"])\n",
        "df2 = pd.DataFrame([[\"A\", 3], [\"B\", 4]], columns = [\"col_a\", \"col_c\"])\n",
        "\n",
        "pd.merge(df1, df2, on = \"col_a\", how = \"inner\")"
      ],
      "metadata": {
        "id": "FaNEpQFA1pDe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df1 = pd.DataFrame([[\"A\", 1], [\"B\", 2]], columns = [\"col_a\", \"col_b\"])\n",
        "df2 = pd.DataFrame([[\"A\", 3], [\"B\", 4]], columns = [\"col_a\", \"col_c\"])"
      ],
      "metadata": {
        "id": "EI-0B3s014CR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Method 1: pd.merge()\n",
        "%%timeit\n",
        "pd.merge(df1, df2, on = \"col_a\", how = \"inner\")"
      ],
      "metadata": {
        "id": "2Z7yflLW1uUD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Method 2: join()\n",
        "\n",
        "## Make the merge column as the index.\n",
        "df1.set_index(\"col_a\", inplace=True)\n",
        "df2.set_index(\"col_a\", inplace=True)"
      ],
      "metadata": {
        "id": "wMzK6VqM157q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%timeit\n",
        "df1.join(df2)"
      ],
      "metadata": {
        "id": "JNbSibTu12so"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df1 = pd.DataFrame([[\"A\", \"B\", 1], [\"C\", \"D\", 2]], \n",
        "                   columns = [\"col_a\", \"col_b\", \"col_c\"])\n",
        "df2 = pd.DataFrame([[\"A\", \"B\", 3], [\"C\", \"D\", 4]], \n",
        "                   columns = [\"col_a\", \"col_b\", \"col_d\"])\n",
        "\n",
        "df1.set_index([\"col_a\", \"col_b\"], inplace=True)\n",
        "df2.set_index([\"col_a\", \"col_b\"], inplace=True)\n",
        "\n",
        "df1.join(df2)"
      ],
      "metadata": {
        "id": "O2i4STAH16qt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Value_counts() vs GroupBy()\n"
      ],
      "metadata": {
        "id": "BU_XEt7t19mV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data[\"Company Name\"].value_counts()"
      ],
      "metadata": {
        "id": "sa1KbXWQ18Ij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.groupby(\"Company Name\").size()"
      ],
      "metadata": {
        "id": "-OuSsra92AIa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%timeit\n",
        "data[\"Company Name\"].value_counts()"
      ],
      "metadata": {
        "id": "_BGPTkfz2Cec"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%timeit\n",
        "data.groupby(\"Company Name\").size()"
      ],
      "metadata": {
        "id": "gSaXCbNZ2GbK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%timeit\n",
        "data[\"Company Name\"].value_counts(normalize=True)"
      ],
      "metadata": {
        "id": "G_W5qR-J2Hqf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%timeit\n",
        "a = data.groupby(\"Company Name\").size()\n",
        "b = a/a.sum()"
      ],
      "metadata": {
        "id": "x62tYSI62KLS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Iterating over a DataFrame\n"
      ],
      "metadata": {
        "id": "riFFU5Dd2RHN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Method 1: Iterate using range(len(df))"
      ],
      "metadata": {
        "id": "2Rw1uSJL2bAq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def apply_loop(df):\n",
        "    salary_sum = 0\n",
        "    \n",
        "    for i in range(len(df)):\n",
        "        salary_sum += df.iloc[i]['Employee Salary']\n",
        "\n",
        "    return salary_sum/df.shape[0]"
      ],
      "metadata": {
        "id": "5zAjq_Gm2LRy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%timeit\n",
        "apply_loop(data)"
      ],
      "metadata": {
        "id": "xsEJtfQF2UbN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Method 2: Iterate using iterrows()\n"
      ],
      "metadata": {
        "id": "0cpvJgdk2Zvz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def salary_iterrows(df):\n",
        "    salary_sum = 0\n",
        "    \n",
        "    for index, row in df.iterrows():\n",
        "        salary_sum += row['Employee Salary']\n",
        "        \n",
        "    return salary_sum/df.shape[0]"
      ],
      "metadata": {
        "id": "KRccbCO72dy0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%timeit\n",
        "salary_iterrows(data)"
      ],
      "metadata": {
        "id": "LYDss3T32czr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Method 3: Iterate using itertuples()\n"
      ],
      "metadata": {
        "id": "wdc_erxX2gGz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def salary_itertuples(df):\n",
        "    salary_sum = 0\n",
        "    \n",
        "    for row in df.itertuples(): \n",
        "        salary_sum += row._4\n",
        "        \n",
        "    return salary_sum/df.shape[0]"
      ],
      "metadata": {
        "id": "eqGiHNnp2iWu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%timeit\n",
        "salary_itertuples(data)"
      ],
      "metadata": {
        "id": "8UnI5gVw2fBu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}