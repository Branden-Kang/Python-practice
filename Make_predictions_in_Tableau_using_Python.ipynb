{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Make predictions in Tableau using Python.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOVLQo4dObnVq/+/O5SdUXk"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[Reference](https://medium.com/@kenanekici/make-predictions-in-tableau-using-python-13ef3a1571c3)"
      ],
      "metadata": {
        "id": "SjNNNABae6kq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ZXK880je5AX",
        "outputId": "dfdfc8b4-61a2-4701-fcba-1eb10debff93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tabpy\n",
            "  Downloading tabpy-2.5.0-py2.py3-none-any.whl (110 kB)\n",
            "\u001b[K     |████████████████████████████████| 110 kB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (0.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.3.5)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.7/dist-packages (0.11.2)\n",
            "Collecting pickle-mixin\n",
            "  Downloading pickle-mixin-1.0.2.tar.gz (5.1 kB)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from tabpy) (4.3.3)\n",
            "Requirement already satisfied: tornado in /usr/local/lib/python3.7/dist-packages (from tabpy) (5.1.1)\n",
            "Collecting twisted\n",
            "  Downloading Twisted-22.4.0-py3-none-any.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 38.9 MB/s \n",
            "\u001b[?25hCollecting genson\n",
            "  Downloading genson-1.2.2.tar.gz (34 kB)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from tabpy) (3.7)\n",
            "Collecting simplejson\n",
            "  Downloading simplejson-3.17.6-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (130 kB)\n",
            "\u001b[K     |████████████████████████████████| 130 kB 48.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from tabpy) (1.3.0)\n",
            "Collecting mock\n",
            "  Downloading mock-4.0.3-py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: coveralls in /usr/local/lib/python3.7/dist-packages (from tabpy) (0.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from tabpy) (1.4.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from tabpy) (1.24.3)\n",
            "Collecting configparser\n",
            "  Downloading configparser-5.2.0-py3-none-any.whl (19 kB)\n",
            "Collecting pytest-cov\n",
            "  Downloading pytest_cov-3.0.0-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from tabpy) (2.23.0)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.7/dist-packages (from tabpy) (3.6.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tabpy) (1.21.6)\n",
            "Requirement already satisfied: textblob in /usr/local/lib/python3.7/dist-packages (from tabpy) (0.15.3)\n",
            "Collecting hypothesis\n",
            "  Downloading hypothesis-6.48.2-py3-none-any.whl (387 kB)\n",
            "\u001b[K     |████████████████████████████████| 387 kB 69.0 MB/s \n",
            "\u001b[?25hCollecting pyopenssl\n",
            "  Downloading pyOpenSSL-22.0.0-py2.py3-none-any.whl (55 kB)\n",
            "\u001b[K     |████████████████████████████████| 55 kB 4.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: coverage in /usr/local/lib/python3.7/dist-packages (from tabpy) (3.7.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from tabpy) (0.16.0)\n",
            "Requirement already satisfied: docopt in /usr/local/lib/python3.7/dist-packages (from tabpy) (0.6.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn) (1.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2022.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Requirement already satisfied: matplotlib>=2.2 in /usr/local/lib/python3.7/dist-packages (from seaborn) (3.2.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn) (1.4.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn) (0.11.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib>=2.2->seaborn) (4.1.1)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.7/dist-packages (from coveralls->tabpy) (3.13)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->tabpy) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->tabpy) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->tabpy) (2022.6.15)\n",
            "Requirement already satisfied: sortedcontainers<3.0.0,>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from hypothesis->tabpy) (2.4.0)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.7/dist-packages (from hypothesis->tabpy) (21.4.0)\n",
            "Collecting exceptiongroup>=1.0.0rc8\n",
            "  Downloading exceptiongroup-1.0.0rc8-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->tabpy) (0.18.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonschema->tabpy) (4.11.4)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->tabpy) (5.7.1)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources>=1.4.0->jsonschema->tabpy) (3.8.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk->tabpy) (1.1.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk->tabpy) (2022.6.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk->tabpy) (7.1.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk->tabpy) (4.64.0)\n",
            "Collecting cryptography>=35.0\n",
            "  Downloading cryptography-37.0.2-cp36-abi3-manylinux_2_24_x86_64.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 39.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=35.0->pyopenssl->tabpy) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=35.0->pyopenssl->tabpy) (2.21)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.7/dist-packages (from pytest->tabpy) (0.7.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from pytest->tabpy) (57.4.0)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pytest->tabpy) (1.11.0)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.7/dist-packages (from pytest->tabpy) (1.4.0)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytest->tabpy) (8.13.0)\n",
            "Collecting pytest\n",
            "  Downloading pytest-7.1.2-py3-none-any.whl (297 kB)\n",
            "\u001b[K     |████████████████████████████████| 297 kB 64.3 MB/s \n",
            "\u001b[?25hCollecting coverage[toml]>=5.2.1\n",
            "  Downloading coverage-6.4.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (208 kB)\n",
            "\u001b[K     |████████████████████████████████| 208 kB 48.5 MB/s \n",
            "\u001b[?25h  Downloading coverage-6.4-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (208 kB)\n",
            "\u001b[K     |████████████████████████████████| 208 kB 46.2 MB/s \n",
            "\u001b[?25h  Downloading coverage-6.3.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (207 kB)\n",
            "\u001b[K     |████████████████████████████████| 207 kB 48.0 MB/s \n",
            "\u001b[?25h  Downloading coverage-6.3.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (207 kB)\n",
            "\u001b[K     |████████████████████████████████| 207 kB 20.4 MB/s \n",
            "\u001b[?25h  Downloading coverage-6.3.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (207 kB)\n",
            "\u001b[K     |████████████████████████████████| 207 kB 52.9 MB/s \n",
            "\u001b[?25h  Downloading coverage-6.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (207 kB)\n",
            "\u001b[K     |████████████████████████████████| 207 kB 6.9 MB/s \n",
            "\u001b[?25h  Downloading coverage-6.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (213 kB)\n",
            "\u001b[K     |████████████████████████████████| 213 kB 6.7 MB/s \n",
            "\u001b[?25h  Downloading coverage-6.1.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (213 kB)\n",
            "\u001b[K     |████████████████████████████████| 213 kB 45.5 MB/s \n",
            "\u001b[?25h  Downloading coverage-6.1.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (213 kB)\n",
            "\u001b[K     |████████████████████████████████| 213 kB 26.1 MB/s \n",
            "\u001b[?25h  Downloading coverage-6.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (213 kB)\n",
            "\u001b[K     |████████████████████████████████| 213 kB 46.1 MB/s \n",
            "\u001b[?25h  Downloading coverage-6.0.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (253 kB)\n",
            "\u001b[K     |████████████████████████████████| 253 kB 50.9 MB/s \n",
            "\u001b[?25h  Downloading coverage-6.0.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (252 kB)\n",
            "\u001b[K     |████████████████████████████████| 252 kB 45.6 MB/s \n",
            "\u001b[?25h  Downloading coverage-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (252 kB)\n",
            "\u001b[K     |████████████████████████████████| 252 kB 54.4 MB/s \n",
            "\u001b[?25h  Downloading coverage-5.5-cp37-cp37m-manylinux2010_x86_64.whl (242 kB)\n",
            "\u001b[K     |████████████████████████████████| 242 kB 50.9 MB/s \n",
            "\u001b[?25h  Downloading coverage-5.4-cp37-cp37m-manylinux2010_x86_64.whl (242 kB)\n",
            "\u001b[K     |████████████████████████████████| 242 kB 45.6 MB/s \n",
            "\u001b[?25h  Downloading coverage-5.3.1-cp37-cp37m-manylinux2010_x86_64.whl (242 kB)\n",
            "\u001b[K     |████████████████████████████████| 242 kB 44.8 MB/s \n",
            "\u001b[?25h  Downloading coverage-5.3-cp37-cp37m-manylinux1_x86_64.whl (229 kB)\n",
            "\u001b[K     |████████████████████████████████| 229 kB 45.1 MB/s \n",
            "\u001b[?25h  Downloading coverage-5.2.1-cp37-cp37m-manylinux1_x86_64.whl (229 kB)\n",
            "\u001b[K     |████████████████████████████████| 229 kB 47.2 MB/s \n",
            "\u001b[?25hINFO: pip is looking at multiple versions of pytest-cov to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting pytest-cov\n",
            "  Downloading pytest_cov-2.12.1-py2.py3-none-any.whl (20 kB)\n",
            "  Downloading pytest_cov-2.12.0-py2.py3-none-any.whl (20 kB)\n",
            "  Downloading pytest_cov-2.11.1-py2.py3-none-any.whl (20 kB)\n",
            "  Downloading pytest_cov-2.11.0-py2.py3-none-any.whl (20 kB)\n",
            "  Downloading pytest_cov-2.10.1-py2.py3-none-any.whl (19 kB)\n",
            "  Downloading pytest_cov-2.10.0-py2.py3-none-any.whl (19 kB)\n",
            "  Downloading pytest_cov-2.9.0-py2.py3-none-any.whl (19 kB)\n",
            "  Downloading pytest_cov-2.8.1-py2.py3-none-any.whl (18 kB)\n",
            "  Downloading pytest_cov-2.8.0-py2.py3-none-any.whl (18 kB)\n",
            "  Downloading pytest_cov-2.7.1-py2.py3-none-any.whl (17 kB)\n",
            "  Downloading pytest_cov-2.7.0-py2.py3-none-any.whl (17 kB)\n",
            "  Downloading pytest_cov-2.6.1-py2.py3-none-any.whl (16 kB)\n",
            "  Downloading pytest_cov-2.6.0-py2.py3-none-any.whl (14 kB)\n",
            "  Downloading pytest_cov-2.5.1-py2.py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (3.1.0)\n",
            "Collecting constantly>=15.1\n",
            "  Downloading constantly-15.1.0-py2.py3-none-any.whl (7.9 kB)\n",
            "Collecting zope.interface>=4.4.2\n",
            "  Downloading zope.interface-5.4.0-cp37-cp37m-manylinux2010_x86_64.whl (251 kB)\n",
            "\u001b[K     |████████████████████████████████| 251 kB 46.5 MB/s \n",
            "\u001b[?25hCollecting Automat>=0.8.0\n",
            "  Downloading Automat-20.2.0-py2.py3-none-any.whl (31 kB)\n",
            "Collecting incremental>=21.3.0\n",
            "  Downloading incremental-21.3.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting hyperlink>=17.1.1\n",
            "  Downloading hyperlink-21.0.0-py2.py3-none-any.whl (74 kB)\n",
            "\u001b[K     |████████████████████████████████| 74 kB 1.4 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pickle-mixin, genson\n",
            "  Building wheel for pickle-mixin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pickle-mixin: filename=pickle_mixin-1.0.2-py3-none-any.whl size=6008 sha256=e1b367ff10624f8f072efa268ab4f9d0c8d382d8c22bc10629740b791f2e7a76\n",
            "  Stored in directory: /root/.cache/pip/wheels/d0/70/0b/673e09a7ed429660d22352a1b117b4f616a8fc054bdd7eb157\n",
            "  Building wheel for genson (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for genson: filename=genson-1.2.2-py2.py3-none-any.whl size=21292 sha256=878205481d662fb8aaa1db11407a6c567884ddddddab977947f7577d4bfb5d48\n",
            "  Stored in directory: /root/.cache/pip/wheels/2e/34/be/0194d05d18bc4695b5c4969178790d535bdd23eabdb9d3b1e3\n",
            "Successfully built pickle-mixin genson\n",
            "Installing collected packages: zope.interface, incremental, hyperlink, exceptiongroup, cryptography, constantly, Automat, twisted, simplejson, pytest-cov, pyopenssl, mock, hypothesis, genson, configparser, tabpy, pickle-mixin\n",
            "Successfully installed Automat-20.2.0 configparser-5.2.0 constantly-15.1.0 cryptography-37.0.2 exceptiongroup-1.0.0rc8 genson-1.2.2 hyperlink-21.0.0 hypothesis-6.48.2 incremental-21.3.0 mock-4.0.3 pickle-mixin-1.0.2 pyopenssl-22.0.0 pytest-cov-2.5.1 simplejson-3.17.6 tabpy-2.5.0 twisted-22.4.0 zope.interface-5.4.0\n"
          ]
        }
      ],
      "source": [
        "!pip install tabpy sklearn pandas seaborn pickle-mixin "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tabpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QttIIsSRfKUj",
        "outputId": "340b46fb-4358-48fe-e1c8-47649f530c47"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-07-02,05:58:49 [INFO] (app.py:app:244): Parsing config file /usr/local/lib/python3.7/dist-packages/tabpy/tabpy_server/app/../common/default.conf\n",
            "2022-07-02,05:58:49 [INFO] (app.py:app:436): Loading state from state file /usr/local/lib/python3.7/dist-packages/tabpy/tabpy_server/state.ini\n",
            "2022-07-02,05:58:49 [INFO] (app.py:app:333): Password file is not specified: Authentication is not enabled\n",
            "2022-07-02,05:58:49 [INFO] (app.py:app:347): Call context logging is disabled\n",
            "2022-07-02,05:58:49 [INFO] (app.py:app:125): Initializing TabPy...\n",
            "2022-07-02,05:58:49 [INFO] (callbacks.py:callbacks:43): Initializing TabPy Server...\n",
            "2022-07-02,05:58:49 [INFO] (app.py:app:129): Done initializing TabPy.\n",
            "2022-07-02,05:58:49 [INFO] (app.py:app:83): Setting max request size to 104857600 bytes\n",
            "2022-07-02,05:58:49 [INFO] (callbacks.py:callbacks:64): Initializing models...\n",
            "2022-07-02,05:58:49 [INFO] (app.py:app:107): Web service listening on port 9004\n",
            "2022-07-02,06:02:04 [CRITICAL] (app.py:app:117): Exiting on signal 2...\n",
            "2022-07-02,06:02:04 [CRITICAL] (app.py:app:117): Exiting on signal 2...\n",
            "2022-07-02,06:02:04 [INFO] (app.py:app:123): Shutting down TabPy...\n",
            "2022-07-02,06:02:04 [INFO] (app.py:app:123): Shutting down TabPy...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training the model and deploying the predict function\n"
      ],
      "metadata": {
        "id": "6DYkeGnFfMjI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import f1_score, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_selection import chi2\n",
        "from sklearn.metrics import f1_score\n",
        "import pickle\n",
        "\n",
        "def clean_text(X):\n",
        "    # remove mentions\n",
        "    X = X.str.lower().str.replace('@[A-Za-z0-9]+', ' ', regex=True)\n",
        "    # remove links\n",
        "    X = X.str.replace('http\\S+', ' ', regex=True)\n",
        "    # remove non alphabet\n",
        "    X = X.str.replace('[^a-zA-Z]+', ' ', regex=True)\n",
        "    # remove extra whitespaces\n",
        "    X = X.str.replace('\\s+', ' ', regex=True).str.strip()\n",
        "    return X\n",
        "\n",
        "def train_model():\n",
        "    # load and prepare data\n",
        "    tweets = pd.read_csv(\"tweets_train_test.csv\")\n",
        "    y = tweets[\"airline_sentiment\"]\n",
        "    X = tweets[\"text\"]\n",
        "    n_positives = len(y[y==\"positive\"])\n",
        "    y_neg = y[y==\"negative\"].sample(n_positives)\n",
        "    y_pos = y[y==\"positive\"]\n",
        "    y = pd.concat([y_neg,y_pos])\n",
        "    X = X.loc[y.index].reset_index(drop=True)\n",
        "    y = y.reset_index(drop=True)\n",
        "\n",
        "    # clean\n",
        "    X = clean_text(X)\n",
        "\n",
        "    # feature selection\n",
        "    temp_vectorizer = TfidfVectorizer(stop_words= 'english')\n",
        "    X_ = temp_vectorizer.fit_transform(X)\n",
        "    n_features=700\n",
        "    chi2score = chi2(X_,y)[0]\n",
        "    wscores = zip(temp_vectorizer.get_feature_names(),chi2score)\n",
        "    wchi2 = sorted(wscores,key=lambda x:x[1]) \n",
        "    topchi2 = wchi2[-n_features:]\n",
        "    labels = [t for t, ch in topchi2]\n",
        "    \n",
        "    # fit and transform with selected features \n",
        "    vectorizer = TfidfVectorizer(vocabulary=labels)\n",
        "    X = vectorizer.fit_transform(X)\n",
        "\n",
        "    # train classifier\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True)\n",
        "    sentiment_model = SVC(random_state=0)\n",
        "    sentiment_model.fit(X_train, y_train)\n",
        "    preds = sentiment_model.predict(X_test)\n",
        "    true = list(y_test)\n",
        "\n",
        "    # evaluate\n",
        "    conf_matr = confusion_matrix(true, preds, labels=[\"positive\", \"negative\"])\n",
        "    ax = sns.heatmap(conf_matr, annot=True, cbar=False, fmt='g', cmap='Blues')\n",
        "    ax.set_ylabel(\"True label\")\n",
        "    ax.set_xlabel(\"Predicted\")\n",
        "    ax.set_xticklabels([\"Positive\", \"Negative\"])\n",
        "    ax.set_yticklabels([\"Positive\",  \"Negative\"])\n",
        "    print(f1_score(preds, y_test, average=\"macro\"))\n",
        "\n",
        "    # export vectorizer and model\n",
        "    # Store data (serialize)\n",
        "    with open('vectorizer.pickle', 'wb') as v:\n",
        "        pickle.dump(vectorizer, v)\n",
        "\n",
        "    # Load data (deserialize)\n",
        "    with open('model.pickle', 'wb') as m:\n",
        "        pickle.dump(sentiment_model, m)\n",
        "\n",
        "# this is the function that we deploy to TabPy\n",
        "def predict(list_of_strings):\n",
        "    X = pd.DataFrame(list_of_strings, columns=[\"text\"])\n",
        "    X = clean_text(X[\"text\"])\n",
        "    with open('vectorizer.pickle', 'rb') as vectorizer:\n",
        "        vectorizer = pickle.load(vectorizer)\n",
        "    with open('model.pickle', 'rb') as model:\n",
        "        model = pickle.load(model)\n",
        "\n",
        "    X = vectorizer.fit_transform(X)\n",
        "    return list(model.predict(X))\n",
        "\n",
        "train_model()\n",
        "\n",
        "# deploy predict function to TabPy\n",
        "from tabpy.tabpy_tools.client import Client\n",
        "client = Client('http://localhost:9004/')\n",
        "client.deploy('predict', predict, 'predict', override=True)"
      ],
      "metadata": {
        "id": "fPvIS6X8fLj_"
      },
      "execution_count": 3,
      "outputs": []
    }
  ]
}