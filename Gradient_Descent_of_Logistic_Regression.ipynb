{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPPUHBn4mAIaCks13rzIURy"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[Reference](https://medium.com/@Coursesteach/deep-learning-part-8-05718b250906)"
      ],
      "metadata": {
        "id": "nFfUQMUn6-j6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GH3IKGPQ68iV"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "data = pd.read_csv(\"train.csv\")\n",
        "\n",
        "X = data.drop(\"target\", axis=1)\n",
        "y = data[\"target\"]\n",
        "\n",
        "theta = np.random.randn(X.shape[1])\n",
        "\n",
        "def sigmoid(z):\n",
        "    return 1 / (1 + np.exp(-z))\n",
        "\n",
        "def loss(theta, X, y):\n",
        "    h = sigmoid(X.dot(theta))\n",
        "    return -np.sum(y * np.log(h) + (1 - y) * np.log(1 - h))\n",
        "\n",
        "def gradient_descent(theta, X, y, alpha, num_iterations):\n",
        "    for i in range(num_iterations):\n",
        "        h = sigmoid(X.dot(theta))\n",
        "        gradient = X.T.dot(y - h)\n",
        "        theta -= alpha * gradient\n",
        "    return theta\n",
        "\n",
        "theta = gradient_descent(theta, X, y, alpha=0.01, num_iterations=1000)\n",
        "\n",
        "def predict(theta, X):\n",
        "    h = sigmoid(X.dot(theta))\n",
        "    y_pred = np.where(h >= 0.5, 1, 0)\n",
        "    return y_pred\n",
        "\n",
        "y_pred = predict(theta, X)\n",
        "\n",
        "accuracy = np.mean(y_pred == y)\n",
        "print(\"Accuracy:\", accuracy)"
      ]
    }
  ]
}