{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN7/51/aTSU5o2w1/SHk72A"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[Reference](https://levelup.gitconnected.com/mastering-feature-engineering-process-in-data-science-6897ba5a2d7a)"
      ],
      "metadata": {
        "id": "rrjF4FkEU1uw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "XmInBV_eUXgD"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "file_path = 'patient_data.csv'\n",
        "dataset = pd.read_csv(file_path)\n",
        "\n",
        "# Display the first few rows of the dataset to understand its structure\n",
        "dataset.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculating statistical summary for numerical variables\n",
        "numerical_summary = dataset.describe()\n",
        "\n",
        "# Calculating summary for categorical variables\n",
        "categorical_summary = dataset.describe(include=['object'])\n",
        "numerical_summary, categorical_summary"
      ],
      "metadata": {
        "id": "5Es4Zf53U5vy"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Calculating the correlation between Weight and Height\n",
        "correlation = dataset['Weight'].corr(dataset['Height'])\n",
        "\n",
        "# Creating a scatter plot to visualize the relationship between Weight and Height\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.scatterplot(data=dataset, x='Height', y='Weight')\n",
        "plt.title('Relationship between Weight and Height of Patients')\n",
        "plt.xlabel('Height (cm)')\n",
        "plt.ylabel('Weight (kg)')\n",
        "plt.grid(True)\n",
        "\n",
        "# Displaying the correlation coefficient\n",
        "plt.figtext(0.5, 0.01, f\"Correlation Coefficient: {correlation:.2f}\", ha=\"center\", fontsize=12, bbox={\"facecolor\":\"orange\", \"alpha\":0.5, \"pad\":5})\n",
        "plt.show()\n",
        "\n",
        "correlation"
      ],
      "metadata": {
        "id": "awx_w_EEU8LZ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculating the Body Mass Index (BMI)\n",
        "dataset['BMI'] = (dataset['Weight'] / (dataset['Height'] / 100) ** 2).round(0)\n",
        "\n",
        "# Displaying the first few lines of the dataset to check the new column\n",
        "dataset.head()"
      ],
      "metadata": {
        "id": "zmX-r2nkU-1r"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "try:\n",
        "\n",
        "# Calculating BMI\n",
        " dataset['BMI'] = (dataset['Weight'] / ((dataset['Height'] / 100) ** 2)).round(0)\n",
        "\n",
        "# Creating and displaying the BMI distribution graph\n",
        " plt.figure(figsize=(10, 6))\n",
        " sns.histplot(dataset['BMI'], bins=20, kde=True)\n",
        " plt.title('Distribution of Body Mass Index (BMI) of Patients')\n",
        " plt.xlabel('BMI')\n",
        " plt.ylabel('Frequency')\n",
        " plt.grid(True)\n",
        " plt.show()\n",
        "except Exception as e:\n",
        " print(f\"An error occurred: {e}\")"
      ],
      "metadata": {
        "id": "nhA5pLmDVBGP"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing the Weight and Height variables from the dataset\n",
        "dataset = dataset.drop(['Weight', 'Height'], axis=1)\n",
        "\n",
        "# Displaying the first few lines of the dataset to check the changes\n",
        "dataset.head()"
      ],
      "metadata": {
        "id": "Qk1ad93-VDfZ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# New column with the first 5 digits of 'Patient_ID'\n",
        "dataset['Patient_Hist_Code'] = dataset['Patient_ID'].str[:5]\n",
        "\n",
        "# Displaying the first few lines of the dataset to check the new column\n",
        "dataset.head()"
      ],
      "metadata": {
        "id": "FnP0dEgjVHXE"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Unique values in the 'Patient_Hist_Code' column\n",
        "unique_codes = dataset['Patient_Hist_Code'].nunique()"
      ],
      "metadata": {
        "id": "bf4ZWXl0VJw2"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining age groups\n",
        "bins = [0, 20, 30, 45, 50, 100]\n",
        "labels = ['0–20', '20–30', '30–40', '40–50', '50+']\n",
        "\n",
        "# Using pandas cut function to create categories\n",
        "dataset['Age_Group'] = pd.cut(dataset['Age'], bins=bins, labels=labels, right=False)\n",
        "\n",
        "# Displaying the first few lines of the dataset to check the new column\n",
        "dataset.head()"
      ],
      "metadata": {
        "id": "s0mFaJizVQOr"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# Contingency table between 'Smoker' and 'Developed_Pneumonia'\n",
        "contingency_table = pd.crosstab(dataset['Smoker'], dataset['Developed_Pneumonia'])\n",
        "contingency_table"
      ],
      "metadata": {
        "id": "GB28gWh7VSpv"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import chi2_contingency\n",
        "\n",
        "# Creating the contingency table for smoker data and development of pneumonia\n",
        "contingency_table = [[278, 268], [220, 234]]\n",
        "\n",
        "# Performing the Chi-square test\n",
        "chi2, p, dof, expected = chi2_contingency(contingency_table)\n",
        "chi2, p"
      ],
      "metadata": {
        "id": "BhZpyD0wVUTR"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the ranges\n",
        "bins = [-1, 2, 4, dataset['Number_of_Children'].max()]\n",
        "\n",
        "# Defining labels for the ranges\n",
        "labels = ['0–2', '3–4', '5+']\n",
        "\n",
        "# Creating the new categorical column\n",
        "dataset['Children_Range'] = pd.cut(dataset['Number_of_Children'], bins=bins, labels=labels, right=True)\n",
        "\n",
        "# Displaying the first few lines of the dataset to check the new column\n",
        "dataset.head()"
      ],
      "metadata": {
        "id": "hw_QBtIdVW7r"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Columns to be removed\n",
        "columns_to_remove = ['Patient_ID', 'Birth_Date', 'Age', 'Number_of_Children', 'Patient_Hist_Code']\n",
        "\n",
        "# Removing the columns\n",
        "clean_dataset = dataset.drop(columns=columns_to_remove)\n",
        "clean_dataset.head()"
      ],
      "metadata": {
        "id": "_z-ww3G4VZp3"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List to store results\n",
        "results = []\n",
        "\n",
        "# Categorical columns\n",
        "categorical_columns = clean_dataset.select_dtypes(include=[pd.np.object]).columns.tolist()\n",
        "categorical_columns.remove('Developed_Pneumonia')\n",
        "\n",
        "# Loop through all categorical columns\n",
        "for col in categorical_columns:\n",
        "\n",
        "# Creating the contingency table\n",
        " contingency_table = pd.crosstab(clean_dataset[col], clean_dataset['Developed_Pneumonia'])\n",
        "\n",
        "# Performing the chi-square test\n",
        " chi2, p_value, dof, expected = chi2_contingency(contingency_table)\n",
        "\n",
        "# Adding the results to the list\n",
        " results.append({'Variable': col, 'p-value': p_value})\n",
        "\n",
        "# Converting the results into a DataFrame for easier visualization\n",
        "results_df = pd.DataFrame(results)\n",
        "results_df"
      ],
      "metadata": {
        "id": "Mb7NLbtVVcYp"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "\n",
        "# Creating the encoders\n",
        "le = LabelEncoder()\n",
        "ohe = OneHotEncoder(drop='first', sparse=False)\n",
        "\n",
        "# Encoding the target variable\n",
        "clean_dataset['Developed_Pneumonia'] = le.fit_transform(clean_dataset['Developed_Pneumonia'])\n",
        "\n",
        "# List to store the new categorical columns\n",
        "new_categorical_cols = []\n",
        "\n",
        "# Loop through all categorical columns\n",
        "for col in categorical_columns:\n",
        "# Encoding the column\n",
        " encoded_cols = ohe.fit_transform(clean_dataset[[col]])\n",
        "# Transforming the result into a DataFrame and adding it\n",
        " encoded_cols_df = pd.DataFrame(encoded_cols, columns=[f\"{col}_{category}\" for category in ohe.categories_[0][1:]])\n",
        " # Adding the resulting DataFrame to the list\n",
        " new_categorical_cols.append(encoded_cols_df)\n",
        "\n",
        "# Concatenating all DataFrames from the list\n",
        "new_categorical_cols_clean_dataset = pd.concat(new_categorical_cols, axis=1)\n",
        "\n",
        "# Removing the original categorical columns from the DataFrame\n",
        "clean_dataset = clean_dataset.drop(categorical_columns, axis=1)\n",
        "\n",
        "# Adding the new encoded categorical columns\n",
        "df = pd.concat([clean_dataset, new_categorical_cols_clean_dataset], axis=1)\n",
        "\n",
        "# First few lines\n",
        "df.head()"
      ],
      "metadata": {
        "id": "YIhLQA8vVeg_"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Applying One-Hot Encoding to 'age_group' and 'Children_Range'\n",
        "df = pd.get_dummies(df, columns=['age_group', 'Children_Range'], drop_first=True)\n",
        "\n",
        "# Viewing the first few lines of the updated DataFrame\n",
        "print(df.head())"
      ],
      "metadata": {
        "id": "PjajdUFiVh9q"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "```python\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# Identify categorical columns\n",
        "categorical_cols = df.select_dtypes(include=['object', 'category']).columns\n",
        "\n",
        "# Apply One-Hot Encoding to categorical variables\n",
        "df_encoded = pd.get_dummies(df, columns=categorical_cols, drop_first=True)\n",
        "\n",
        "# Separate features and target variable\n",
        "X = df_encoded.drop('Developed_Pneumonia', axis=1)\n",
        "y = df_encoded['Developed_Pneumonia']\n",
        "\n",
        "# Create and train the Random Forest model\n",
        "model = RandomForestClassifier()\n",
        "model.fit(X, y)\n",
        "\n",
        "# Select features based on importance\n",
        "selector = SelectFromModel(model, threshold='median')\n",
        "X_selected = selector.fit_transform(X, y)\n",
        "\n",
        "# Get the names of selected features\n",
        "selected_features = X.columns[selector.get_support()]\n",
        "print(\"Selected Features:\", selected_features)"
      ],
      "metadata": {
        "id": "-auAVQroVkHM"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "\n",
        "# Apply One-Hot Encoding and separate features and target variable\n",
        "df_encoded = pd.get_dummies(df, drop_first=True)\n",
        "X = df_encoded.drop('Developed_Pneumonia', axis=1)\n",
        "y = df['Developed_Pneumonia']\n",
        "\n",
        "# Train the Random Forest model and select important features\n",
        "model = RandomForestClassifier().fit(X, y)\n",
        "selected_features = X.columns[SelectFromModel(model, threshold='median').fit(X, y).get_support()]\n",
        "\n",
        "# Create a new DataFrame with selected features and the target variable\n",
        "df_final = df_encoded[selected_features].join(df['Developed_Pneumonia'])\n",
        "\n",
        "# Save the new DataFrame to a CSV file\n",
        "df_final.to_csv('optimized_dataset.csv', index=False)\n",
        "print(\"Optimized dataset saved as 'optimized_dataset.csv'.\")"
      ],
      "metadata": {
        "id": "cHa6wj3LVn9u"
      },
      "execution_count": 19,
      "outputs": []
    }
  ]
}