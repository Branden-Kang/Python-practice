{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Optuna Hyperparameter Tuning.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOOtrz2UvcAHtAspV0hC1/3"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[Reference](https://bobrupakroy.medium.com/optuna-hyperparameter-tuning-81de049fe359)"
      ],
      "metadata": {
        "id": "Y_nHCqel0i_o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jnmx46OF0QS5",
        "outputId": "732cf7be-a20c-4f3a-d1e4-4728ab6c1de1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-2.10.0-py3-none-any.whl (308 kB)\n",
            "\u001b[?25l\r\u001b[K     |█                               | 10 kB 24.2 MB/s eta 0:00:01\r\u001b[K     |██▏                             | 20 kB 13.2 MB/s eta 0:00:01\r\u001b[K     |███▏                            | 30 kB 10.1 MB/s eta 0:00:01\r\u001b[K     |████▎                           | 40 kB 8.9 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 51 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 61 kB 5.8 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 71 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 81 kB 6.4 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 92 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 102 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 112 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 122 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 133 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 143 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 153 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 163 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 174 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 184 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 194 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 204 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 215 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 225 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 235 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 245 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 256 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 266 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 276 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 286 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 296 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 307 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 308 kB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: sqlalchemy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.29)\n",
            "Collecting alembic\n",
            "  Downloading alembic-1.7.5-py3-none-any.whl (209 kB)\n",
            "\u001b[K     |████████████████████████████████| 209 kB 45.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from optuna) (4.62.3)\n",
            "Requirement already satisfied: scipy!=1.4.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from optuna) (1.19.5)\n",
            "Collecting cmaes>=0.8.2\n",
            "  Downloading cmaes-0.8.2-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (21.3)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from optuna) (3.13)\n",
            "Collecting colorlog\n",
            "  Downloading colorlog-6.6.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting cliff\n",
            "  Downloading cliff-3.10.0-py3-none-any.whl (80 kB)\n",
            "\u001b[K     |████████████████████████████████| 80 kB 8.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->optuna) (3.0.6)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (1.1.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (4.10.0)\n",
            "Collecting Mako\n",
            "  Downloading Mako-1.1.6-py2.py3-none-any.whl (75 kB)\n",
            "\u001b[K     |████████████████████████████████| 75 kB 4.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from alembic->optuna) (5.4.0)\n",
            "Collecting stevedore>=2.0.1\n",
            "  Downloading stevedore-3.5.0-py3-none-any.whl (49 kB)\n",
            "\u001b[K     |████████████████████████████████| 49 kB 5.1 MB/s \n",
            "\u001b[?25hCollecting autopage>=0.4.0\n",
            "  Downloading autopage-0.4.0-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (3.0.0)\n",
            "Collecting cmd2>=1.0.0\n",
            "  Downloading cmd2-2.3.3-py3-none-any.whl (149 kB)\n",
            "\u001b[K     |████████████████████████████████| 149 kB 51.1 MB/s \n",
            "\u001b[?25hCollecting pbr!=2.1.0,>=2.0.0\n",
            "  Downloading pbr-5.8.0-py2.py3-none-any.whl (112 kB)\n",
            "\u001b[K     |████████████████████████████████| 112 kB 49.6 MB/s \n",
            "\u001b[?25hCollecting pyperclip>=1.6\n",
            "  Downloading pyperclip-1.8.2.tar.gz (20 kB)\n",
            "Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (0.2.5)\n",
            "Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (21.4.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (3.10.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->sqlalchemy>=1.1.0->optuna) (3.7.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from Mako->alembic->optuna) (2.0.1)\n",
            "Building wheels for collected packages: pyperclip\n",
            "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyperclip: filename=pyperclip-1.8.2-py3-none-any.whl size=11137 sha256=416e5f2ebca9d871532cb4aedc2f463f6ea9792340ab52940921e81d2a87ca9f\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/18/84/8f69f8b08169c7bae2dde6bd7daf0c19fca8c8e500ee620a28\n",
            "Successfully built pyperclip\n",
            "Installing collected packages: pyperclip, pbr, stevedore, Mako, cmd2, autopage, colorlog, cmaes, cliff, alembic, optuna\n",
            "Successfully installed Mako-1.1.6 alembic-1.7.5 autopage-0.4.0 cliff-3.10.0 cmaes-0.8.2 cmd2-2.3.3 colorlog-6.6.0 optuna-2.10.0 pbr-5.8.0 pyperclip-1.8.2 stevedore-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "CyP_mHXIzqoe"
      },
      "outputs": [],
      "source": [
        "import optuna\n",
        "import sklearn\n",
        "from sklearn import datasets\n",
        "def objective(trial):\n",
        "      iris = sklearn.datasets.load_iris()\n",
        "      \n",
        "      n_estimators = trial.suggest_int('n_estimators', 2, 20)\n",
        "      max_depth = int(trial.suggest_loguniform('max_depth', 1, 32)) \n",
        "      clf = sklearn.ensemble.RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth)\n",
        "      \n",
        "      return sklearn.model_selection.cross_val_score(clf, iris.data, iris.target,n_jobs=-1, cv=3).mean()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#direction= 'minimize' or 'maximize' \n",
        "#here i want to maximize the cross validation score\n",
        "study = optuna.create_study(direction='maximize')\n",
        "#study = optuna.create_study(sampler=TPESampler(), #direction=\"maximize\") by default the sampler = TPESampler()\n",
        "study.optimize(objective, n_trials=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GHRz7wNL0Os8",
        "outputId": "6feaf3a7-b8b9-4575-a790-eda9ba8e1a5c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-01-19 14:50:28,281]\u001b[0m A new study created in memory with name: no-name-8b1399fe-6bcf-4be0-81c8-a568252bdd99\u001b[0m\n",
            "\u001b[32m[I 2022-01-19 14:50:29,509]\u001b[0m Trial 0 finished with value: 0.8666666666666667 and parameters: {'n_estimators': 12, 'max_depth': 1.3233315730922257}. Best is trial 0 with value: 0.8666666666666667.\u001b[0m\n",
            "\u001b[32m[I 2022-01-19 14:50:29,615]\u001b[0m Trial 1 finished with value: 0.9533333333333333 and parameters: {'n_estimators': 16, 'max_depth': 15.446480394753323}. Best is trial 1 with value: 0.9533333333333333.\u001b[0m\n",
            "\u001b[32m[I 2022-01-19 14:50:29,716]\u001b[0m Trial 2 finished with value: 0.9666666666666667 and parameters: {'n_estimators': 17, 'max_depth': 3.557176617323015}. Best is trial 2 with value: 0.9666666666666667.\u001b[0m\n",
            "\u001b[32m[I 2022-01-19 14:50:29,751]\u001b[0m Trial 3 finished with value: 0.7466666666666667 and parameters: {'n_estimators': 3, 'max_depth': 1.0227787130889197}. Best is trial 2 with value: 0.9666666666666667.\u001b[0m\n",
            "\u001b[32m[I 2022-01-19 14:50:29,803]\u001b[0m Trial 4 finished with value: 0.9466666666666667 and parameters: {'n_estimators': 7, 'max_depth': 2.6281008109636357}. Best is trial 2 with value: 0.9666666666666667.\u001b[0m\n",
            "\u001b[32m[I 2022-01-19 14:50:29,878]\u001b[0m Trial 5 finished with value: 0.96 and parameters: {'n_estimators': 12, 'max_depth': 18.59968399557807}. Best is trial 2 with value: 0.9666666666666667.\u001b[0m\n",
            "\u001b[32m[I 2022-01-19 14:50:29,952]\u001b[0m Trial 6 finished with value: 0.94 and parameters: {'n_estimators': 12, 'max_depth': 2.1023548552513907}. Best is trial 2 with value: 0.9666666666666667.\u001b[0m\n",
            "\u001b[32m[I 2022-01-19 14:50:29,992]\u001b[0m Trial 7 finished with value: 0.9466666666666667 and parameters: {'n_estimators': 4, 'max_depth': 4.36149388035878}. Best is trial 2 with value: 0.9666666666666667.\u001b[0m\n",
            "\u001b[32m[I 2022-01-19 14:50:30,085]\u001b[0m Trial 8 finished with value: 0.96 and parameters: {'n_estimators': 16, 'max_depth': 29.739963324048393}. Best is trial 2 with value: 0.9666666666666667.\u001b[0m\n",
            "\u001b[32m[I 2022-01-19 14:50:30,182]\u001b[0m Trial 9 finished with value: 0.9666666666666667 and parameters: {'n_estimators': 16, 'max_depth': 26.454483351038995}. Best is trial 2 with value: 0.9666666666666667.\u001b[0m\n",
            "\u001b[32m[I 2022-01-19 14:50:30,308]\u001b[0m Trial 10 finished with value: 0.96 and parameters: {'n_estimators': 20, 'max_depth': 8.032019939723599}. Best is trial 2 with value: 0.9666666666666667.\u001b[0m\n",
            "\u001b[32m[I 2022-01-19 14:50:30,415]\u001b[0m Trial 11 finished with value: 0.96 and parameters: {'n_estimators': 18, 'max_depth': 6.714957901364936}. Best is trial 2 with value: 0.9666666666666667.\u001b[0m\n",
            "\u001b[32m[I 2022-01-19 14:50:30,510]\u001b[0m Trial 12 finished with value: 0.9733333333333333 and parameters: {'n_estimators': 15, 'max_depth': 3.99890996545104}. Best is trial 12 with value: 0.9733333333333333.\u001b[0m\n",
            "\u001b[32m[I 2022-01-19 14:50:30,603]\u001b[0m Trial 13 finished with value: 0.9666666666666667 and parameters: {'n_estimators': 14, 'max_depth': 3.8041210200307156}. Best is trial 12 with value: 0.9733333333333333.\u001b[0m\n",
            "\u001b[32m[I 2022-01-19 14:50:30,685]\u001b[0m Trial 14 finished with value: 0.96 and parameters: {'n_estimators': 8, 'max_depth': 10.340379427857032}. Best is trial 12 with value: 0.9733333333333333.\u001b[0m\n",
            "\u001b[32m[I 2022-01-19 14:50:30,800]\u001b[0m Trial 15 finished with value: 0.9666666666666667 and parameters: {'n_estimators': 20, 'max_depth': 2.6448474851631176}. Best is trial 12 with value: 0.9733333333333333.\u001b[0m\n",
            "\u001b[32m[I 2022-01-19 14:50:30,866]\u001b[0m Trial 16 finished with value: 0.9533333333333333 and parameters: {'n_estimators': 9, 'max_depth': 4.469101399437586}. Best is trial 12 with value: 0.9733333333333333.\u001b[0m\n",
            "\u001b[32m[I 2022-01-19 14:50:30,956]\u001b[0m Trial 17 finished with value: 0.8466666666666667 and parameters: {'n_estimators': 14, 'max_depth': 1.7133274454111425}. Best is trial 12 with value: 0.9733333333333333.\u001b[0m\n",
            "\u001b[32m[I 2022-01-19 14:50:31,075]\u001b[0m Trial 18 finished with value: 0.9533333333333333 and parameters: {'n_estimators': 18, 'max_depth': 3.2150276473367887}. Best is trial 12 with value: 0.9733333333333333.\u001b[0m\n",
            "\u001b[32m[I 2022-01-19 14:50:31,159]\u001b[0m Trial 19 finished with value: 0.9533333333333333 and parameters: {'n_estimators': 14, 'max_depth': 30.498654838499036}. Best is trial 12 with value: 0.9733333333333333.\u001b[0m\n",
            "\u001b[32m[I 2022-01-19 14:50:31,226]\u001b[0m Trial 20 finished with value: 0.96 and parameters: {'n_estimators': 10, 'max_depth': 11.291042255050307}. Best is trial 12 with value: 0.9733333333333333.\u001b[0m\n",
            "\u001b[32m[I 2022-01-19 14:50:31,349]\u001b[0m Trial 21 finished with value: 0.9666666666666667 and parameters: {'n_estimators': 20, 'max_depth': 5.558325423931975}. Best is trial 12 with value: 0.9733333333333333.\u001b[0m\n",
            "\u001b[32m[I 2022-01-19 14:50:31,465]\u001b[0m Trial 22 finished with value: 0.9466666666666667 and parameters: {'n_estimators': 20, 'max_depth': 6.164345890288475}. Best is trial 12 with value: 0.9733333333333333.\u001b[0m\n",
            "\u001b[32m[I 2022-01-19 14:50:31,564]\u001b[0m Trial 23 finished with value: 0.9533333333333333 and parameters: {'n_estimators': 16, 'max_depth': 21.491493198807333}. Best is trial 12 with value: 0.9733333333333333.\u001b[0m\n",
            "\u001b[32m[I 2022-01-19 14:50:31,682]\u001b[0m Trial 24 finished with value: 0.9666666666666667 and parameters: {'n_estimators': 18, 'max_depth': 5.363321132491353}. Best is trial 12 with value: 0.9733333333333333.\u001b[0m\n",
            "\u001b[32m[I 2022-01-19 14:50:31,792]\u001b[0m Trial 25 finished with value: 0.9666666666666667 and parameters: {'n_estimators': 19, 'max_depth': 2.594182327569922}. Best is trial 12 with value: 0.9733333333333333.\u001b[0m\n",
            "\u001b[32m[I 2022-01-19 14:50:31,904]\u001b[0m Trial 26 finished with value: 0.8866666666666667 and parameters: {'n_estimators': 20, 'max_depth': 1.754671317102191}. Best is trial 12 with value: 0.9733333333333333.\u001b[0m\n",
            "\u001b[32m[I 2022-01-19 14:50:32,005]\u001b[0m Trial 27 finished with value: 0.9666666666666667 and parameters: {'n_estimators': 14, 'max_depth': 3.567454061089912}. Best is trial 12 with value: 0.9733333333333333.\u001b[0m\n",
            "\u001b[32m[I 2022-01-19 14:50:32,091]\u001b[0m Trial 28 finished with value: 0.9533333333333333 and parameters: {'n_estimators': 14, 'max_depth': 2.5017367358207365}. Best is trial 12 with value: 0.9733333333333333.\u001b[0m\n",
            "\u001b[32m[I 2022-01-19 14:50:32,192]\u001b[0m Trial 29 finished with value: 0.96 and parameters: {'n_estimators': 17, 'max_depth': 1.4659910725368186}. Best is trial 12 with value: 0.9733333333333333.\u001b[0m\n",
            "\u001b[32m[I 2022-01-19 14:50:32,273]\u001b[0m Trial 30 finished with value: 0.96 and parameters: {'n_estimators': 13, 'max_depth': 3.9280574643792217}. Best is trial 12 with value: 0.9733333333333333.\u001b[0m\n",
            "\u001b[32m[I 2022-01-19 14:50:32,367]\u001b[0m Trial 31 finished with value: 0.9666666666666667 and parameters: {'n_estimators': 15, 'max_depth': 3.2206275770313675}. Best is trial 12 with value: 0.9733333333333333.\u001b[0m\n",
            "\u001b[32m[I 2022-01-19 14:50:32,479]\u001b[0m Trial 32 finished with value: 0.9466666666666667 and parameters: {'n_estimators': 19, 'max_depth': 2.661447171400367}. Best is trial 12 with value: 0.9733333333333333.\u001b[0m\n",
            "\u001b[32m[I 2022-01-19 14:50:32,584]\u001b[0m Trial 33 finished with value: 0.96 and parameters: {'n_estimators': 17, 'max_depth': 8.307622122777877}. Best is trial 12 with value: 0.9733333333333333.\u001b[0m\n",
            "\u001b[32m[I 2022-01-19 14:50:32,677]\u001b[0m Trial 34 finished with value: 0.9666666666666667 and parameters: {'n_estimators': 15, 'max_depth': 4.913659408851759}. Best is trial 12 with value: 0.9733333333333333.\u001b[0m\n",
            "\u001b[32m[I 2022-01-19 14:50:32,757]\u001b[0m Trial 35 finished with value: 0.96 and parameters: {'n_estimators': 10, 'max_depth': 4.880425981597724}. Best is trial 12 with value: 0.9733333333333333.\u001b[0m\n",
            "\u001b[32m[I 2022-01-19 14:50:32,857]\u001b[0m Trial 36 finished with value: 0.94 and parameters: {'n_estimators': 18, 'max_depth': 1.1961141369239934}. Best is trial 12 with value: 0.9733333333333333.\u001b[0m\n",
            "\u001b[32m[I 2022-01-19 14:50:32,937]\u001b[0m Trial 37 finished with value: 0.9666666666666667 and parameters: {'n_estimators': 12, 'max_depth': 3.2946772900692167}. Best is trial 12 with value: 0.9733333333333333.\u001b[0m\n",
            "\u001b[32m[I 2022-01-19 14:50:33,008]\u001b[0m Trial 38 finished with value: 0.9333333333333332 and parameters: {'n_estimators': 11, 'max_depth': 2.0237451792193952}. Best is trial 12 with value: 0.9733333333333333.\u001b[0m\n",
            "\u001b[32m[I 2022-01-19 14:50:33,104]\u001b[0m Trial 39 finished with value: 0.9533333333333333 and parameters: {'n_estimators': 17, 'max_depth': 3.1180595668951727}. Best is trial 12 with value: 0.9733333333333333.\u001b[0m\n",
            "\u001b[32m[I 2022-01-19 14:50:33,155]\u001b[0m Trial 40 finished with value: 0.9533333333333333 and parameters: {'n_estimators': 5, 'max_depth': 7.571829985578437}. Best is trial 12 with value: 0.9733333333333333.\u001b[0m\n",
            "\u001b[32m[I 2022-01-19 14:50:33,257]\u001b[0m Trial 41 finished with value: 0.96 and parameters: {'n_estimators': 18, 'max_depth': 2.1652943720900826}. Best is trial 12 with value: 0.9733333333333333.\u001b[0m\n",
            "\u001b[32m[I 2022-01-19 14:50:33,336]\u001b[0m Trial 42 finished with value: 0.96 and parameters: {'n_estimators': 12, 'max_depth': 4.767300599119513}. Best is trial 12 with value: 0.9733333333333333.\u001b[0m\n",
            "\u001b[32m[I 2022-01-19 14:50:33,447]\u001b[0m Trial 43 finished with value: 0.96 and parameters: {'n_estimators': 19, 'max_depth': 5.95528446484457}. Best is trial 12 with value: 0.9733333333333333.\u001b[0m\n",
            "\u001b[32m[I 2022-01-19 14:50:33,558]\u001b[0m Trial 44 finished with value: 0.96 and parameters: {'n_estimators': 19, 'max_depth': 2.692599885023507}. Best is trial 12 with value: 0.9733333333333333.\u001b[0m\n",
            "\u001b[32m[I 2022-01-19 14:50:33,667]\u001b[0m Trial 45 finished with value: 0.9666666666666667 and parameters: {'n_estimators': 20, 'max_depth': 4.057682396385064}. Best is trial 12 with value: 0.9733333333333333.\u001b[0m\n",
            "\u001b[32m[I 2022-01-19 14:50:33,774]\u001b[0m Trial 46 finished with value: 0.9666666666666667 and parameters: {'n_estimators': 15, 'max_depth': 3.3756143874774005}. Best is trial 12 with value: 0.9733333333333333.\u001b[0m\n",
            "\u001b[32m[I 2022-01-19 14:50:33,871]\u001b[0m Trial 47 finished with value: 0.9466666666666667 and parameters: {'n_estimators': 15, 'max_depth': 14.274434926588516}. Best is trial 12 with value: 0.9733333333333333.\u001b[0m\n",
            "\u001b[32m[I 2022-01-19 14:50:33,963]\u001b[0m Trial 48 finished with value: 0.9533333333333333 and parameters: {'n_estimators': 16, 'max_depth': 9.504686703664781}. Best is trial 12 with value: 0.9733333333333333.\u001b[0m\n",
            "\u001b[32m[I 2022-01-19 14:50:34,044]\u001b[0m Trial 49 finished with value: 0.96 and parameters: {'n_estimators': 13, 'max_depth': 7.263410907093973}. Best is trial 12 with value: 0.9733333333333333.\u001b[0m\n",
            "\u001b[32m[I 2022-01-19 14:50:34,130]\u001b[0m Trial 50 finished with value: 0.9533333333333333 and parameters: {'n_estimators': 13, 'max_depth': 2.2580452983480606}. Best is trial 12 with value: 0.9733333333333333.\u001b[0m\n",
            "\u001b[32m[I 2022-01-19 14:50:34,206]\u001b[0m Trial 51 finished with value: 0.9533333333333333 and parameters: {'n_estimators': 11, 'max_depth': 5.21053471846562}. Best is trial 12 with value: 0.9733333333333333.\u001b[0m\n",
            "\u001b[32m[I 2022-01-19 14:50:34,299]\u001b[0m Trial 52 finished with value: 0.94 and parameters: {'n_estimators': 15, 'max_depth': 3.600892120548799}. Best is trial 12 with value: 0.9733333333333333.\u001b[0m\n",
            "\u001b[32m[I 2022-01-19 14:50:34,403]\u001b[0m Trial 53 finished with value: 0.9666666666666667 and parameters: {'n_estimators': 15, 'max_depth': 4.339751072339428}. Best is trial 12 with value: 0.9733333333333333.\u001b[0m\n",
            "\u001b[32m[I 2022-01-19 14:50:34,456]\u001b[0m Trial 54 finished with value: 0.96 and parameters: {'n_estimators': 6, 'max_depth': 4.414033630196369}. Best is trial 12 with value: 0.9733333333333333.\u001b[0m\n",
            "\u001b[32m[I 2022-01-19 14:50:34,551]\u001b[0m Trial 55 finished with value: 0.9533333333333333 and parameters: {'n_estimators': 16, 'max_depth': 6.3915025206745355}. Best is trial 12 with value: 0.9733333333333333.\u001b[0m\n",
            "\u001b[32m[I 2022-01-19 14:50:34,629]\u001b[0m Trial 56 finished with value: 0.9466666666666667 and parameters: {'n_estimators': 12, 'max_depth': 3.0740207152276815}. Best is trial 12 with value: 0.9733333333333333.\u001b[0m\n",
            "\u001b[32m[I 2022-01-19 14:50:34,727]\u001b[0m Trial 57 finished with value: 0.96 and parameters: {'n_estimators': 14, 'max_depth': 3.718941842825432}. Best is trial 12 with value: 0.9733333333333333.\u001b[0m\n",
            "\u001b[32m[I 2022-01-19 14:50:34,836]\u001b[0m Trial 58 finished with value: 0.9533333333333333 and parameters: {'n_estimators': 15, 'max_depth': 3.0138621878319034}. Best is trial 12 with value: 0.9733333333333333.\u001b[0m\n",
            "\u001b[32m[I 2022-01-19 14:50:34,942]\u001b[0m Trial 59 finished with value: 0.9533333333333333 and parameters: {'n_estimators': 16, 'max_depth': 2.390558385136106}. Best is trial 12 with value: 0.9733333333333333.\u001b[0m\n",
            "\u001b[32m[I 2022-01-19 14:50:35,051]\u001b[0m Trial 60 finished with value: 0.7799999999999999 and parameters: {'n_estimators': 18, 'max_depth': 1.8750715694832105}. Best is trial 12 with value: 0.9733333333333333.\u001b[0m\n",
            "\u001b[32m[I 2022-01-19 14:50:35,155]\u001b[0m Trial 61 finished with value: 0.9466666666666667 and parameters: {'n_estimators': 17, 'max_depth': 5.243750540664212}. Best is trial 12 with value: 0.9733333333333333.\u001b[0m\n",
            "\u001b[32m[I 2022-01-19 14:50:35,266]\u001b[0m Trial 62 finished with value: 0.9533333333333333 and parameters: {'n_estimators': 19, 'max_depth': 2.7712487901785674}. Best is trial 12 with value: 0.9733333333333333.\u001b[0m\n",
            "\u001b[32m[I 2022-01-19 14:50:35,380]\u001b[0m Trial 63 finished with value: 0.96 and parameters: {'n_estimators': 19, 'max_depth': 4.113815626279971}. Best is trial 12 with value: 0.9733333333333333.\u001b[0m\n",
            "\u001b[32m[I 2022-01-19 14:50:35,461]\u001b[0m Trial 64 finished with value: 0.9733333333333333 and parameters: {'n_estimators': 13, 'max_depth': 5.722540603977289}. Best is trial 12 with value: 0.9733333333333333.\u001b[0m\n",
            "\u001b[32m[I 2022-01-19 14:50:35,548]\u001b[0m Trial 65 finished with value: 0.9466666666666667 and parameters: {'n_estimators': 13, 'max_depth': 4.179075775260116}. Best is trial 12 with value: 0.9733333333333333.\u001b[0m\n",
            "\u001b[32m[I 2022-01-19 14:50:35,640]\u001b[0m Trial 66 finished with value: 0.9466666666666667 and parameters: {'n_estimators': 14, 'max_depth': 5.334406429349909}. Best is trial 12 with value: 0.9733333333333333.\u001b[0m\n",
            "\u001b[32m[I 2022-01-19 14:50:35,727]\u001b[0m Trial 67 finished with value: 0.9533333333333333 and parameters: {'n_estimators': 14, 'max_depth': 8.474067291603648}. Best is trial 12 with value: 0.9733333333333333.\u001b[0m\n",
            "\u001b[32m[I 2022-01-19 14:50:35,840]\u001b[0m Trial 68 finished with value: 0.96 and parameters: {'n_estimators': 17, 'max_depth': 2.893283754101416}. Best is trial 12 with value: 0.9733333333333333.\u001b[0m\n",
            "\u001b[32m[I 2022-01-19 14:50:35,955]\u001b[0m Trial 69 finished with value: 0.9666666666666667 and parameters: {'n_estimators': 20, 'max_depth': 5.77978622385333}. Best is trial 12 with value: 0.9733333333333333.\u001b[0m\n",
            "\u001b[32m[I 2022-01-19 14:50:36,021]\u001b[0m Trial 70 finished with value: 0.9666666666666667 and parameters: {'n_estimators': 8, 'max_depth': 3.367355198481012}. Best is trial 12 with value: 0.9733333333333333.\u001b[0m\n",
            "\u001b[32m[I 2022-01-19 14:50:36,054]\u001b[0m Trial 71 finished with value: 0.9466666666666667 and parameters: {'n_estimators': 2, 'max_depth': 3.9370325051369144}. Best is trial 12 with value: 0.9733333333333333.\u001b[0m\n",
            "\u001b[32m[I 2022-01-19 14:50:36,115]\u001b[0m Trial 72 finished with value: 0.9666666666666667 and parameters: {'n_estimators': 8, 'max_depth': 6.748277330543504}. Best is trial 12 with value: 0.9733333333333333.\u001b[0m\n",
            "\u001b[32m[I 2022-01-19 14:50:36,180]\u001b[0m Trial 73 finished with value: 0.96 and parameters: {'n_estimators': 9, 'max_depth': 4.651131074402763}. Best is trial 12 with value: 0.9733333333333333.\u001b[0m\n",
            "\u001b[32m[I 2022-01-19 14:50:36,263]\u001b[0m Trial 74 finished with value: 0.9666666666666667 and parameters: {'n_estimators': 12, 'max_depth': 5.7471721018716275}. Best is trial 12 with value: 0.9733333333333333.\u001b[0m\n",
            "\u001b[32m[I 2022-01-19 14:50:36,330]\u001b[0m Trial 75 finished with value: 0.9466666666666667 and parameters: {'n_estimators': 9, 'max_depth': 6.523154061237304}. Best is trial 12 with value: 0.9733333333333333.\u001b[0m\n",
            "\u001b[32m[I 2022-01-19 14:50:36,410]\u001b[0m Trial 76 finished with value: 0.9666666666666667 and parameters: {'n_estimators': 12, 'max_depth': 4.799594102084291}. Best is trial 12 with value: 0.9733333333333333.\u001b[0m\n",
            "\u001b[32m[I 2022-01-19 14:50:36,495]\u001b[0m Trial 77 finished with value: 0.9466666666666667 and parameters: {'n_estimators': 11, 'max_depth': 3.4278968699160517}. Best is trial 12 with value: 0.9733333333333333.\u001b[0m\n",
            "\u001b[32m[I 2022-01-19 14:50:36,605]\u001b[0m Trial 78 finished with value: 0.9533333333333333 and parameters: {'n_estimators': 18, 'max_depth': 2.4445131421237094}. Best is trial 12 with value: 0.9733333333333333.\u001b[0m\n",
            "\u001b[32m[I 2022-01-19 14:50:36,693]\u001b[0m Trial 79 finished with value: 0.9666666666666667 and parameters: {'n_estimators': 13, 'max_depth': 5.889154905092401}. Best is trial 12 with value: 0.9733333333333333.\u001b[0m\n",
            "\u001b[32m[I 2022-01-19 14:50:36,779]\u001b[0m Trial 80 finished with value: 0.96 and parameters: {'n_estimators': 13, 'max_depth': 4.111644327116793}. Best is trial 12 with value: 0.9733333333333333.\u001b[0m\n",
            "\u001b[32m[I 2022-01-19 14:50:36,881]\u001b[0m Trial 81 finished with value: 0.9533333333333333 and parameters: {'n_estimators': 13, 'max_depth': 7.111319410095995}. Best is trial 12 with value: 0.9733333333333333.\u001b[0m\n",
            "\u001b[32m[I 2022-01-19 14:50:36,973]\u001b[0m Trial 82 finished with value: 0.9533333333333333 and parameters: {'n_estimators': 15, 'max_depth': 3.2596960978425633}. Best is trial 12 with value: 0.9733333333333333.\u001b[0m\n",
            "\u001b[32m[I 2022-01-19 14:50:37,031]\u001b[0m Trial 83 finished with value: 0.9666666666666667 and parameters: {'n_estimators': 7, 'max_depth': 9.292111755377222}. Best is trial 12 with value: 0.9733333333333333.\u001b[0m\n",
            "\u001b[32m[I 2022-01-19 14:50:37,077]\u001b[0m Trial 84 finished with value: 0.9533333333333333 and parameters: {'n_estimators': 4, 'max_depth': 12.066580475180295}. Best is trial 12 with value: 0.9733333333333333.\u001b[0m\n",
            "\u001b[32m[I 2022-01-19 14:50:37,147]\u001b[0m Trial 85 finished with value: 0.9466666666666667 and parameters: {'n_estimators': 10, 'max_depth': 17.230988418634887}. Best is trial 12 with value: 0.9733333333333333.\u001b[0m\n",
            "\u001b[32m[I 2022-01-19 14:50:37,230]\u001b[0m Trial 86 finished with value: 0.9666666666666667 and parameters: {'n_estimators': 12, 'max_depth': 5.899259748565265}. Best is trial 12 with value: 0.9733333333333333.\u001b[0m\n",
            "\u001b[32m[I 2022-01-19 14:50:37,342]\u001b[0m Trial 87 finished with value: 0.9666666666666667 and parameters: {'n_estimators': 19, 'max_depth': 3.643449395947037}. Best is trial 12 with value: 0.9733333333333333.\u001b[0m\n",
            "\u001b[32m[I 2022-01-19 14:50:37,467]\u001b[0m Trial 88 finished with value: 0.9666666666666667 and parameters: {'n_estimators': 20, 'max_depth': 3.7073185477941126}. Best is trial 12 with value: 0.9733333333333333.\u001b[0m\n",
            "\u001b[32m[I 2022-01-19 14:50:37,575]\u001b[0m Trial 89 finished with value: 0.9466666666666667 and parameters: {'n_estimators': 19, 'max_depth': 3.6889939695359772}. Best is trial 12 with value: 0.9733333333333333.\u001b[0m\n",
            "\u001b[32m[I 2022-01-19 14:50:37,661]\u001b[0m Trial 90 finished with value: 0.96 and parameters: {'n_estimators': 14, 'max_depth': 2.8520602181138837}. Best is trial 12 with value: 0.9733333333333333.\u001b[0m\n",
            "\u001b[32m[I 2022-01-19 14:50:37,753]\u001b[0m Trial 91 finished with value: 0.96 and parameters: {'n_estimators': 15, 'max_depth': 4.425939560446589}. Best is trial 12 with value: 0.9733333333333333.\u001b[0m\n",
            "\u001b[32m[I 2022-01-19 14:50:37,868]\u001b[0m Trial 92 finished with value: 0.9666666666666667 and parameters: {'n_estimators': 16, 'max_depth': 5.1799004619855245}. Best is trial 12 with value: 0.9733333333333333.\u001b[0m\n",
            "\u001b[32m[I 2022-01-19 14:50:37,959]\u001b[0m Trial 93 finished with value: 0.9533333333333333 and parameters: {'n_estimators': 15, 'max_depth': 3.1812815115347366}. Best is trial 12 with value: 0.9733333333333333.\u001b[0m\n",
            "\u001b[32m[I 2022-01-19 14:50:38,044]\u001b[0m Trial 94 finished with value: 0.9466666666666667 and parameters: {'n_estimators': 14, 'max_depth': 2.5296606023565333}. Best is trial 12 with value: 0.9733333333333333.\u001b[0m\n",
            "\u001b[32m[I 2022-01-19 14:50:38,125]\u001b[0m Trial 95 finished with value: 0.96 and parameters: {'n_estimators': 12, 'max_depth': 9.144448473154085}. Best is trial 12 with value: 0.9733333333333333.\u001b[0m\n",
            "\u001b[32m[I 2022-01-19 14:50:38,227]\u001b[0m Trial 96 finished with value: 0.9533333333333333 and parameters: {'n_estimators': 17, 'max_depth': 5.074447365591826}. Best is trial 12 with value: 0.9733333333333333.\u001b[0m\n",
            "\u001b[32m[I 2022-01-19 14:50:38,307]\u001b[0m Trial 97 finished with value: 0.9666666666666667 and parameters: {'n_estimators': 11, 'max_depth': 5.649650731840191}. Best is trial 12 with value: 0.9733333333333333.\u001b[0m\n",
            "\u001b[32m[I 2022-01-19 14:50:38,383]\u001b[0m Trial 98 finished with value: 0.96 and parameters: {'n_estimators': 11, 'max_depth': 5.663107601744861}. Best is trial 12 with value: 0.9733333333333333.\u001b[0m\n",
            "\u001b[32m[I 2022-01-19 14:50:38,500]\u001b[0m Trial 99 finished with value: 0.9666666666666667 and parameters: {'n_estimators': 20, 'max_depth': 5.431251414800425}. Best is trial 12 with value: 0.9733333333333333.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trial = study.best_trial\n",
        "print('Accuracy: {}'.format(trial.value)) #0.9733333333333333\n",
        "print(\"Best hyperparameters: {}\".format(trial.params))\n",
        "#{'n_estimators': 11, 'max_depth': 27.827767703750034}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cUD4e3lv0VJM",
        "outputId": "f6862ca8-911a-4762-a05b-c9ad28635a99"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9733333333333333\n",
            "Best hyperparameters: {'n_estimators': 15, 'max_depth': 3.99890996545104}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optuna.visualization.plot_optimization_history(study)\n",
        "optuna.visualization.plot_slice(study)\n",
        "# optuna.importances.get_param_importance()\n",
        "help(optuna)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g5E1ECiH0X9X",
        "outputId": "cafab051-7f99-4441-95f9-0b2923722a7c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on package optuna:\n",
            "\n",
            "NAME\n",
            "    optuna\n",
            "\n",
            "PACKAGE CONTENTS\n",
            "    _callbacks\n",
            "    _deprecated\n",
            "    _experimental\n",
            "    _hypervolume (package)\n",
            "    _imports\n",
            "    _transform\n",
            "    cli\n",
            "    dashboard\n",
            "    distributions\n",
            "    exceptions\n",
            "    importance (package)\n",
            "    integration (package)\n",
            "    logging\n",
            "    multi_objective (package)\n",
            "    progress_bar\n",
            "    pruners (package)\n",
            "    samplers (package)\n",
            "    storages (package)\n",
            "    structs\n",
            "    study (package)\n",
            "    testing (package)\n",
            "    trial (package)\n",
            "    type_checking\n",
            "    version\n",
            "    visualization (package)\n",
            "\n",
            "CLASSES\n",
            "    optuna.exceptions.OptunaError(builtins.Exception)\n",
            "        optuna.exceptions.TrialPruned\n",
            "    optuna.study.study.BaseStudy(builtins.object)\n",
            "        optuna.study.study.Study\n",
            "    optuna.trial._base.BaseTrial(builtins.object)\n",
            "        optuna.trial._trial.Trial\n",
            "    \n",
            "    class Study(BaseStudy)\n",
            "     |  Study(study_name: str, storage: Union[str, optuna.storages._base.BaseStorage], sampler: Union[ForwardRef('samplers.BaseSampler'), NoneType] = None, pruner: Union[optuna.pruners._base.BasePruner, NoneType] = None) -> None\n",
            "     |  \n",
            "     |  A study corresponds to an optimization task, i.e., a set of trials.\n",
            "     |  \n",
            "     |  This object provides interfaces to run a new :class:`~optuna.trial.Trial`, access trials'\n",
            "     |  history, set/get user-defined attributes of the study itself.\n",
            "     |  \n",
            "     |  Note that the direct use of this constructor is not recommended.\n",
            "     |  To create and load a study, please refer to the documentation of\n",
            "     |  :func:`~optuna.study.create_study` and :func:`~optuna.study.load_study` respectively.\n",
            "     |  \n",
            "     |  Method resolution order:\n",
            "     |      Study\n",
            "     |      BaseStudy\n",
            "     |      builtins.object\n",
            "     |  \n",
            "     |  Methods defined here:\n",
            "     |  \n",
            "     |  __getstate__(self) -> Dict[Any, Any]\n",
            "     |  \n",
            "     |  __init__(self, study_name: str, storage: Union[str, optuna.storages._base.BaseStorage], sampler: Union[ForwardRef('samplers.BaseSampler'), NoneType] = None, pruner: Union[optuna.pruners._base.BasePruner, NoneType] = None) -> None\n",
            "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
            "     |  \n",
            "     |  __setstate__(self, state: Dict[Any, Any]) -> None\n",
            "     |  \n",
            "     |  add_trial(self, trial: optuna.trial._frozen.FrozenTrial) -> None\n",
            "     |      Add trial to study.\n",
            "     |      \n",
            "     |      The trial is validated before being added.\n",
            "     |      \n",
            "     |      Example:\n",
            "     |      \n",
            "     |          .. testcode::\n",
            "     |      \n",
            "     |              import optuna\n",
            "     |              from optuna.distributions import UniformDistribution\n",
            "     |      \n",
            "     |      \n",
            "     |              def objective(trial):\n",
            "     |                  x = trial.suggest_float(\"x\", 0, 10)\n",
            "     |                  return x ** 2\n",
            "     |      \n",
            "     |      \n",
            "     |              study = optuna.create_study()\n",
            "     |              assert len(study.trials) == 0\n",
            "     |      \n",
            "     |              trial = optuna.trial.create_trial(\n",
            "     |                  params={\"x\": 2.0},\n",
            "     |                  distributions={\"x\": UniformDistribution(0, 10)},\n",
            "     |                  value=4.0,\n",
            "     |              )\n",
            "     |      \n",
            "     |              study.add_trial(trial)\n",
            "     |              assert len(study.trials) == 1\n",
            "     |      \n",
            "     |              study.optimize(objective, n_trials=3)\n",
            "     |              assert len(study.trials) == 4\n",
            "     |      \n",
            "     |              other_study = optuna.create_study()\n",
            "     |      \n",
            "     |              for trial in study.trials:\n",
            "     |                  other_study.add_trial(trial)\n",
            "     |              assert len(other_study.trials) == len(study.trials)\n",
            "     |      \n",
            "     |              other_study.optimize(objective, n_trials=2)\n",
            "     |              assert len(other_study.trials) == len(study.trials) + 2\n",
            "     |      \n",
            "     |      .. seealso::\n",
            "     |      \n",
            "     |          This method should in general be used to add already evaluated trials\n",
            "     |          (``trial.state.is_finished() == True``). To queue trials for evaluation,\n",
            "     |          please refer to :func:`~optuna.study.Study.enqueue_trial`.\n",
            "     |      \n",
            "     |      .. seealso::\n",
            "     |      \n",
            "     |          See :func:`~optuna.trial.create_trial` for how to create trials.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          trial: Trial to add.\n",
            "     |      \n",
            "     |      Raises:\n",
            "     |          :exc:`ValueError`:\n",
            "     |              If trial is an invalid state.\n",
            "     |      \n",
            "     |      .. note::\n",
            "     |          Added in v2.0.0 as an experimental feature. The interface may change in newer versions\n",
            "     |          without prior notice. See https://github.com/optuna/optuna/releases/tag/v2.0.0.\n",
            "     |  \n",
            "     |  add_trials(self, trials: Iterable[optuna.trial._frozen.FrozenTrial]) -> None\n",
            "     |      Add trials to study.\n",
            "     |      \n",
            "     |      The trials are validated before being added.\n",
            "     |      \n",
            "     |      Example:\n",
            "     |      \n",
            "     |          .. testcode::\n",
            "     |      \n",
            "     |              import optuna\n",
            "     |              from optuna.distributions import UniformDistribution\n",
            "     |      \n",
            "     |      \n",
            "     |              def objective(trial):\n",
            "     |                  x = trial.suggest_float(\"x\", 0, 10)\n",
            "     |                  return x ** 2\n",
            "     |      \n",
            "     |      \n",
            "     |              study = optuna.create_study()\n",
            "     |              study.optimize(objective, n_trials=3)\n",
            "     |              assert len(study.trials) == 3\n",
            "     |      \n",
            "     |              other_study = optuna.create_study()\n",
            "     |              other_study.add_trials(study.trials)\n",
            "     |              assert len(other_study.trials) == len(study.trials)\n",
            "     |      \n",
            "     |              other_study.optimize(objective, n_trials=2)\n",
            "     |              assert len(other_study.trials) == len(study.trials) + 2\n",
            "     |      \n",
            "     |      .. seealso::\n",
            "     |      \n",
            "     |          See :func:`~optuna.study.Study.add_trial` for addition of each trial.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          trials: Trials to add.\n",
            "     |      \n",
            "     |      Raises:\n",
            "     |          :exc:`ValueError`:\n",
            "     |              If ``trials`` include invalid trial.\n",
            "     |      \n",
            "     |      .. note::\n",
            "     |          Added in v2.5.0 as an experimental feature. The interface may change in newer versions\n",
            "     |          without prior notice. See https://github.com/optuna/optuna/releases/tag/v2.5.0.\n",
            "     |  \n",
            "     |  ask(self, fixed_distributions: Union[Dict[str, optuna.distributions.BaseDistribution], NoneType] = None) -> optuna.trial._trial.Trial\n",
            "     |      Create a new trial from which hyperparameters can be suggested.\n",
            "     |      \n",
            "     |      This method is part of an alternative to :func:`~optuna.study.Study.optimize` that allows\n",
            "     |      controlling the lifetime of a trial outside the scope of ``func``. Each call to this\n",
            "     |      method should be followed by a call to :func:`~optuna.study.Study.tell` to finish the\n",
            "     |      created trial.\n",
            "     |      \n",
            "     |      .. seealso::\n",
            "     |      \n",
            "     |          The :ref:`ask_and_tell` tutorial provides use-cases with examples.\n",
            "     |      \n",
            "     |      Example:\n",
            "     |      \n",
            "     |          Getting the trial object with the :func:`~optuna.study.Study.ask` method.\n",
            "     |      \n",
            "     |          .. testcode::\n",
            "     |      \n",
            "     |              import optuna\n",
            "     |      \n",
            "     |      \n",
            "     |              study = optuna.create_study()\n",
            "     |      \n",
            "     |              trial = study.ask()\n",
            "     |      \n",
            "     |              x = trial.suggest_float(\"x\", -1, 1)\n",
            "     |      \n",
            "     |              study.tell(trial, x ** 2)\n",
            "     |      \n",
            "     |      Example:\n",
            "     |      \n",
            "     |          Passing previously defined distributions to the :func:`~optuna.study.Study.ask`\n",
            "     |          method.\n",
            "     |      \n",
            "     |          .. testcode::\n",
            "     |      \n",
            "     |              import optuna\n",
            "     |      \n",
            "     |      \n",
            "     |              study = optuna.create_study()\n",
            "     |      \n",
            "     |              distributions = {\n",
            "     |                  \"optimizer\": optuna.distributions.CategoricalDistribution([\"adam\", \"sgd\"]),\n",
            "     |                  \"lr\": optuna.distributions.LogUniformDistribution(0.0001, 0.1),\n",
            "     |              }\n",
            "     |      \n",
            "     |              # You can pass the distributions previously defined.\n",
            "     |              trial = study.ask(fixed_distributions=distributions)\n",
            "     |      \n",
            "     |              # `optimizer` and `lr` are already suggested and accessible with `trial.params`.\n",
            "     |              assert \"optimizer\" in trial.params\n",
            "     |              assert \"lr\" in trial.params\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          fixed_distributions:\n",
            "     |              A dictionary containing the parameter names and parameter's distributions. Each\n",
            "     |              parameter in this dictionary is automatically suggested for the returned trial,\n",
            "     |              even when the suggest method is not explicitly invoked by the user. If this\n",
            "     |              argument is set to :obj:`None`, no parameter is automatically suggested.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          A :class:`~optuna.trial.Trial`.\n",
            "     |  \n",
            "     |  enqueue_trial(self, params: Dict[str, Any]) -> None\n",
            "     |      Enqueue a trial with given parameter values.\n",
            "     |      \n",
            "     |      You can fix the next sampling parameters which will be evaluated in your\n",
            "     |      objective function.\n",
            "     |      \n",
            "     |      Example:\n",
            "     |      \n",
            "     |          .. testcode::\n",
            "     |      \n",
            "     |              import optuna\n",
            "     |      \n",
            "     |      \n",
            "     |              def objective(trial):\n",
            "     |                  x = trial.suggest_float(\"x\", 0, 10)\n",
            "     |                  return x ** 2\n",
            "     |      \n",
            "     |      \n",
            "     |              study = optuna.create_study()\n",
            "     |              study.enqueue_trial({\"x\": 5})\n",
            "     |              study.enqueue_trial({\"x\": 0})\n",
            "     |              study.optimize(objective, n_trials=2)\n",
            "     |      \n",
            "     |              assert study.trials[0].params == {\"x\": 5}\n",
            "     |              assert study.trials[1].params == {\"x\": 0}\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          params:\n",
            "     |              Parameter values to pass your objective function.\n",
            "     |      \n",
            "     |      .. note::\n",
            "     |          Added in v1.2.0 as an experimental feature. The interface may change in newer versions\n",
            "     |          without prior notice. See https://github.com/optuna/optuna/releases/tag/v1.2.0.\n",
            "     |  \n",
            "     |  optimize(self, func: Callable[[optuna.trial._trial.Trial], Union[float, Sequence[float]]], n_trials: Union[int, NoneType] = None, timeout: Union[float, NoneType] = None, n_jobs: int = 1, catch: Tuple[Type[Exception], ...] = (), callbacks: Union[List[Callable[[ForwardRef('Study'), optuna.trial._frozen.FrozenTrial], NoneType]], NoneType] = None, gc_after_trial: bool = False, show_progress_bar: bool = False) -> None\n",
            "     |      Optimize an objective function.\n",
            "     |      \n",
            "     |      Optimization is done by choosing a suitable set of hyperparameter values from a given\n",
            "     |      range. Uses a sampler which implements the task of value suggestion based on a specified\n",
            "     |      distribution. The sampler is specified in :func:`~optuna.study.create_study` and the\n",
            "     |      default choice for the sampler is TPE.\n",
            "     |      See also :class:`~optuna.samplers.TPESampler` for more details on 'TPE'.\n",
            "     |      \n",
            "     |      Example:\n",
            "     |      \n",
            "     |          .. testcode::\n",
            "     |      \n",
            "     |              import optuna\n",
            "     |      \n",
            "     |      \n",
            "     |              def objective(trial):\n",
            "     |                  x = trial.suggest_float(\"x\", -1, 1)\n",
            "     |                  return x ** 2\n",
            "     |      \n",
            "     |      \n",
            "     |              study = optuna.create_study()\n",
            "     |              study.optimize(objective, n_trials=3)\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          func:\n",
            "     |              A callable that implements objective function.\n",
            "     |          n_trials:\n",
            "     |              The number of trials. If this argument is set to :obj:`None`, there is no\n",
            "     |              limitation on the number of trials. If :obj:`timeout` is also set to :obj:`None`,\n",
            "     |              the study continues to create trials until it receives a termination signal such\n",
            "     |              as Ctrl+C or SIGTERM.\n",
            "     |          timeout:\n",
            "     |              Stop study after the given number of second(s). If this argument is set to\n",
            "     |              :obj:`None`, the study is executed without time limitation. If :obj:`n_trials` is\n",
            "     |              also set to :obj:`None`, the study continues to create trials until it receives a\n",
            "     |              termination signal such as Ctrl+C or SIGTERM.\n",
            "     |          n_jobs:\n",
            "     |              The number of parallel jobs. If this argument is set to :obj:`-1`, the number is\n",
            "     |              set to CPU count.\n",
            "     |      \n",
            "     |              .. note::\n",
            "     |                  ``n_jobs`` allows parallelization using :obj:`threading` and may suffer from\n",
            "     |                  `Python's GIL <https://wiki.python.org/moin/GlobalInterpreterLock>`_.\n",
            "     |                  It is recommended to use :ref:`process-based parallelization<distributed>`\n",
            "     |                  if ``func`` is CPU bound.\n",
            "     |      \n",
            "     |              .. warning::\n",
            "     |                  Deprecated in v2.7.0. This feature will be removed in the future.\n",
            "     |                  It is recommended to use :ref:`process-based parallelization<distributed>`.\n",
            "     |                  The removal of this feature is currently scheduled for v4.0.0, but this\n",
            "     |                  schedule is subject to change.\n",
            "     |                  See https://github.com/optuna/optuna/releases/tag/v2.7.0.\n",
            "     |      \n",
            "     |          catch:\n",
            "     |              A study continues to run even when a trial raises one of the exceptions specified\n",
            "     |              in this argument. Default is an empty tuple, i.e. the study will stop for any\n",
            "     |              exception except for :class:`~optuna.exceptions.TrialPruned`.\n",
            "     |          callbacks:\n",
            "     |              List of callback functions that are invoked at the end of each trial. Each function\n",
            "     |              must accept two parameters with the following types in this order:\n",
            "     |              :class:`~optuna.study.Study` and :class:`~optuna.FrozenTrial`.\n",
            "     |          gc_after_trial:\n",
            "     |              Flag to determine whether to automatically run garbage collection after each trial.\n",
            "     |              Set to :obj:`True` to run the garbage collection, :obj:`False` otherwise.\n",
            "     |              When it runs, it runs a full collection by internally calling :func:`gc.collect`.\n",
            "     |              If you see an increase in memory consumption over several trials, try setting this\n",
            "     |              flag to :obj:`True`.\n",
            "     |      \n",
            "     |              .. seealso::\n",
            "     |      \n",
            "     |                  :ref:`out-of-memory-gc-collect`\n",
            "     |      \n",
            "     |          show_progress_bar:\n",
            "     |              Flag to show progress bars or not. To disable progress bar, set this :obj:`False`.\n",
            "     |              Currently, progress bar is experimental feature and disabled\n",
            "     |              when ``n_jobs`` :math:`\\ne 1`.\n",
            "     |      \n",
            "     |      Raises:\n",
            "     |          RuntimeError:\n",
            "     |              If nested invocation of this method occurs.\n",
            "     |  \n",
            "     |  set_system_attr(self, key: str, value: Any) -> None\n",
            "     |      Set a system attribute to the study.\n",
            "     |      \n",
            "     |      Note that Optuna internally uses this method to save system messages. Please use\n",
            "     |      :func:`~optuna.study.Study.set_user_attr` to set users' attributes.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          key: A key string of the attribute.\n",
            "     |          value: A value of the attribute. The value should be JSON serializable.\n",
            "     |  \n",
            "     |  set_user_attr(self, key: str, value: Any) -> None\n",
            "     |      Set a user attribute to the study.\n",
            "     |      \n",
            "     |      .. seealso::\n",
            "     |      \n",
            "     |          See :attr:`~optuna.study.Study.user_attrs` for related attribute.\n",
            "     |      \n",
            "     |      Example:\n",
            "     |      \n",
            "     |          .. testcode::\n",
            "     |      \n",
            "     |              import optuna\n",
            "     |      \n",
            "     |      \n",
            "     |              def objective(trial):\n",
            "     |                  x = trial.suggest_float(\"x\", 0, 1)\n",
            "     |                  y = trial.suggest_float(\"y\", 0, 1)\n",
            "     |                  return x ** 2 + y ** 2\n",
            "     |      \n",
            "     |      \n",
            "     |              study = optuna.create_study()\n",
            "     |      \n",
            "     |              study.set_user_attr(\"objective function\", \"quadratic function\")\n",
            "     |              study.set_user_attr(\"dimensions\", 2)\n",
            "     |              study.set_user_attr(\"contributors\", [\"Akiba\", \"Sano\"])\n",
            "     |      \n",
            "     |              assert study.user_attrs == {\n",
            "     |                  \"objective function\": \"quadratic function\",\n",
            "     |                  \"dimensions\": 2,\n",
            "     |                  \"contributors\": [\"Akiba\", \"Sano\"],\n",
            "     |              }\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          key: A key string of the attribute.\n",
            "     |          value: A value of the attribute. The value should be JSON serializable.\n",
            "     |  \n",
            "     |  stop(self) -> None\n",
            "     |      Exit from the current optimization loop after the running trials finish.\n",
            "     |      \n",
            "     |      This method lets the running :meth:`~optuna.study.Study.optimize` method return\n",
            "     |      immediately after all trials which the :meth:`~optuna.study.Study.optimize` method\n",
            "     |      spawned finishes.\n",
            "     |      This method does not affect any behaviors of parallel or successive study processes.\n",
            "     |      \n",
            "     |      Example:\n",
            "     |      \n",
            "     |          .. testcode::\n",
            "     |      \n",
            "     |              import optuna\n",
            "     |      \n",
            "     |      \n",
            "     |              def objective(trial):\n",
            "     |                  if trial.number == 4:\n",
            "     |                      trial.study.stop()\n",
            "     |                  x = trial.suggest_float(\"x\", 0, 10)\n",
            "     |                  return x ** 2\n",
            "     |      \n",
            "     |      \n",
            "     |              study = optuna.create_study()\n",
            "     |              study.optimize(objective, n_trials=10)\n",
            "     |              assert len(study.trials) == 5\n",
            "     |      \n",
            "     |      Raises:\n",
            "     |          RuntimeError:\n",
            "     |              If this method is called outside an objective function or callback.\n",
            "     |  \n",
            "     |  tell(self, trial: Union[optuna.trial._trial.Trial, int], values: Union[float, Sequence[float], NoneType] = None, state: optuna.trial._state.TrialState = TrialState.COMPLETE) -> None\n",
            "     |      Finish a trial created with :func:`~optuna.study.Study.ask`.\n",
            "     |      \n",
            "     |      .. seealso::\n",
            "     |      \n",
            "     |          The :ref:`ask_and_tell` tutorial provides use-cases with examples.\n",
            "     |      \n",
            "     |      Example:\n",
            "     |      \n",
            "     |          .. testcode::\n",
            "     |      \n",
            "     |              import optuna\n",
            "     |              from optuna.trial import TrialState\n",
            "     |      \n",
            "     |      \n",
            "     |              def f(x):\n",
            "     |                  return (x - 2) ** 2\n",
            "     |      \n",
            "     |      \n",
            "     |              def df(x):\n",
            "     |                  return 2 * x - 4\n",
            "     |      \n",
            "     |      \n",
            "     |              study = optuna.create_study()\n",
            "     |      \n",
            "     |              n_trials = 30\n",
            "     |      \n",
            "     |              for _ in range(n_trials):\n",
            "     |                  trial = study.ask()\n",
            "     |      \n",
            "     |                  lr = trial.suggest_float(\"lr\", 1e-5, 1e-1, log=True)\n",
            "     |      \n",
            "     |                  # Iterative gradient descent objective function.\n",
            "     |                  x = 3  # Initial value.\n",
            "     |                  for step in range(128):\n",
            "     |                      y = f(x)\n",
            "     |      \n",
            "     |                      trial.report(y, step=step)\n",
            "     |      \n",
            "     |                      if trial.should_prune():\n",
            "     |                          # Finish the trial with the pruned state.\n",
            "     |                          study.tell(trial, state=TrialState.PRUNED)\n",
            "     |                          break\n",
            "     |      \n",
            "     |                      gy = df(x)\n",
            "     |                      x -= gy * lr\n",
            "     |                  else:\n",
            "     |                      # Finish the trial with the final value after all iterations.\n",
            "     |                      study.tell(trial, y)\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          trial:\n",
            "     |              A :class:`~optuna.trial.Trial` object or a trial number.\n",
            "     |          values:\n",
            "     |              Optional objective value or a sequence of such values in case the study is used\n",
            "     |              for multi-objective optimization. Argument must be provided if ``state`` is\n",
            "     |              :class:`~optuna.trial.TrialState.COMPLETE` and should be :obj:`None` if ``state``\n",
            "     |              is :class:`~optuna.trial.TrialState.FAIL` or\n",
            "     |              :class:`~optuna.trial.TrialState.PRUNED`.\n",
            "     |          state:\n",
            "     |              State to be reported. Must be :class:`~optuna.trial.TrialState.COMPLETE`,\n",
            "     |              :class:`~optuna.trial.TrialState.FAIL` or\n",
            "     |              :class:`~optuna.trial.TrialState.PRUNED`.\n",
            "     |      \n",
            "     |      Raises:\n",
            "     |          TypeError:\n",
            "     |              If ``trial`` is not a :class:`~optuna.trial.Trial` or an :obj:`int`.\n",
            "     |          ValueError:\n",
            "     |              If any of the following.\n",
            "     |              ``values`` is a sequence but its length does not match the number of objectives\n",
            "     |              for its associated study.\n",
            "     |              ``state`` is :class:`~optuna.trial.TrialState.COMPLETE` but\n",
            "     |              ``values`` is :obj:`None`.\n",
            "     |              ``state`` is :class:`~optuna.trial.TrialState.FAIL` or\n",
            "     |              :class:`~optuna.trial.TrialState.PRUNED` but\n",
            "     |              ``values`` is not :obj:`None`.\n",
            "     |              ``state`` is not\n",
            "     |              :class:`~optuna.trial.TrialState.COMPLETE`,\n",
            "     |              :class:`~optuna.trial.TrialState.FAIL` or\n",
            "     |              :class:`~optuna.trial.TrialState.PRUNED`.\n",
            "     |              ``trial`` is a trial number but no\n",
            "     |              trial exists with that number.\n",
            "     |  \n",
            "     |  trials_dataframe(self, attrs: Tuple[str, ...] = ('number', 'value', 'datetime_start', 'datetime_complete', 'duration', 'params', 'user_attrs', 'system_attrs', 'state'), multi_index: bool = False) -> 'pd.DataFrame'\n",
            "     |      Export trials as a pandas DataFrame_.\n",
            "     |      \n",
            "     |      The DataFrame_ provides various features to analyze studies. It is also useful to draw a\n",
            "     |      histogram of objective values and to export trials as a CSV file.\n",
            "     |      If there are no trials, an empty DataFrame_ is returned.\n",
            "     |      \n",
            "     |      Example:\n",
            "     |      \n",
            "     |          .. testcode::\n",
            "     |      \n",
            "     |              import optuna\n",
            "     |              import pandas\n",
            "     |      \n",
            "     |      \n",
            "     |              def objective(trial):\n",
            "     |                  x = trial.suggest_float(\"x\", -1, 1)\n",
            "     |                  return x ** 2\n",
            "     |      \n",
            "     |      \n",
            "     |              study = optuna.create_study()\n",
            "     |              study.optimize(objective, n_trials=3)\n",
            "     |      \n",
            "     |              # Create a dataframe from the study.\n",
            "     |              df = study.trials_dataframe()\n",
            "     |              assert isinstance(df, pandas.DataFrame)\n",
            "     |              assert df.shape[0] == 3  # n_trials.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          attrs:\n",
            "     |              Specifies field names of :class:`~optuna.FrozenTrial` to include them to a\n",
            "     |              DataFrame of trials.\n",
            "     |          multi_index:\n",
            "     |              Specifies whether the returned DataFrame_ employs MultiIndex_ or not. Columns that\n",
            "     |              are hierarchical by nature such as ``(params, x)`` will be flattened to\n",
            "     |              ``params_x`` when set to :obj:`False`.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          A pandas DataFrame_ of trials in the :class:`~optuna.study.Study`.\n",
            "     |      \n",
            "     |      .. _DataFrame: http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html\n",
            "     |      .. _MultiIndex: https://pandas.pydata.org/pandas-docs/stable/advanced.html\n",
            "     |      \n",
            "     |      Note:\n",
            "     |          If ``value`` is in ``attrs`` during multi-objective optimization, it is implicitly\n",
            "     |          replaced with ``values``.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Data descriptors defined here:\n",
            "     |  \n",
            "     |  system_attrs\n",
            "     |      Return system attributes.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          A dictionary containing all system attributes.\n",
            "     |  \n",
            "     |  user_attrs\n",
            "     |      Return user attributes.\n",
            "     |      \n",
            "     |      .. seealso::\n",
            "     |      \n",
            "     |          See :func:`~optuna.study.Study.set_user_attr` for related method.\n",
            "     |      \n",
            "     |      Example:\n",
            "     |      \n",
            "     |          .. testcode::\n",
            "     |      \n",
            "     |              import optuna\n",
            "     |      \n",
            "     |      \n",
            "     |              def objective(trial):\n",
            "     |                  x = trial.suggest_float(\"x\", 0, 1)\n",
            "     |                  y = trial.suggest_float(\"y\", 0, 1)\n",
            "     |                  return x ** 2 + y ** 2\n",
            "     |      \n",
            "     |      \n",
            "     |              study = optuna.create_study()\n",
            "     |      \n",
            "     |              study.set_user_attr(\"objective function\", \"quadratic function\")\n",
            "     |              study.set_user_attr(\"dimensions\", 2)\n",
            "     |              study.set_user_attr(\"contributors\", [\"Akiba\", \"Sano\"])\n",
            "     |      \n",
            "     |              assert study.user_attrs == {\n",
            "     |                  \"objective function\": \"quadratic function\",\n",
            "     |                  \"dimensions\": 2,\n",
            "     |                  \"contributors\": [\"Akiba\", \"Sano\"],\n",
            "     |              }\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          A dictionary containing all user attributes.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Methods inherited from BaseStudy:\n",
            "     |  \n",
            "     |  get_trials(self, deepcopy: bool = True, states: Union[Tuple[optuna.trial._state.TrialState, ...], NoneType] = None) -> List[optuna.trial._frozen.FrozenTrial]\n",
            "     |      Return all trials in the study.\n",
            "     |      \n",
            "     |      The returned trials are ordered by trial number.\n",
            "     |      \n",
            "     |      Example:\n",
            "     |          .. testcode::\n",
            "     |      \n",
            "     |              import optuna\n",
            "     |      \n",
            "     |      \n",
            "     |              def objective(trial):\n",
            "     |                  x = trial.suggest_float(\"x\", -1, 1)\n",
            "     |                  return x ** 2\n",
            "     |      \n",
            "     |      \n",
            "     |              study = optuna.create_study()\n",
            "     |              study.optimize(objective, n_trials=3)\n",
            "     |      \n",
            "     |              trials = study.get_trials()\n",
            "     |              assert len(trials) == 3\n",
            "     |      Args:\n",
            "     |          deepcopy:\n",
            "     |              Flag to control whether to apply ``copy.deepcopy()`` to the trials.\n",
            "     |              Note that if you set the flag to :obj:`False`, you shouldn't mutate\n",
            "     |              any fields of the returned trial. Otherwise the internal state of\n",
            "     |              the study may corrupt and unexpected behavior may happen.\n",
            "     |          states:\n",
            "     |              Trial states to filter on. If :obj:`None`, include all states.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          A list of :class:`~optuna.FrozenTrial` objects.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Data descriptors inherited from BaseStudy:\n",
            "     |  \n",
            "     |  __dict__\n",
            "     |      dictionary for instance variables (if defined)\n",
            "     |  \n",
            "     |  __weakref__\n",
            "     |      list of weak references to the object (if defined)\n",
            "     |  \n",
            "     |  best_params\n",
            "     |      Return parameters of the best trial in the study.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          A dictionary containing parameters of the best trial.\n",
            "     |      \n",
            "     |      Raises:\n",
            "     |          :exc:`RuntimeError`:\n",
            "     |              If the study has more than one direction.\n",
            "     |  \n",
            "     |  best_trial\n",
            "     |      Return the best trial in the study.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          A :class:`~optuna.FrozenTrial` object of the best trial.\n",
            "     |      \n",
            "     |      Raises:\n",
            "     |          :exc:`RuntimeError`:\n",
            "     |              If the study has more than one direction.\n",
            "     |  \n",
            "     |  best_trials\n",
            "     |      Return trials located at the Pareto front in the study.\n",
            "     |      \n",
            "     |      A trial is located at the Pareto front if there are no trials that dominate the trial.\n",
            "     |      It's called that a trial ``t0`` dominates another trial ``t1`` if\n",
            "     |      ``all(v0 <= v1) for v0, v1 in zip(t0.values, t1.values)`` and\n",
            "     |      ``any(v0 < v1) for v0, v1 in zip(t0.values, t1.values)`` are held.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          A list of :class:`~optuna.trial.FrozenTrial` objects.\n",
            "     |  \n",
            "     |  best_value\n",
            "     |      Return the best objective value in the study.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          A float representing the best objective value.\n",
            "     |      \n",
            "     |      Raises:\n",
            "     |          :exc:`RuntimeError`:\n",
            "     |              If the study has more than one direction.\n",
            "     |  \n",
            "     |  direction\n",
            "     |      Return the direction of the study.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          A :class:`~optuna.study.StudyDirection` object.\n",
            "     |      \n",
            "     |      Raises:\n",
            "     |          :exc:`RuntimeError`:\n",
            "     |              If the study has more than one direction.\n",
            "     |  \n",
            "     |  directions\n",
            "     |      Return the directions of the study.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          A list of :class:`~optuna.study.StudyDirection` objects.\n",
            "     |  \n",
            "     |  trials\n",
            "     |      Return all trials in the study.\n",
            "     |      \n",
            "     |      The returned trials are ordered by trial number.\n",
            "     |      \n",
            "     |      This is a short form of ``self.get_trials(deepcopy=True, states=None)``.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          A list of :class:`~optuna.FrozenTrial` objects.\n",
            "    \n",
            "    class Trial(optuna.trial._base.BaseTrial)\n",
            "     |  Trial(study: 'optuna.study.Study', trial_id: int) -> None\n",
            "     |  \n",
            "     |  A trial is a process of evaluating an objective function.\n",
            "     |  \n",
            "     |  This object is passed to an objective function and provides interfaces to get parameter\n",
            "     |  suggestion, manage the trial's state, and set/get user-defined attributes of the trial.\n",
            "     |  \n",
            "     |  Note that the direct use of this constructor is not recommended.\n",
            "     |  This object is seamlessly instantiated and passed to the objective function behind\n",
            "     |  the :func:`optuna.study.Study.optimize()` method; hence library users do not care about\n",
            "     |  instantiation of this object.\n",
            "     |  \n",
            "     |  Args:\n",
            "     |      study:\n",
            "     |          A :class:`~optuna.study.Study` object.\n",
            "     |      trial_id:\n",
            "     |          A trial ID that is automatically generated.\n",
            "     |  \n",
            "     |  Method resolution order:\n",
            "     |      Trial\n",
            "     |      optuna.trial._base.BaseTrial\n",
            "     |      builtins.object\n",
            "     |  \n",
            "     |  Methods defined here:\n",
            "     |  \n",
            "     |  __init__(self, study: 'optuna.study.Study', trial_id: int) -> None\n",
            "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
            "     |  \n",
            "     |  report(self, value: float, step: int) -> None\n",
            "     |      Report an objective function value for a given step.\n",
            "     |      \n",
            "     |      The reported values are used by the pruners to determine whether this trial should be\n",
            "     |      pruned.\n",
            "     |      \n",
            "     |      .. seealso::\n",
            "     |          Please refer to :class:`~optuna.pruners.BasePruner`.\n",
            "     |      \n",
            "     |      .. note::\n",
            "     |          The reported value is converted to ``float`` type by applying ``float()``\n",
            "     |          function internally. Thus, it accepts all float-like types (e.g., ``numpy.float32``).\n",
            "     |          If the conversion fails, a ``TypeError`` is raised.\n",
            "     |      \n",
            "     |      Example:\n",
            "     |      \n",
            "     |          Report intermediate scores of `SGDClassifier <https://scikit-learn.org/stable/modules/\n",
            "     |          generated/sklearn.linear_model.SGDClassifier.html>`_ training.\n",
            "     |      \n",
            "     |          .. testcode::\n",
            "     |      \n",
            "     |              import numpy as np\n",
            "     |              from sklearn.datasets import load_iris\n",
            "     |              from sklearn.linear_model import SGDClassifier\n",
            "     |              from sklearn.model_selection import train_test_split\n",
            "     |      \n",
            "     |              import optuna\n",
            "     |      \n",
            "     |              X, y = load_iris(return_X_y=True)\n",
            "     |              X_train, X_valid, y_train, y_valid = train_test_split(X, y)\n",
            "     |      \n",
            "     |      \n",
            "     |              def objective(trial):\n",
            "     |                  clf = SGDClassifier(random_state=0)\n",
            "     |                  for step in range(100):\n",
            "     |                      clf.partial_fit(X_train, y_train, np.unique(y))\n",
            "     |                      intermediate_value = clf.score(X_valid, y_valid)\n",
            "     |                      trial.report(intermediate_value, step=step)\n",
            "     |                      if trial.should_prune():\n",
            "     |                          raise optuna.TrialPruned()\n",
            "     |      \n",
            "     |                  return clf.score(X_valid, y_valid)\n",
            "     |      \n",
            "     |      \n",
            "     |              study = optuna.create_study(direction=\"maximize\")\n",
            "     |              study.optimize(objective, n_trials=3)\n",
            "     |      \n",
            "     |      \n",
            "     |      Args:\n",
            "     |          value:\n",
            "     |              A value returned from the objective function.\n",
            "     |          step:\n",
            "     |              Step of the trial (e.g., Epoch of neural network training). Note that pruners\n",
            "     |              assume that ``step`` starts at zero. For example,\n",
            "     |              :class:`~optuna.pruners.MedianPruner` simply checks if ``step`` is less than\n",
            "     |              ``n_warmup_steps`` as the warmup mechanism.\n",
            "     |      \n",
            "     |      Raises:\n",
            "     |          :exc:`NotImplementedError`:\n",
            "     |              If trial is being used for multi-objective optimization.\n",
            "     |  \n",
            "     |  set_system_attr(self, key: str, value: Any) -> None\n",
            "     |      Set system attributes to the trial.\n",
            "     |      \n",
            "     |      Note that Optuna internally uses this method to save system messages such as failure\n",
            "     |      reason of trials. Please use :func:`~optuna.trial.Trial.set_user_attr` to set users'\n",
            "     |      attributes.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          key:\n",
            "     |              A key string of the attribute.\n",
            "     |          value:\n",
            "     |              A value of the attribute. The value should be JSON serializable.\n",
            "     |  \n",
            "     |  set_user_attr(self, key: str, value: Any) -> None\n",
            "     |      Set user attributes to the trial.\n",
            "     |      \n",
            "     |      The user attributes in the trial can be access via :func:`optuna.trial.Trial.user_attrs`.\n",
            "     |      \n",
            "     |      Example:\n",
            "     |      \n",
            "     |          Save fixed hyperparameters of neural network training.\n",
            "     |      \n",
            "     |          .. testcode::\n",
            "     |      \n",
            "     |              import numpy as np\n",
            "     |              from sklearn.datasets import load_iris\n",
            "     |              from sklearn.model_selection import train_test_split\n",
            "     |              from sklearn.neural_network import MLPClassifier\n",
            "     |      \n",
            "     |              import optuna\n",
            "     |      \n",
            "     |              X, y = load_iris(return_X_y=True)\n",
            "     |              X_train, X_valid, y_train, y_valid = train_test_split(X, y, random_state=0)\n",
            "     |      \n",
            "     |      \n",
            "     |              def objective(trial):\n",
            "     |                  trial.set_user_attr(\"BATCHSIZE\", 128)\n",
            "     |                  momentum = trial.suggest_uniform(\"momentum\", 0, 1.0)\n",
            "     |                  clf = MLPClassifier(\n",
            "     |                      hidden_layer_sizes=(100, 50),\n",
            "     |                      batch_size=trial.user_attrs[\"BATCHSIZE\"],\n",
            "     |                      momentum=momentum,\n",
            "     |                      solver=\"sgd\",\n",
            "     |                      random_state=0,\n",
            "     |                  )\n",
            "     |                  clf.fit(X_train, y_train)\n",
            "     |      \n",
            "     |                  return clf.score(X_valid, y_valid)\n",
            "     |      \n",
            "     |      \n",
            "     |              study = optuna.create_study(direction=\"maximize\")\n",
            "     |              study.optimize(objective, n_trials=3)\n",
            "     |              assert \"BATCHSIZE\" in study.best_trial.user_attrs.keys()\n",
            "     |              assert study.best_trial.user_attrs[\"BATCHSIZE\"] == 128\n",
            "     |      \n",
            "     |      \n",
            "     |      Args:\n",
            "     |          key:\n",
            "     |              A key string of the attribute.\n",
            "     |          value:\n",
            "     |              A value of the attribute. The value should be JSON serializable.\n",
            "     |  \n",
            "     |  should_prune(self) -> bool\n",
            "     |      Suggest whether the trial should be pruned or not.\n",
            "     |      \n",
            "     |      The suggestion is made by a pruning algorithm associated with the trial and is based on\n",
            "     |      previously reported values. The algorithm can be specified when constructing a\n",
            "     |      :class:`~optuna.study.Study`.\n",
            "     |      \n",
            "     |      .. note::\n",
            "     |          If no values have been reported, the algorithm cannot make meaningful suggestions.\n",
            "     |          Similarly, if this method is called multiple times with the exact same set of reported\n",
            "     |          values, the suggestions will be the same.\n",
            "     |      \n",
            "     |      .. seealso::\n",
            "     |          Please refer to the example code in :func:`optuna.trial.Trial.report`.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          A boolean value. If :obj:`True`, the trial should be pruned according to the\n",
            "     |          configured pruning algorithm. Otherwise, the trial should continue.\n",
            "     |      \n",
            "     |      Raises:\n",
            "     |          :exc:`NotImplementedError`:\n",
            "     |              If trial is being used for multi-objective optimization.\n",
            "     |  \n",
            "     |  suggest_categorical(self, name: str, choices: Sequence[Union[NoneType, bool, int, float, str]]) -> Union[NoneType, bool, int, float, str]\n",
            "     |      Suggest a value for the categorical parameter.\n",
            "     |      \n",
            "     |      The value is sampled from ``choices``.\n",
            "     |      \n",
            "     |      Example:\n",
            "     |      \n",
            "     |          Suggest a kernel function of `SVC <https://scikit-learn.org/stable/modules/generated/\n",
            "     |          sklearn.svm.SVC.html>`_.\n",
            "     |      \n",
            "     |          .. testcode::\n",
            "     |      \n",
            "     |              import numpy as np\n",
            "     |              from sklearn.datasets import load_iris\n",
            "     |              from sklearn.model_selection import train_test_split\n",
            "     |              from sklearn.svm import SVC\n",
            "     |      \n",
            "     |              import optuna\n",
            "     |      \n",
            "     |              X, y = load_iris(return_X_y=True)\n",
            "     |              X_train, X_valid, y_train, y_valid = train_test_split(X, y)\n",
            "     |      \n",
            "     |      \n",
            "     |              def objective(trial):\n",
            "     |                  kernel = trial.suggest_categorical(\"kernel\", [\"linear\", \"poly\", \"rbf\"])\n",
            "     |                  clf = SVC(kernel=kernel, gamma=\"scale\", random_state=0)\n",
            "     |                  clf.fit(X_train, y_train)\n",
            "     |                  return clf.score(X_valid, y_valid)\n",
            "     |      \n",
            "     |      \n",
            "     |              study = optuna.create_study(direction=\"maximize\")\n",
            "     |              study.optimize(objective, n_trials=3)\n",
            "     |      \n",
            "     |      \n",
            "     |      Args:\n",
            "     |          name:\n",
            "     |              A parameter name.\n",
            "     |          choices:\n",
            "     |              Parameter value candidates.\n",
            "     |      \n",
            "     |      .. seealso::\n",
            "     |          :class:`~optuna.distributions.CategoricalDistribution`.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          A suggested value.\n",
            "     |  \n",
            "     |  suggest_discrete_uniform(self, name: str, low: float, high: float, q: float) -> float\n",
            "     |      Suggest a value for the discrete parameter.\n",
            "     |      \n",
            "     |      The value is sampled from the range :math:`[\\mathsf{low}, \\mathsf{high}]`,\n",
            "     |      and the step of discretization is :math:`q`. More specifically,\n",
            "     |      this method returns one of the values in the sequence\n",
            "     |      :math:`\\mathsf{low}, \\mathsf{low} + q, \\mathsf{low} + 2 q, \\dots,\n",
            "     |      \\mathsf{low} + k q \\le \\mathsf{high}`,\n",
            "     |      where :math:`k` denotes an integer. Note that :math:`high` may be changed due to round-off\n",
            "     |      errors if :math:`q` is not an integer. Please check warning messages to find the changed\n",
            "     |      values.\n",
            "     |      \n",
            "     |      Example:\n",
            "     |      \n",
            "     |          Suggest a fraction of samples used for fitting the individual learners of\n",
            "     |          `GradientBoostingClassifier <https://scikit-learn.org/stable/modules/generated/\n",
            "     |          sklearn.ensemble.GradientBoostingClassifier.html>`_.\n",
            "     |      \n",
            "     |          .. testcode::\n",
            "     |      \n",
            "     |              import numpy as np\n",
            "     |              from sklearn.datasets import load_iris\n",
            "     |              from sklearn.ensemble import GradientBoostingClassifier\n",
            "     |              from sklearn.model_selection import train_test_split\n",
            "     |      \n",
            "     |              import optuna\n",
            "     |      \n",
            "     |              X, y = load_iris(return_X_y=True)\n",
            "     |              X_train, X_valid, y_train, y_valid = train_test_split(X, y)\n",
            "     |      \n",
            "     |      \n",
            "     |              def objective(trial):\n",
            "     |                  subsample = trial.suggest_discrete_uniform(\"subsample\", 0.1, 1.0, 0.1)\n",
            "     |                  clf = GradientBoostingClassifier(subsample=subsample, random_state=0)\n",
            "     |                  clf.fit(X_train, y_train)\n",
            "     |                  return clf.score(X_valid, y_valid)\n",
            "     |      \n",
            "     |      \n",
            "     |              study = optuna.create_study(direction=\"maximize\")\n",
            "     |              study.optimize(objective, n_trials=3)\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          name:\n",
            "     |              A parameter name.\n",
            "     |          low:\n",
            "     |              Lower endpoint of the range of suggested values. ``low`` is included in the range.\n",
            "     |          high:\n",
            "     |              Upper endpoint of the range of suggested values. ``high`` is included in the range.\n",
            "     |          q:\n",
            "     |              A step of discretization.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          A suggested float value.\n",
            "     |  \n",
            "     |  suggest_float(self, name: str, low: float, high: float, *, step: Union[float, NoneType] = None, log: bool = False) -> float\n",
            "     |      Suggest a value for the floating point parameter.\n",
            "     |      \n",
            "     |      Note that this is a wrapper method for :func:`~optuna.trial.Trial.suggest_uniform`,\n",
            "     |      :func:`~optuna.trial.Trial.suggest_loguniform` and\n",
            "     |      :func:`~optuna.trial.Trial.suggest_discrete_uniform`.\n",
            "     |      \n",
            "     |      .. versionadded:: 1.3.0\n",
            "     |      \n",
            "     |      .. seealso::\n",
            "     |          Please see also :func:`~optuna.trial.Trial.suggest_uniform`,\n",
            "     |          :func:`~optuna.trial.Trial.suggest_loguniform` and\n",
            "     |          :func:`~optuna.trial.Trial.suggest_discrete_uniform`.\n",
            "     |      \n",
            "     |      Example:\n",
            "     |      \n",
            "     |          Suggest a momentum, learning rate and scaling factor of learning rate\n",
            "     |          for neural network training.\n",
            "     |      \n",
            "     |          .. testcode::\n",
            "     |      \n",
            "     |              import numpy as np\n",
            "     |              from sklearn.datasets import load_iris\n",
            "     |              from sklearn.model_selection import train_test_split\n",
            "     |              from sklearn.neural_network import MLPClassifier\n",
            "     |      \n",
            "     |              import optuna\n",
            "     |      \n",
            "     |              X, y = load_iris(return_X_y=True)\n",
            "     |              X_train, X_valid, y_train, y_valid = train_test_split(X, y, random_state=0)\n",
            "     |      \n",
            "     |      \n",
            "     |              def objective(trial):\n",
            "     |                  momentum = trial.suggest_float(\"momentum\", 0.0, 1.0)\n",
            "     |                  learning_rate_init = trial.suggest_float(\n",
            "     |                      \"learning_rate_init\", 1e-5, 1e-3, log=True\n",
            "     |                  )\n",
            "     |                  power_t = trial.suggest_float(\"power_t\", 0.2, 0.8, step=0.1)\n",
            "     |                  clf = MLPClassifier(\n",
            "     |                      hidden_layer_sizes=(100, 50),\n",
            "     |                      momentum=momentum,\n",
            "     |                      learning_rate_init=learning_rate_init,\n",
            "     |                      solver=\"sgd\",\n",
            "     |                      random_state=0,\n",
            "     |                      power_t=power_t,\n",
            "     |                  )\n",
            "     |                  clf.fit(X_train, y_train)\n",
            "     |      \n",
            "     |                  return clf.score(X_valid, y_valid)\n",
            "     |      \n",
            "     |      \n",
            "     |              study = optuna.create_study(direction=\"maximize\")\n",
            "     |              study.optimize(objective, n_trials=3)\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          name:\n",
            "     |              A parameter name.\n",
            "     |          low:\n",
            "     |              Lower endpoint of the range of suggested values. ``low`` is included in the range.\n",
            "     |          high:\n",
            "     |              Upper endpoint of the range of suggested values. ``high`` is excluded from the\n",
            "     |              range.\n",
            "     |      \n",
            "     |              .. note::\n",
            "     |                  If ``step`` is specified, ``high`` is included as well as ``low`` because\n",
            "     |                  this method falls back to :func:`~optuna.trial.Trial.suggest_discrete_uniform`.\n",
            "     |      \n",
            "     |          step:\n",
            "     |              A step of discretization.\n",
            "     |      \n",
            "     |              .. note::\n",
            "     |                  The ``step`` and ``log`` arguments cannot be used at the same time. To set\n",
            "     |                  the ``step`` argument to a float number, set the ``log`` argument to\n",
            "     |                  :obj:`False`.\n",
            "     |          log:\n",
            "     |              A flag to sample the value from the log domain or not.\n",
            "     |              If ``log`` is true, the value is sampled from the range in the log domain.\n",
            "     |              Otherwise, the value is sampled from the range in the linear domain.\n",
            "     |              See also :func:`suggest_uniform` and :func:`suggest_loguniform`.\n",
            "     |      \n",
            "     |              .. note::\n",
            "     |                  The ``step`` and ``log`` arguments cannot be used at the same time. To set\n",
            "     |                  the ``log`` argument to :obj:`True`, set the ``step`` argument to :obj:`None`.\n",
            "     |      \n",
            "     |      Raises:\n",
            "     |          :exc:`ValueError`:\n",
            "     |              If ``step is not None`` and ``log = True`` are specified.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          A suggested float value.\n",
            "     |  \n",
            "     |  suggest_int(self, name: str, low: int, high: int, step: int = 1, log: bool = False) -> int\n",
            "     |      Suggest a value for the integer parameter.\n",
            "     |      \n",
            "     |      The value is sampled from the integers in :math:`[\\mathsf{low}, \\mathsf{high}]`.\n",
            "     |      \n",
            "     |      Example:\n",
            "     |      \n",
            "     |          Suggest the number of trees in `RandomForestClassifier <https://scikit-learn.org/\n",
            "     |          stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html>`_.\n",
            "     |      \n",
            "     |          .. testcode::\n",
            "     |      \n",
            "     |              import numpy as np\n",
            "     |              from sklearn.datasets import load_iris\n",
            "     |              from sklearn.ensemble import RandomForestClassifier\n",
            "     |              from sklearn.model_selection import train_test_split\n",
            "     |      \n",
            "     |              import optuna\n",
            "     |      \n",
            "     |              X, y = load_iris(return_X_y=True)\n",
            "     |              X_train, X_valid, y_train, y_valid = train_test_split(X, y)\n",
            "     |      \n",
            "     |      \n",
            "     |              def objective(trial):\n",
            "     |                  n_estimators = trial.suggest_int(\"n_estimators\", 50, 400)\n",
            "     |                  clf = RandomForestClassifier(n_estimators=n_estimators, random_state=0)\n",
            "     |                  clf.fit(X_train, y_train)\n",
            "     |                  return clf.score(X_valid, y_valid)\n",
            "     |      \n",
            "     |      \n",
            "     |              study = optuna.create_study(direction=\"maximize\")\n",
            "     |              study.optimize(objective, n_trials=3)\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          name:\n",
            "     |              A parameter name.\n",
            "     |          low:\n",
            "     |              Lower endpoint of the range of suggested values. ``low`` is included in the range.\n",
            "     |          high:\n",
            "     |              Upper endpoint of the range of suggested values. ``high`` is included in the range.\n",
            "     |          step:\n",
            "     |              A step of discretization.\n",
            "     |      \n",
            "     |              .. note::\n",
            "     |                  Note that :math:`\\mathsf{high}` is modified if the range is not divisible by\n",
            "     |                  :math:`\\mathsf{step}`. Please check the warning messages to find the changed\n",
            "     |                  values.\n",
            "     |      \n",
            "     |              .. note::\n",
            "     |                  The method returns one of the values in the sequence\n",
            "     |                  :math:`\\mathsf{low}, \\mathsf{low} + \\mathsf{step}, \\mathsf{low} + 2 *\n",
            "     |                  \\mathsf{step}, \\dots, \\mathsf{low} + k * \\mathsf{step} \\le\n",
            "     |                  \\mathsf{high}`, where :math:`k` denotes an integer.\n",
            "     |      \n",
            "     |              .. note::\n",
            "     |                  The ``step != 1`` and ``log`` arguments cannot be used at the same time.\n",
            "     |                  To set the ``step`` argument :math:`\\mathsf{step} \\ge 2`, set the\n",
            "     |                  ``log`` argument to :obj:`False`.\n",
            "     |          log:\n",
            "     |              A flag to sample the value from the log domain or not.\n",
            "     |      \n",
            "     |              .. note::\n",
            "     |                  If ``log`` is true, at first, the range of suggested values is divided into\n",
            "     |                  grid points of width 1. The range of suggested values is then converted to\n",
            "     |                  a log domain, from which a value is sampled. The uniformly sampled\n",
            "     |                  value is re-converted to the original domain and rounded to the nearest grid\n",
            "     |                  point that we just split, and the suggested value is determined.\n",
            "     |                  For example, if `low = 2` and `high = 8`, then the range of suggested values is\n",
            "     |                  `[2, 3, 4, 5, 6, 7, 8]` and lower values tend to be more sampled than higher\n",
            "     |                  values.\n",
            "     |      \n",
            "     |              .. note::\n",
            "     |                  The ``step != 1`` and ``log`` arguments cannot be used at the same time.\n",
            "     |                  To set the ``log`` argument to :obj:`True`, set the ``step`` argument to 1.\n",
            "     |      \n",
            "     |      Raises:\n",
            "     |          :exc:`ValueError`:\n",
            "     |              If ``step != 1`` and ``log = True`` are specified.\n",
            "     |  \n",
            "     |  suggest_loguniform(self, name: str, low: float, high: float) -> float\n",
            "     |      Suggest a value for the continuous parameter.\n",
            "     |      \n",
            "     |      The value is sampled from the range :math:`[\\mathsf{low}, \\mathsf{high})`\n",
            "     |      in the log domain. When :math:`\\mathsf{low} = \\mathsf{high}`, the value of\n",
            "     |      :math:`\\mathsf{low}` will be returned.\n",
            "     |      \n",
            "     |      Example:\n",
            "     |      \n",
            "     |          Suggest penalty parameter ``C`` of `SVC <https://scikit-learn.org/stable/modules/\n",
            "     |          generated/sklearn.svm.SVC.html>`_.\n",
            "     |      \n",
            "     |          .. testcode::\n",
            "     |      \n",
            "     |              import numpy as np\n",
            "     |              from sklearn.datasets import load_iris\n",
            "     |              from sklearn.model_selection import train_test_split\n",
            "     |              from sklearn.svm import SVC\n",
            "     |      \n",
            "     |              import optuna\n",
            "     |      \n",
            "     |              X, y = load_iris(return_X_y=True)\n",
            "     |              X_train, X_valid, y_train, y_valid = train_test_split(X, y)\n",
            "     |      \n",
            "     |      \n",
            "     |              def objective(trial):\n",
            "     |                  c = trial.suggest_loguniform(\"c\", 1e-5, 1e2)\n",
            "     |                  clf = SVC(C=c, gamma=\"scale\", random_state=0)\n",
            "     |                  clf.fit(X_train, y_train)\n",
            "     |                  return clf.score(X_valid, y_valid)\n",
            "     |      \n",
            "     |      \n",
            "     |              study = optuna.create_study(direction=\"maximize\")\n",
            "     |              study.optimize(objective, n_trials=3)\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          name:\n",
            "     |              A parameter name.\n",
            "     |          low:\n",
            "     |              Lower endpoint of the range of suggested values. ``low`` is included in the range.\n",
            "     |          high:\n",
            "     |              Upper endpoint of the range of suggested values. ``high`` is excluded from the\n",
            "     |              range.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          A suggested float value.\n",
            "     |  \n",
            "     |  suggest_uniform(self, name: str, low: float, high: float) -> float\n",
            "     |      Suggest a value for the continuous parameter.\n",
            "     |      \n",
            "     |      The value is sampled from the range :math:`[\\mathsf{low}, \\mathsf{high})`\n",
            "     |      in the linear domain. When :math:`\\mathsf{low} = \\mathsf{high}`, the value of\n",
            "     |      :math:`\\mathsf{low}` will be returned.\n",
            "     |      \n",
            "     |      Example:\n",
            "     |      \n",
            "     |          Suggest a momentum for neural network training.\n",
            "     |      \n",
            "     |          .. testcode::\n",
            "     |      \n",
            "     |              import numpy as np\n",
            "     |              from sklearn.datasets import load_iris\n",
            "     |              from sklearn.model_selection import train_test_split\n",
            "     |              from sklearn.neural_network import MLPClassifier\n",
            "     |      \n",
            "     |              import optuna\n",
            "     |      \n",
            "     |              X, y = load_iris(return_X_y=True)\n",
            "     |              X_train, X_valid, y_train, y_valid = train_test_split(X, y)\n",
            "     |      \n",
            "     |      \n",
            "     |              def objective(trial):\n",
            "     |                  momentum = trial.suggest_uniform(\"momentum\", 0.0, 1.0)\n",
            "     |                  clf = MLPClassifier(\n",
            "     |                      hidden_layer_sizes=(100, 50),\n",
            "     |                      momentum=momentum,\n",
            "     |                      solver=\"sgd\",\n",
            "     |                      random_state=0,\n",
            "     |                  )\n",
            "     |                  clf.fit(X_train, y_train)\n",
            "     |      \n",
            "     |                  return clf.score(X_valid, y_valid)\n",
            "     |      \n",
            "     |      \n",
            "     |              study = optuna.create_study(direction=\"maximize\")\n",
            "     |              study.optimize(objective, n_trials=3)\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          name:\n",
            "     |              A parameter name.\n",
            "     |          low:\n",
            "     |              Lower endpoint of the range of suggested values. ``low`` is included in the range.\n",
            "     |          high:\n",
            "     |              Upper endpoint of the range of suggested values. ``high`` is excluded from the\n",
            "     |              range.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          A suggested float value.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Data descriptors defined here:\n",
            "     |  \n",
            "     |  datetime_start\n",
            "     |      Return start datetime.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          Datetime where the :class:`~optuna.trial.Trial` started.\n",
            "     |  \n",
            "     |  distributions\n",
            "     |      Return distributions of parameters to be optimized.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          A dictionary containing all distributions.\n",
            "     |  \n",
            "     |  number\n",
            "     |      Return trial's number which is consecutive and unique in a study.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          A trial number.\n",
            "     |  \n",
            "     |  params\n",
            "     |      Return parameters to be optimized.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          A dictionary containing all parameters.\n",
            "     |  \n",
            "     |  system_attrs\n",
            "     |      Return system attributes.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          A dictionary containing all system attributes.\n",
            "     |  \n",
            "     |  user_attrs\n",
            "     |      Return user attributes.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          A dictionary containing all user attributes.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Data and other attributes defined here:\n",
            "     |  \n",
            "     |  __abstractmethods__ = frozenset()\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Data descriptors inherited from optuna.trial._base.BaseTrial:\n",
            "     |  \n",
            "     |  __dict__\n",
            "     |      dictionary for instance variables (if defined)\n",
            "     |  \n",
            "     |  __weakref__\n",
            "     |      list of weak references to the object (if defined)\n",
            "    \n",
            "    class TrialPruned(OptunaError)\n",
            "     |  Exception for pruned trials.\n",
            "     |  \n",
            "     |  This error tells a trainer that the current :class:`~optuna.trial.Trial` was pruned. It is\n",
            "     |  supposed to be raised after :func:`optuna.trial.Trial.should_prune` as shown in the following\n",
            "     |  example.\n",
            "     |  \n",
            "     |  See also:\n",
            "     |      :class:`optuna.TrialPruned` is an alias of :class:`optuna.exceptions.TrialPruned`.\n",
            "     |  \n",
            "     |  Example:\n",
            "     |  \n",
            "     |      .. testcode::\n",
            "     |  \n",
            "     |          import numpy as np\n",
            "     |          from sklearn.datasets import load_iris\n",
            "     |          from sklearn.linear_model import SGDClassifier\n",
            "     |          from sklearn.model_selection import train_test_split\n",
            "     |  \n",
            "     |          import optuna\n",
            "     |  \n",
            "     |          X, y = load_iris(return_X_y=True)\n",
            "     |          X_train, X_valid, y_train, y_valid = train_test_split(X, y)\n",
            "     |          classes = np.unique(y)\n",
            "     |  \n",
            "     |  \n",
            "     |          def objective(trial):\n",
            "     |              alpha = trial.suggest_float(\"alpha\", 0.0, 1.0)\n",
            "     |              clf = SGDClassifier(alpha=alpha)\n",
            "     |              n_train_iter = 100\n",
            "     |  \n",
            "     |              for step in range(n_train_iter):\n",
            "     |                  clf.partial_fit(X_train, y_train, classes=classes)\n",
            "     |  \n",
            "     |                  intermediate_value = clf.score(X_valid, y_valid)\n",
            "     |                  trial.report(intermediate_value, step)\n",
            "     |  \n",
            "     |                  if trial.should_prune():\n",
            "     |                      raise optuna.TrialPruned()\n",
            "     |  \n",
            "     |              return clf.score(X_valid, y_valid)\n",
            "     |  \n",
            "     |  \n",
            "     |          study = optuna.create_study(direction=\"maximize\")\n",
            "     |          study.optimize(objective, n_trials=20)\n",
            "     |  \n",
            "     |  Method resolution order:\n",
            "     |      TrialPruned\n",
            "     |      OptunaError\n",
            "     |      builtins.Exception\n",
            "     |      builtins.BaseException\n",
            "     |      builtins.object\n",
            "     |  \n",
            "     |  Data descriptors inherited from OptunaError:\n",
            "     |  \n",
            "     |  __weakref__\n",
            "     |      list of weak references to the object (if defined)\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Methods inherited from builtins.Exception:\n",
            "     |  \n",
            "     |  __init__(self, /, *args, **kwargs)\n",
            "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Static methods inherited from builtins.Exception:\n",
            "     |  \n",
            "     |  __new__(*args, **kwargs) from builtins.type\n",
            "     |      Create and return a new object.  See help(type) for accurate signature.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Methods inherited from builtins.BaseException:\n",
            "     |  \n",
            "     |  __delattr__(self, name, /)\n",
            "     |      Implement delattr(self, name).\n",
            "     |  \n",
            "     |  __getattribute__(self, name, /)\n",
            "     |      Return getattr(self, name).\n",
            "     |  \n",
            "     |  __reduce__(...)\n",
            "     |      Helper for pickle.\n",
            "     |  \n",
            "     |  __repr__(self, /)\n",
            "     |      Return repr(self).\n",
            "     |  \n",
            "     |  __setattr__(self, name, value, /)\n",
            "     |      Implement setattr(self, name, value).\n",
            "     |  \n",
            "     |  __setstate__(...)\n",
            "     |  \n",
            "     |  __str__(self, /)\n",
            "     |      Return str(self).\n",
            "     |  \n",
            "     |  with_traceback(...)\n",
            "     |      Exception.with_traceback(tb) --\n",
            "     |      set self.__traceback__ to tb and return self.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Data descriptors inherited from builtins.BaseException:\n",
            "     |  \n",
            "     |  __cause__\n",
            "     |      exception cause\n",
            "     |  \n",
            "     |  __context__\n",
            "     |      exception context\n",
            "     |  \n",
            "     |  __dict__\n",
            "     |  \n",
            "     |  __suppress_context__\n",
            "     |  \n",
            "     |  __traceback__\n",
            "     |  \n",
            "     |  args\n",
            "\n",
            "FUNCTIONS\n",
            "    copy_study(from_study_name: str, from_storage: Union[str, optuna.storages._base.BaseStorage], to_storage: Union[str, optuna.storages._base.BaseStorage], to_study_name: Union[str, NoneType] = None) -> None\n",
            "        Copy study from one storage to another.\n",
            "        \n",
            "        The direction(s) of the objective(s) in the study, trials, user attributes and system\n",
            "        attributes are copied.\n",
            "        \n",
            "        Example:\n",
            "        \n",
            "            .. testsetup::\n",
            "        \n",
            "                import os\n",
            "        \n",
            "                if os.path.exists(\"example.db\"):\n",
            "                    raise RuntimeError(\"'example.db' already exists. Please remove it.\")\n",
            "                if os.path.exists(\"example_copy.db\"):\n",
            "                    raise RuntimeError(\"'example_copy.db' already exists. Please remove it.\")\n",
            "        \n",
            "            .. testcode::\n",
            "        \n",
            "                import optuna\n",
            "        \n",
            "        \n",
            "                def objective(trial):\n",
            "                    x = trial.suggest_float(\"x\", -10, 10)\n",
            "                    return (x - 2) ** 2\n",
            "        \n",
            "        \n",
            "                study = optuna.create_study(\n",
            "                    study_name=\"example-study\",\n",
            "                    storage=\"sqlite:///example.db\",\n",
            "                )\n",
            "                study.optimize(objective, n_trials=3)\n",
            "        \n",
            "                optuna.copy_study(\n",
            "                    from_study_name=\"example-study\",\n",
            "                    from_storage=\"sqlite:///example.db\",\n",
            "                    to_storage=\"sqlite:///example_copy.db\",\n",
            "                )\n",
            "        \n",
            "                study = optuna.load_study(\n",
            "                    study_name=None,\n",
            "                    storage=\"sqlite:///example_copy.db\",\n",
            "                )\n",
            "        \n",
            "            .. testcleanup::\n",
            "        \n",
            "                os.remove(\"example.db\")\n",
            "                os.remove(\"example_copy.db\")\n",
            "        \n",
            "        Args:\n",
            "            from_study_name:\n",
            "                Name of study.\n",
            "            from_storage:\n",
            "                Source database URL such as ``sqlite:///example.db``. Please see also the\n",
            "                documentation of :func:`~optuna.study.create_study` for further details.\n",
            "            to_storage:\n",
            "                Destination database URL.\n",
            "            to_study_name:\n",
            "                Name of the created study. If omitted, ``from_study_name`` is used.\n",
            "        \n",
            "        Raises:\n",
            "            :class:`~optuna.exceptions.DuplicatedStudyError`:\n",
            "                If a study with a conflicting name already exists in the destination storage.\n",
            "        \n",
            "        .. note::\n",
            "            Added in v2.8.0 as an experimental feature. The interface may change in newer versions\n",
            "            without prior notice. See https://github.com/optuna/optuna/releases/tag/v2.8.0.\n",
            "    \n",
            "    create_study(storage: Union[str, optuna.storages._base.BaseStorage, NoneType] = None, sampler: Union[ForwardRef('samplers.BaseSampler'), NoneType] = None, pruner: Union[optuna.pruners._base.BasePruner, NoneType] = None, study_name: Union[str, NoneType] = None, direction: Union[str, optuna.study._study_direction.StudyDirection, NoneType] = None, load_if_exists: bool = False, *, directions: Union[Sequence[Union[str, optuna.study._study_direction.StudyDirection]], NoneType] = None) -> optuna.study.study.Study\n",
            "        Create a new :class:`~optuna.study.Study`.\n",
            "        \n",
            "        Example:\n",
            "        \n",
            "            .. testcode::\n",
            "        \n",
            "                import optuna\n",
            "        \n",
            "        \n",
            "                def objective(trial):\n",
            "                    x = trial.suggest_float(\"x\", 0, 10)\n",
            "                    return x ** 2\n",
            "        \n",
            "        \n",
            "                study = optuna.create_study()\n",
            "                study.optimize(objective, n_trials=3)\n",
            "        \n",
            "        Args:\n",
            "            storage:\n",
            "                Database URL. If this argument is set to None, in-memory storage is used, and the\n",
            "                :class:`~optuna.study.Study` will not be persistent.\n",
            "        \n",
            "                .. note::\n",
            "                    When a database URL is passed, Optuna internally uses `SQLAlchemy`_ to handle\n",
            "                    the database. Please refer to `SQLAlchemy's document`_ for further details.\n",
            "                    If you want to specify non-default options to `SQLAlchemy Engine`_, you can\n",
            "                    instantiate :class:`~optuna.storages.RDBStorage` with your desired options and\n",
            "                    pass it to the ``storage`` argument instead of a URL.\n",
            "        \n",
            "                 .. _SQLAlchemy: https://www.sqlalchemy.org/\n",
            "                 .. _SQLAlchemy's document:\n",
            "                     https://docs.sqlalchemy.org/en/latest/core/engines.html#database-urls\n",
            "                 .. _SQLAlchemy Engine: https://docs.sqlalchemy.org/en/latest/core/engines.html\n",
            "        \n",
            "            sampler:\n",
            "                A sampler object that implements background algorithm for value suggestion.\n",
            "                If :obj:`None` is specified, :class:`~optuna.samplers.TPESampler` is used during\n",
            "                single-objective optimization and :class:`~optuna.samplers.NSGAIISampler` during\n",
            "                multi-objective optimization. See also :class:`~optuna.samplers`.\n",
            "            pruner:\n",
            "                A pruner object that decides early stopping of unpromising trials. If :obj:`None`\n",
            "                is specified, :class:`~optuna.pruners.MedianPruner` is used as the default. See\n",
            "                also :class:`~optuna.pruners`.\n",
            "            study_name:\n",
            "                Study's name. If this argument is set to None, a unique name is generated\n",
            "                automatically.\n",
            "            direction:\n",
            "                Direction of optimization. Set ``minimize`` for minimization and ``maximize`` for\n",
            "                maximization. You can also pass the corresponding :class:`~optuna.study.StudyDirection`\n",
            "                object.\n",
            "        \n",
            "                .. note::\n",
            "                    If none of `direction` and `directions` are specified, the direction of the study\n",
            "                    is set to \"minimize\".\n",
            "            load_if_exists:\n",
            "                Flag to control the behavior to handle a conflict of study names.\n",
            "                In the case where a study named ``study_name`` already exists in the ``storage``,\n",
            "                a :class:`~optuna.exceptions.DuplicatedStudyError` is raised if ``load_if_exists`` is\n",
            "                set to :obj:`False`.\n",
            "                Otherwise, the creation of the study is skipped, and the existing one is returned.\n",
            "            directions:\n",
            "                A sequence of directions during multi-objective optimization.\n",
            "        \n",
            "        Returns:\n",
            "            A :class:`~optuna.study.Study` object.\n",
            "        \n",
            "        Raises:\n",
            "            :exc:`ValueError`:\n",
            "                If the length of ``directions`` is zero.\n",
            "                Or, if ``direction`` is neither 'minimize' nor 'maximize' when it is a string.\n",
            "                Or, if the element of ``directions`` is neither `minimize` nor `maximize`.\n",
            "                Or, if both ``direction`` and ``directions`` are specified.\n",
            "        \n",
            "        See also:\n",
            "            :func:`optuna.create_study` is an alias of :func:`optuna.study.create_study`.\n",
            "    \n",
            "    create_trial(*, state: optuna.trial._state.TrialState = TrialState.COMPLETE, value: Union[float, NoneType] = None, values: Union[Sequence[float], NoneType] = None, params: Union[Dict[str, Any], NoneType] = None, distributions: Union[Dict[str, optuna.distributions.BaseDistribution], NoneType] = None, user_attrs: Union[Dict[str, Any], NoneType] = None, system_attrs: Union[Dict[str, Any], NoneType] = None, intermediate_values: Union[Dict[int, float], NoneType] = None) -> optuna.trial._frozen.FrozenTrial\n",
            "        Create a new :class:`~optuna.trial.FrozenTrial`.\n",
            "        \n",
            "        Example:\n",
            "        \n",
            "            .. testcode::\n",
            "        \n",
            "                import optuna\n",
            "                from optuna.distributions import CategoricalDistribution\n",
            "                from optuna.distributions import UniformDistribution\n",
            "        \n",
            "                trial = optuna.trial.create_trial(\n",
            "                    params={\"x\": 1.0, \"y\": 0},\n",
            "                    distributions={\n",
            "                        \"x\": UniformDistribution(0, 10),\n",
            "                        \"y\": CategoricalDistribution([-1, 0, 1]),\n",
            "                    },\n",
            "                    value=5.0,\n",
            "                )\n",
            "        \n",
            "                assert isinstance(trial, optuna.trial.FrozenTrial)\n",
            "                assert trial.value == 5.0\n",
            "                assert trial.params == {\"x\": 1.0, \"y\": 0}\n",
            "        \n",
            "        .. seealso::\n",
            "        \n",
            "            See :func:`~optuna.study.Study.add_trial` for how this function can be used to create a\n",
            "            study from existing trials.\n",
            "        \n",
            "        .. note::\n",
            "        \n",
            "            Please note that this is a low-level API. In general, trials that are passed to objective\n",
            "            functions are created inside :func:`~optuna.study.Study.optimize`.\n",
            "        \n",
            "        .. note::\n",
            "            When ``state`` is :class:`TrialState.COMPLETE`, the following parameters are\n",
            "            required:\n",
            "        \n",
            "            * ``params``\n",
            "            * ``distributions``\n",
            "            * ``value`` or ``values``\n",
            "        \n",
            "        Args:\n",
            "            state:\n",
            "                Trial state.\n",
            "            value:\n",
            "                Trial objective value. Must be specified if ``state`` is :class:`TrialState.COMPLETE`.\n",
            "            values:\n",
            "                Sequence of the trial objective values. The length is greater than 1 if the problem is\n",
            "                multi-objective optimization.\n",
            "                Must be specified if ``state`` is :class:`TrialState.COMPLETE`.\n",
            "            params:\n",
            "                Dictionary with suggested parameters of the trial.\n",
            "            distributions:\n",
            "                Dictionary with parameter distributions of the trial.\n",
            "            user_attrs:\n",
            "                Dictionary with user attributes.\n",
            "            system_attrs:\n",
            "                Dictionary with system attributes. Should not have to be used for most users.\n",
            "            intermediate_values:\n",
            "                Dictionary with intermediate objective values of the trial.\n",
            "        \n",
            "        Returns:\n",
            "            Created trial.\n",
            "        \n",
            "        Raises:\n",
            "            :exc:`ValueError`:\n",
            "                If both ``value`` and ``values`` are specified.\n",
            "        \n",
            "        .. note::\n",
            "            Added in v2.0.0 as an experimental feature. The interface may change in newer versions\n",
            "            without prior notice. See https://github.com/optuna/optuna/releases/tag/v2.0.0.\n",
            "    \n",
            "    delete_study(study_name: str, storage: Union[str, optuna.storages._base.BaseStorage]) -> None\n",
            "        Delete a :class:`~optuna.study.Study` object.\n",
            "        \n",
            "        Example:\n",
            "        \n",
            "            .. testsetup::\n",
            "        \n",
            "                import os\n",
            "        \n",
            "                if os.path.exists(\"example.db\"):\n",
            "                    raise RuntimeError(\"'example.db' already exists. Please remove it.\")\n",
            "        \n",
            "            .. testcode::\n",
            "        \n",
            "                import optuna\n",
            "        \n",
            "        \n",
            "                def objective(trial):\n",
            "                    x = trial.suggest_float(\"x\", -10, 10)\n",
            "                    return (x - 2) ** 2\n",
            "        \n",
            "        \n",
            "                study = optuna.create_study(study_name=\"example-study\", storage=\"sqlite:///example.db\")\n",
            "                study.optimize(objective, n_trials=3)\n",
            "        \n",
            "                optuna.delete_study(study_name=\"example-study\", storage=\"sqlite:///example.db\")\n",
            "        \n",
            "            .. testcleanup::\n",
            "        \n",
            "                os.remove(\"example.db\")\n",
            "        \n",
            "        Args:\n",
            "            study_name:\n",
            "                Study's name.\n",
            "            storage:\n",
            "                Database URL such as ``sqlite:///example.db``. Please see also the documentation of\n",
            "                :func:`~optuna.study.create_study` for further details.\n",
            "        \n",
            "        See also:\n",
            "            :func:`optuna.delete_study` is an alias of :func:`optuna.study.delete_study`.\n",
            "    \n",
            "    get_all_study_summaries(storage: Union[str, optuna.storages._base.BaseStorage]) -> List[optuna.study._study_summary.StudySummary]\n",
            "        Get all history of studies stored in a specified storage.\n",
            "        \n",
            "        Example:\n",
            "        \n",
            "            .. testsetup::\n",
            "        \n",
            "                import os\n",
            "        \n",
            "                if os.path.exists(\"example.db\"):\n",
            "                    raise RuntimeError(\"'example.db' already exists. Please remove it.\")\n",
            "        \n",
            "            .. testcode::\n",
            "        \n",
            "                import optuna\n",
            "        \n",
            "        \n",
            "                def objective(trial):\n",
            "                    x = trial.suggest_float(\"x\", -10, 10)\n",
            "                    return (x - 2) ** 2\n",
            "        \n",
            "        \n",
            "                study = optuna.create_study(study_name=\"example-study\", storage=\"sqlite:///example.db\")\n",
            "                study.optimize(objective, n_trials=3)\n",
            "        \n",
            "                study_summaries = optuna.study.get_all_study_summaries(storage=\"sqlite:///example.db\")\n",
            "                assert len(study_summaries) == 1\n",
            "        \n",
            "                study_summary = study_summaries[0]\n",
            "                assert study_summary.study_name == \"example-study\"\n",
            "        \n",
            "            .. testcleanup::\n",
            "        \n",
            "                os.remove(\"example.db\")\n",
            "        \n",
            "        Args:\n",
            "            storage:\n",
            "                Database URL such as ``sqlite:///example.db``. Please see also the documentation of\n",
            "                :func:`~optuna.study.create_study` for further details.\n",
            "        \n",
            "        Returns:\n",
            "            List of study history summarized as :class:`~optuna.study.StudySummary` objects.\n",
            "        \n",
            "        See also:\n",
            "            :func:`optuna.get_all_study_summaries` is an alias of\n",
            "            :func:`optuna.study.get_all_study_summaries`.\n",
            "    \n",
            "    load_study(study_name: Union[str, NoneType], storage: Union[str, optuna.storages._base.BaseStorage], sampler: Union[ForwardRef('samplers.BaseSampler'), NoneType] = None, pruner: Union[optuna.pruners._base.BasePruner, NoneType] = None) -> optuna.study.study.Study\n",
            "        Load the existing :class:`~optuna.study.Study` that has the specified name.\n",
            "        \n",
            "        Example:\n",
            "        \n",
            "            .. testsetup::\n",
            "        \n",
            "                import os\n",
            "        \n",
            "                if os.path.exists(\"example.db\"):\n",
            "                    raise RuntimeError(\"'example.db' already exists. Please remove it.\")\n",
            "        \n",
            "            .. testcode::\n",
            "        \n",
            "                import optuna\n",
            "        \n",
            "        \n",
            "                def objective(trial):\n",
            "                    x = trial.suggest_float(\"x\", 0, 10)\n",
            "                    return x ** 2\n",
            "        \n",
            "        \n",
            "                study = optuna.create_study(storage=\"sqlite:///example.db\", study_name=\"my_study\")\n",
            "                study.optimize(objective, n_trials=3)\n",
            "        \n",
            "                loaded_study = optuna.load_study(study_name=\"my_study\", storage=\"sqlite:///example.db\")\n",
            "                assert len(loaded_study.trials) == len(study.trials)\n",
            "        \n",
            "            .. testcleanup::\n",
            "        \n",
            "                os.remove(\"example.db\")\n",
            "        \n",
            "        Args:\n",
            "            study_name:\n",
            "                Study's name. Each study has a unique name as an identifier. If :obj:`None`, checks\n",
            "                whether the storage contains a single study, and if so loads that study.\n",
            "            storage:\n",
            "                Database URL such as ``sqlite:///example.db``. Please see also the documentation of\n",
            "                :func:`~optuna.study.create_study` for further details.\n",
            "            sampler:\n",
            "                A sampler object that implements background algorithm for value suggestion.\n",
            "                If :obj:`None` is specified, :class:`~optuna.samplers.TPESampler` is used\n",
            "                as the default. See also :class:`~optuna.samplers`.\n",
            "            pruner:\n",
            "                A pruner object that decides early stopping of unpromising trials.\n",
            "                If :obj:`None` is specified, :class:`~optuna.pruners.MedianPruner` is used\n",
            "                as the default. See also :class:`~optuna.pruners`.\n",
            "        \n",
            "        Raises:\n",
            "            :exc:`ValueError`:\n",
            "                If ``study_name`` is :obj:`None` and the storage contains more than 1 study.\n",
            "        \n",
            "        See also:\n",
            "            :func:`optuna.load_study` is an alias of :func:`optuna.study.load_study`.\n",
            "\n",
            "DATA\n",
            "    TYPE_CHECKING = False\n",
            "    __all__ = ['Study', 'TYPE_CHECKING', 'Trial', 'TrialPruned', '__versio...\n",
            "\n",
            "VERSION\n",
            "    2.10.0\n",
            "\n",
            "FILE\n",
            "    /usr/local/lib/python3.7/dist-packages/optuna/__init__.py\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ]
}