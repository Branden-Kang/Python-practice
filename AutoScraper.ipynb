{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AutoScraper.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO6t4Nrv/57gVeMHBhxXBYH"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wMfzMZFPi41",
        "colab_type": "text"
      },
      "source": [
        "[Reference](https://medium.com/better-programming/introducing-autoscraper-a-smart-fast-and-lightweight-web-scraper-for-python-20987f52c749)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0HFWpVChO1SS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "outputId": "4a1baf80-513c-4af0-d923-f45ea04a4f52"
      },
      "source": [
        "!pip install git+https://github.com/alirezamika/autoscraper.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/alirezamika/autoscraper.git\n",
            "  Cloning https://github.com/alirezamika/autoscraper.git to /tmp/pip-req-build-9jadighs\n",
            "  Running command git clone -q https://github.com/alirezamika/autoscraper.git /tmp/pip-req-build-9jadighs\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from autoscraper==1.1.1) (2.23.0)\n",
            "Requirement already satisfied: bs4 in /usr/local/lib/python3.6/dist-packages (from autoscraper==1.1.1) (0.0.1)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.6/dist-packages (from autoscraper==1.1.1) (4.2.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->autoscraper==1.1.1) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->autoscraper==1.1.1) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->autoscraper==1.1.1) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->autoscraper==1.1.1) (1.24.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (from bs4->autoscraper==1.1.1) (4.6.3)\n",
            "Building wheels for collected packages: autoscraper\n",
            "  Building wheel for autoscraper (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for autoscraper: filename=autoscraper-1.1.1-cp36-none-any.whl size=7969 sha256=606adb5cb581a4b90435849f0a075ea345ddd9da50187161e253f4dff06f04cc\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-uqzygdaq/wheels/c5/5f/a4/7f181e331bcece27dcb9f1c88b250235d2021a895a27804614\n",
            "Successfully built autoscraper\n",
            "Installing collected packages: autoscraper\n",
            "Successfully installed autoscraper-1.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGwKz-qEO2cB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "3cfa5d84-8c85-4a69-8566-54ca3ca1bb97"
      },
      "source": [
        "from autoscraper import AutoScraper\n",
        "url = 'https://stackoverflow.com/questions/2081586/web-scraping-with-python'\n",
        "# We can add one or multiple candidates here.\n",
        "# You can also put urls here to retrieve urls.\n",
        "wanted_list = [\"How to call an external command?\"]\n",
        "scraper = AutoScraper()\n",
        "result = scraper.build(url, wanted_list)\n",
        "print(result)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['How do I merge two dictionaries in a single expression in Python (taking union of dictionaries)?', 'How to call an external command?', 'What are metaclasses in Python?', 'Does Python have a ternary conditional operator?', 'How do you remove duplicates from a list whilst preserving order?', 'Convert bytes to a string', 'How to get line count of a large file cheaply in Python?', \"Does Python have a string 'contains' substring method?\", 'Why is “1000000000000000 in range(1000000000000001)” so fast in Python 3?']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3nJ6yBgO82g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "99386250-98fc-4f67-c9ca-46a0f0cc5024"
      },
      "source": [
        "scraper.get_result_similar('https://stackoverflow.com/questions/606191/convert-bytes-to-a-string')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['What is the difference between String and string in C#?',\n",
              " 'How do I read / convert an InputStream into a String in Java?',\n",
              " \"Case insensitive 'Contains(string)'\",\n",
              " 'Converting string into datetime',\n",
              " 'How do I make the first letter of a string uppercase in JavaScript?',\n",
              " 'How to replace all occurrences of a string?',\n",
              " 'How to check whether a string contains a substring in JavaScript?',\n",
              " \"Does Python have a string 'contains' substring method?\",\n",
              " 'How do I convert a String to an int in Java?',\n",
              " 'Why is char[] preferred over String for passwords?']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MiqRIKdNPGat",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "62f523f3-6424-4ed0-c894-30d6276ffb34"
      },
      "source": [
        "from autoscraper import AutoScraper\n",
        "\n",
        "url = 'https://finance.yahoo.com/quote/AAPL/'\n",
        "\n",
        "wanted_list = [\"124.81\"]\n",
        "\n",
        "scraper = AutoScraper()\n",
        "\n",
        "# Here we can also pass html content via the html parameter instead of the url (html=html_content)\n",
        "result = scraper.build(url, wanted_list)\n",
        "print(result)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7O3AjYOBPM6A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# proxies = {\n",
        "#     \"http\": 'http://127.0.0.1:8001',\n",
        "#     \"https\": 'https://127.0.0.1:8001',\n",
        "# }\n",
        "\n",
        "# result = scraper.build(url, wanted_list, request_args=dict(proxies=proxies))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFtsNqa4PPZ3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2521b99b-e77f-4bb2-96a0-aeec807410a1"
      },
      "source": [
        "scraper.get_result_exact('https://finance.yahoo.com/quote/MSFT/')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V71Qqmi7PSi-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "url = 'https://github.com/alirezamika/autoscraper'\n",
        "\n",
        "wanted_list = ['A Smart, Automatic, Fast and Lightweight Web Scraper for Python', '662', 'https://github.com/alirezamika/autoscraper/issues']\n",
        "\n",
        "scraper.build(url, wanted_list)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGAAqPa5PY-q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Give it a file path\n",
        "scraper.save('yahoo-finance')"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44LmBXjqPdL8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scraper.load('yahoo-finance')"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mU0oVpqPeFi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "a89cd0bf-da94-442a-d882-62fd63b907d1"
      },
      "source": [
        "code = scraper.generate_python_code()\n",
        "print(code)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This function is deprecated. Please use save() and load() instead.\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}