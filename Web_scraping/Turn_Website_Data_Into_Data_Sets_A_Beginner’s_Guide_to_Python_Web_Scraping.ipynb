{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Turn Website Data Into Data Sets: A Beginner’s Guide to Python Web Scraping.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPZhdjv7QvBZ5mhjOgNqdKD"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CcItMj3ThiSX"
      },
      "source": [
        "[Reference](https://betterprogramming.pub/turn-website-data-into-datasets-a-beginners-guide-to-python-web-scraping-ac1ce99d73a1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ZLYa2JdhhG3",
        "outputId": "935f577b-fb29-4553-e28d-0b95e341988d"
      },
      "source": [
        "pip install beautifulsoup4"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (4.6.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fgZQXIh-iOze",
        "outputId": "35b26b45-1029-4894-dc92-c7014efff989"
      },
      "source": [
        "pip install requests"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (2.23.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests) (2.10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7qnj6b5iQFL"
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qm0aet2xiUkB"
      },
      "source": [
        "import re\n",
        "from re import sub\n",
        "from decimal import Decimal\n",
        "import io\n",
        "from datetime import datetime\n",
        "import pandas as pd"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3NB3xCkPiwnr"
      },
      "source": [
        "# 1. Logic to get one data point"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "po83CiCYiWCz"
      },
      "source": [
        "# search area of interest\n",
        "url = 'https://www.website.com/london/page_size=25&q=london&pn=1'\n",
        "\n",
        "# make request with url provided and get html text\n",
        "html_text = requests.get(url).text\n",
        "\n",
        "# employ lxml as a parser to extract html code\n",
        "soup = BeautifulSoup(html_text, 'lxml')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "71WryAGYizxs",
        "outputId": "83f2a783-5244-4d53-b3aa-866cfa1b0a72"
      },
      "source": [
        "soup"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<!DOCTYPE html>\n",
              "<!--[if lt IE 7]> <html class=\"no-js ie6 oldie\" lang=\"en-US\"> <![endif]--><!--[if IE 7]>    <html class=\"no-js ie7 oldie\" lang=\"en-US\"> <![endif]--><!--[if IE 8]>    <html class=\"no-js ie8 oldie\" lang=\"en-US\"> <![endif]--><!--[if gt IE 8]><!--><html class=\"no-js\" lang=\"en-US\"> <!--<![endif]-->\n",
              "<head>\n",
              "<title>Please Wait... | Cloudflare</title>\n",
              "<meta charset=\"utf-8\"/>\n",
              "<meta content=\"text/html; charset=utf-8\" http-equiv=\"Content-Type\"/>\n",
              "<meta content=\"IE=Edge,chrome=1\" http-equiv=\"X-UA-Compatible\"/>\n",
              "<meta content=\"noindex, nofollow\" name=\"robots\"/>\n",
              "<meta content=\"width=device-width,initial-scale=1\" name=\"viewport\"/>\n",
              "<link href=\"/cdn-cgi/styles/cf.errors.css\" id=\"cf_styles-css\" media=\"screen,projection\" rel=\"stylesheet\" type=\"text/css\"/>\n",
              "<!--[if lt IE 9]><link rel=\"stylesheet\" id='cf_styles-ie-css' href=\"/cdn-cgi/styles/cf.errors.ie.css\" type=\"text/css\" media=\"screen,projection\" /><![endif]-->\n",
              "<style type=\"text/css\">body{margin:0;padding:0}</style>\n",
              "<!--[if gte IE 10]><!-->\n",
              "<script>\n",
              "  if (!navigator.cookieEnabled) {\n",
              "    window.addEventListener('DOMContentLoaded', function () {\n",
              "      var cookieEl = document.getElementById('cookie-alert');\n",
              "      cookieEl.style.display = 'block';\n",
              "    })\n",
              "  }\n",
              "</script>\n",
              "<!--<![endif]-->\n",
              "<script type=\"text/javascript\">\n",
              "    //<![CDATA[\n",
              "    (function(){\n",
              "      window._cf_chl_opt={\n",
              "        cvId: \"2\",\n",
              "        cType: \"managed\",\n",
              "        cNounce: \"81753\",\n",
              "        cRay: \"6713a336182e5daf\",\n",
              "        cHash: \"80a1cc28cb7c183\",\n",
              "        cFPWv: \"g\",\n",
              "        cTTimeMs: \"4000\",\n",
              "        cLt: \"n\",\n",
              "        cRq: {\n",
              "          ru: \"aHR0cHM6Ly93d3cud2Vic2l0ZS5jb20vbG9uZG9uL3BhZ2Vfc2l6ZT0yNSZxPWxvbmRvbiZwbj0x\",\n",
              "          ra: \"cHl0aG9uLXJlcXVlc3RzLzIuMjMuMA==\",\n",
              "          rm: \"R0VU\",\n",
              "          d: \"RCiSomiiuA4xbmFsyAJKntz4GAn/x7+mOtDy7pT5gM5lAD0aJCLAMjfbFJo/8FDbTYou60tx4ZvJyXKyelI5wTLbIgZ/N1v4XR6zXO401T+95WE4CvP9jzo/xTtx+gRBgwD2F/m8jWkHe6SSL6W/Vfs9Q1cj0kfw8kOINWpgFPAJWYT8H1HhxvermL7wD0f3q3XVJtebDRw/eOkyoR5rqsS1/+Z5EKCB80ALXp+5PoXko7PfuVSff2pqK7IYGeJNV7SdsxKEfHhE76xbm//1je/yicNAN+enHcPzRzQWkIed5cVyJWrI0OEnmVjiNQkh1wAx1cEEElYvyQImv2bj5bBGy6R+m8e/3WmTOzNZt2Q4UAosr7HJ9Dnk26WvoaZG1ZOHdywWCAhUG6BcSUUttOBHn/JkrLvuyInqqxiRULUmCzFFJWXW1g9rrj7m6Qblr+hJHtw0xhsGp240Qmb6nO8WHRTDdPs7GBAZgglmiR3oVok1k9RJLafoMdcQEJqZqCBcmL9R/7jtbgxSEzGQjqcXjkpcl+FN5iecrmalXtjDHFFg/FBV9zonPxTVTWs0x5GN0iiTTL6K9gg8ASkbPpQ/wtQOtl+1ON40EVGb47Xd+HMLiJOruG39IPXKVnl7/0/fIbPav/PfVSs7yMTu9tuNnuC2d+1a6ErQwDezxhDHqmV+fIMARHXHrP1+lseYU6HN7cHCswNaAk8tNfmF4t1X29HMKp5+jAKKY8MdGZnXZjhvjJ06oaBBD7Q7AXdLANnoRCnYdugWu7gAERLexXImH9btWofC+o0c+dQb6FH54kqKVb0T1N/9U/zw/JqPIFj5/qhooOoK6VLs7PsnQ3bz4qmKm5qUWykibAbtEtu+ZTq0SQugIp4dzrqI5ge79wFitsc3qliBoMK6Wnq7NDLAqjgbVwEvxSFvkq1D8QYnPtq0s8lpSYqywE4YzIyN\",\n",
              "          t: \"MTYyNjY5NDQzNC4zMDMwMDA=\",\n",
              "          m: \"EwK5rvvWwJu2gUTdG39Ruw9HVUlZTFZMC6AW4ewO8Yg=\",\n",
              "          i1: \"oOJ+FBA0kfRXm5t2TetZww==\",\n",
              "          i2: \"cUxL8iLzrzOv1r7F63GYxw==\",\n",
              "          zh: \"ToMS3HV0OtNita7AnV3aODrva5zgra0L0wNakz8GGyA=\",\n",
              "          uh: \"7miS0Xxj9JuMfUL1dJ1m1OOYUPnyhcctTsOqdlLYMgc=\",\n",
              "          hh: \"jjKlqAMxBb2CvRxePZXE2G+3zvYLMKPJ3n6zB5D4w/g=\",\n",
              "        }\n",
              "      };\n",
              "    }());\n",
              "    //]]>\n",
              "    </script>\n",
              "<style type=\"text/css\">\n",
              "  #cf-wrapper #spinner {width:69px; margin:  auto;}\n",
              "  #cf-wrapper #cf-please-wait{text-align:center}\n",
              "  .attribution {margin-top: 32px;}\n",
              "  .bubbles { background-color: #f58220; width:20px; height: 20px; margin:2px; border-radius:100%; display:inline-block; }\n",
              "  #cf-wrapper #challenge-form { padding-top:25px; padding-bottom:25px; }\n",
              "  #cf-hcaptcha-container { text-align:center;}\n",
              "  #cf-hcaptcha-container iframe { display: inline-block;}\n",
              "  @keyframes fader     { 0% {opacity: 0.2;} 50% {opacity: 1.0;} 100% {opacity: 0.2;} }\n",
              "  #cf-wrapper #cf-bubbles { width:69px; }\n",
              "  @-webkit-keyframes fader { 0% {opacity: 0.2;} 50% {opacity: 1.0;} 100% {opacity: 0.2;} }\n",
              "  #cf-bubbles > .bubbles { animation: fader 1.6s infinite;}\n",
              "  #cf-bubbles > .bubbles:nth-child(2) { animation-delay: .2s;}\n",
              "  #cf-bubbles > .bubbles:nth-child(3) { animation-delay: .4s;}\n",
              "</style>\n",
              "</head>\n",
              "<body>\n",
              "<div id=\"cf-wrapper\">\n",
              "<div class=\"cf-alert cf-alert-error cf-cookie-error\" data-translate=\"enable_cookies\" id=\"cookie-alert\">Please enable cookies.</div>\n",
              "<div class=\"cf-error-details-wrapper\" id=\"cf-error-details\">\n",
              "<div class=\"cf-wrapper cf-header cf-error-overview\">\n",
              "<h1 data-translate=\"managed_challenge_headline\">Please wait...</h1>\n",
              "<h2 class=\"cf-subheadline\"><span data-translate=\"managed_checking_msg\">We are checking your browser...</span> www.website.com</h2>\n",
              "</div>\n",
              "<div class=\"cf-section cf-highlight cf-captcha-container\">\n",
              "<div class=\"cf-wrapper\">\n",
              "<div class=\"cf-columns two\">\n",
              "<div class=\"cf-column\">\n",
              "<div class=\"cf-highlight-inverse cf-form-stacked\">\n",
              "<form action=\"/london/page_size=25&amp;q=london&amp;pn=1?__cf_chl_managed_tk__=362b641d1dc82ce9b88da6dec3d6fd87c57d261d-1626694434-0-AR5f-lINPrMA3V73GywaaL-8p16XQkrBZSZhEQ5bQgWbWTpRU0hZ31dUUA3gzCuIYUp_0qT2kJFQX1bo8MvwkcpREGM3x2ukoeZr8IKOSQeYrzxGZ94yjFB7UymEVRyllLfCq4ywP6t7Puc_wAHt__eOzJ1GIF06TdqLHhRWpfAsRju3f67KekB8wsQsEUhuHgKP17TamsSS8VQfC2VihwO2Mb0uUWm4aqT21Q0W8yy1DFtEpJyb-V2odBwT6x7rGaPYwXorYvCjecaPu8r08FS5_iXUQHwZBtuIxTPwApAJiYtjzc6kqdRMK81MI2jUi2nBO3qzyPYTidv4UEZ-pVXNnbURU2vzaqSIiU6phDwntZWN_Gx7WRVbyI0_mfgSv2q39okNfC0qwLEV8U_7Em-ZAYDJwrq51nQO6-SMEMy0NPKqUgcKY7wzoTNzWz9rRelMqLij5h_8glPN7GkWZs9PrW_koetIDJSuGDUE33G8n5cgtYG6qQtzfEaLcNl9B5wRXsWIXItjfFyzZE2BKA0nIvS0JuTX3T7P-ZT2qGiJyYvVEwLS0hCPFE1vgeGyvXVj9dwwMg27vMyswbjfrg3dKPubl7u5sCwyV3hdTExsx91VI2Xpr3vHbR1bqItdbtRB26fNlrjq4_MzGgM955nLw0Mvgrh1UK3KywHBuDu0WGKF1-UfIi3BZghcHNOxJXBsc5r3x5VW4yrOBNAJltw\" class=\"challenge-form managed-form\" enctype=\"application/x-www-form-urlencoded\" id=\"challenge-form\" method=\"POST\">\n",
              "<div id=\"cf-please-wait\">\n",
              "<div id=\"spinner\">\n",
              "<div id=\"cf-bubbles\">\n",
              "<div class=\"bubbles\"></div>\n",
              "<div class=\"bubbles\"></div>\n",
              "<div class=\"bubbles\"></div>\n",
              "</div>\n",
              "</div>\n",
              "<p data-translate=\"please_wait\" id=\"cf-spinner-please-wait\">Please stand by, while we are checking your browser...</p>\n",
              "<p data-translate=\"redirecting\" id=\"cf-spinner-redirecting\" style=\"display:none\">Redirecting...</p>\n",
              "</div>\n",
              "<input name=\"r\" type=\"hidden\" value=\"f26fafc9a5c4dfedd6d3662d76568d724e7b524c-1626694434-0-AZOGp+YSrhgPTmtxsDVYJguBxymwTrm/O16oAcwUt7v3df5uJ/EVh5iaG7BK0ePDY/kAFF1dvSZM9RN1lWQZBbO0LHM5Y3SiCO8byCynItkJ59e7HLtmOe4H7peWniQpglMJpmu1APejIGgUB8UkJpoYcRvva89sQv5qWeD5wjyHZuk0QwIPNBL2b5n5rY8UhfX2p9+OS9nCELioHwM5DTsPRfIv7GF4qhFw+m/mabqtRYrkQXYgRjcs14Jaz0lPKZye31ua4UANSVRXdZOe06dnJozXOn7uOIyG/PNaSejp0SSeHQAYFyrsJGLCmBNU8nPH9nJ7NdMILEUjIl5gGqDfJWpXZOAyVB23lCJNTr9jKhy/9YzXtHVovq2JKTDAi2mhH3V/H1aaTQg0SrWTi926puMuhRCpf9WscvJCGHbeaWujKCIt/kibzw0qqbKMzLuDN4llMeObQErls7NECXqnJxmS4rW0t9uwsDjvGGw+SOtorihGoOO1knvAbMZAtMLxPOMVIB2/5+wSaP+S8xV1/K3SxjOMSQGZFDb2afr3blJ7kqLbz86945a/VaXcg77oeiyAXToEX+mDbvQHnuAvt+/p9EA7rjJvQaVFIg09v8rCsJsQR28PutpfU6e2uQbVbTYRqo1LAfh90nd7fxmi1u22OpM5QkWAA8H32uA96QRxwXVZ/8tnHoz4BtAX61NRNuLBlUbJBGm+XSjrES35pxzJq30yWqlJTr4J3Bgdkq5P/7BtAcEV/vIAbPo1i/fnVANMpXfmJranKvR6R9yekkwVmQ0JiaVqpihEeQyRZuYfdaUc0b1HEKj32fZFInrB+DkUWG6QWbin0sTRxvqWim/DPSc6X0UVGGy8nmqzru2cBmBVciIgfoeAcKWjv3XKEzWoMOf1Dydq7jdHAPxxCF+R529iwaHNGf6YTGfoWsXLOGtYNuudxzlTtxttDs6/u9igw53oyCgeXyP4Wv2iBFQAnm1L2q7g1eIxaGj1QglXJ5DAOQQ7PwWHwfaasYg1M8ECH9uZOWXkwKc1kLFdM9Xl8Dz2hzaqisCNU/0eBDmai4dcCmPdmM/emaUChZ0P9RFy+Fx9q+poST00msIRkhoBNXOdudguJpBY/RcDrT+HhD86Spw9eTkwMZUvTydwMygAOCpenIcj8vqX7QKH5gxA2uV/5fxBf0b0mH0926nkmpSdqsbIeRt5n4OA4776LT0dAqto4xoUjlIJJzw/bgRiVf3dw0eJ1fAlku8myWUPCI7D4olO9ZZttBGg3FBadgzMcOMOa9c0vyHZ8KUzlwWf97BvrrdB0JTQzTlGGrxi10JhBagws5dtU/HYRyC//sHLtiBjUzsjdgvg6+1lN/hPgKQdurPybPfGhZWP8hp/xKDJIiqv2QgRyGYZgE+GOtWP049bCtykxaqoSsF8vklekIFJMODbuBEANZTx0sj9Izz0sxI8I4Mi8Qs1wo6WwOoRlOAblQh0BH82rQkwfhAxgBGBiKbMv7EDZNOLBhMhNU0CvZv1paeqk0dueUujaNB3qahwf6J3DW97P14w9ffBwrXJFnhV7hAhQqk7SFpyPY3jvFmxJDTWXAeNfZoBSdrvVrnFjHawcsyoZfjax4vdTckrPAO3QL8VogWBEzx3MUJzjcJjvQ36+0ApcnLCCy6p+EqO1WmKdc2hGoCK2US+/8S7RazjYqzhPUEzwExaLXeC4gRTu5v2WtmnoSg5Jk0EssgsDYPMFI09EipmWkrD9EYOd4BL9ZK+XkCAke9hda7nSosiLLWCJZHulZg2f05bsD8H8vdEO79TWOU=\"/>\n",
              "<input name=\"cf_captcha_kind\" type=\"hidden\" value=\"h\"/>\n",
              "<input name=\"vc\" type=\"hidden\" value=\"b7ee18b720096eeb3d2a6df4423ba97a\"/>\n",
              "<noscript class=\"cf-captcha-info\" id=\"cf-captcha-bookmark\">\n",
              "<h1 data-translate=\"turn_on_js\" style=\"color:#bd2426;\">Please turn JavaScript on and reload the page.</h1>\n",
              "</noscript>\n",
              "<div class=\"cookie-warning\" data-translate=\"turn_on_cookies\" id=\"no-cookie-warning\" style=\"display:none\">\n",
              "<p data-translate=\"turn_on_cookies\" style=\"color:#bd2426;\">Please enable Cookies and reload the page.</p>\n",
              "</div>\n",
              "<script type=\"text/javascript\">\n",
              "  //<![CDATA[\n",
              "    var a = function() {try{return !!window.addEventListener} catch(e) {return !1} },\n",
              "      b = function(b, c) {a() ? document.addEventListener(\"DOMContentLoaded\", b, c) : document.attachEvent(\"onreadystatechange\", b)};\n",
              "      b(function(){\n",
              "        var cookiesEnabled=(navigator.cookieEnabled)? true : false;\n",
              "        if(!cookiesEnabled){\n",
              "          var q = document.getElementById('no-cookie-warning');q.style.display = 'block';\n",
              "        }\n",
              "      });\n",
              "  //]]>\n",
              "  </script>\n",
              "<div id=\"trk_captcha_js\" style=\"background-image:url('/cdn-cgi/images/trace/captcha/nojs/h/transparent.gif?ray=6713a336182e5daf')\"></div>\n",
              "</form>\n",
              "<script type=\"text/javascript\">\n",
              "    //<![CDATA[\n",
              "    (function(){\n",
              "        var isIE = /(MSIE|Trident\\/|Edge\\/)/i.test(window.navigator.userAgent);\n",
              "        var trkjs = isIE ? new Image() : document.createElement('img');\n",
              "        trkjs.setAttribute(\"src\", \"/cdn-cgi/images/trace/managed/js/transparent.gif?ray=6713a336182e5daf\");\n",
              "        trkjs.id = \"trk_managed_js\";\n",
              "        trkjs.setAttribute(\"alt\", \"\");\n",
              "        document.body.appendChild(trkjs);\n",
              "        var cpo=document.createElement('script');\n",
              "        cpo.type='text/javascript';\n",
              "        cpo.src=\"/cdn-cgi/challenge-platform/h/g/orchestrate/managed/v1?ray=6713a336182e5daf\";\n",
              "        document.getElementsByTagName('head')[0].appendChild(cpo);\n",
              "    }());\n",
              "    //]]>\n",
              "    </script>\n",
              "</div>\n",
              "</div>\n",
              "<div class=\"cf-column\">\n",
              "<div class=\"cf-screenshot-container\">\n",
              "<span class=\"cf-no-screenshot\"></span>\n",
              "</div>\n",
              "</div>\n",
              "</div>\n",
              "</div>\n",
              "</div>\n",
              "<div class=\"cf-section cf-wrapper\">\n",
              "<div class=\"cf-columns two\">\n",
              "<div class=\"cf-column\">\n",
              "<h2 data-translate=\"why_captcha_headline\">Why do I have to complete a CAPTCHA?</h2>\n",
              "<p data-translate=\"why_captcha_detail\">Completing the CAPTCHA proves you are a human and gives you temporary access to the web property.</p>\n",
              "</div>\n",
              "<div class=\"cf-column\">\n",
              "<h2 data-translate=\"resolve_captcha_headline\">What can I do to prevent this in the future?</h2>\n",
              "<p data-translate=\"resolve_captcha_antivirus\">If you are on a personal connection, like at home, you can run an anti-virus scan on your device to make sure it is not infected with malware.</p>\n",
              "<p data-translate=\"resolve_captcha_network\">If you are at an office or shared network, you can ask the network administrator to run a scan across the network looking for misconfigured or infected devices.</p>\n",
              "</div>\n",
              "</div>\n",
              "</div>\n",
              "<div class=\"cf-error-footer cf-wrapper w-240 lg:w-full py-10 sm:py-4 sm:px-8 mx-auto text-center sm:text-left border-solid border-0 border-t border-gray-300\">\n",
              "<p class=\"text-13\">\n",
              "<span class=\"cf-footer-item sm:block sm:mb-1\">Cloudflare Ray ID: <strong class=\"font-semibold\">6713a336182e5daf</strong></span>\n",
              "<span class=\"cf-footer-separator sm:hidden\">•</span>\n",
              "<span class=\"cf-footer-item sm:block sm:mb-1\"><span>Your IP</span>: 35.245.18.122</span>\n",
              "<span class=\"cf-footer-separator sm:hidden\">•</span>\n",
              "<span class=\"cf-footer-item sm:block sm:mb-1\"><span>Performance &amp; security by</span> <a href=\"https://www.cloudflare.com/5xx-error-landing\" id=\"brand_link\" rel=\"noopener noreferrer\" target=\"_blank\">Cloudflare</a></span>\n",
              "</p>\n",
              "</div><!-- /.error-footer -->\n",
              "</div>\n",
              "</div>\n",
              "<script type=\"text/javascript\">\n",
              "  window._cf_translation = {};\n",
              "  \n",
              "  \n",
              "</script>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGkM4L3JjD6V"
      },
      "source": [
        "# find address in ad\n",
        "address = ad.find('p', class_ = 'css-address-123456').text# show address\n",
        "address"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Y06GAKrjWE7"
      },
      "source": [
        "# 2. Logic to get all data points from one single page"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2zVh0Y6ajUYg"
      },
      "source": [
        "# get all ads within one page\n",
        "ads = ad.find_all('p', class_ = 'css-ad-wrapper-123456')"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xyM3skyojX94"
      },
      "source": [
        "# identify how many ads we have fetched\n",
        "len(ads)# show source code of second ad\n",
        "print(ads[0])"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_2b2u2Yjb9R"
      },
      "source": [
        "# search area of interest\n",
        "url = 'https://www.website.com/london/page_size=25&q=london&pn=1'\n",
        "\n",
        "# make request with url provided and get html text\n",
        "html_text = requests.get(url).text\n",
        "\n",
        "# employ lxml as a parser\n",
        "soup = BeautifulSoup(html_text, 'lxml')\n",
        "# create empty dict\n",
        "map = {}\n",
        "\n",
        "# initialise id value\n",
        "id = 0\n",
        "\n",
        "# get HTML code of all ads within one page\n",
        "ads = ad.find_all('p', class_ = 'css-ad-wrapper-123456')\n",
        "\n",
        "for i in range(len(ads)):\n",
        "\n",
        "    ad = ads[i]\n",
        "    id += 1\n",
        "    map[id] = {}\n",
        "    \n",
        "    # find price information\n",
        "    price = ad.find('p', class_ = 'css-aaabbbccc').text\n",
        "    # find address in ad\n",
        "    address = ad.find('p', class_ = 'css-address-123456').text\n",
        "    \n",
        "    # store value to dict\n",
        "    map[id][\"address\"] = address\n",
        "    # store value to dict\n",
        "    map[id][\"price\"] = price"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wALBVaAIjgm4"
      },
      "source": [
        "# 3. Get data points from all available results pages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHVorWezjest"
      },
      "source": [
        "# base link to scrape ads across London\n",
        "url = 'https://www.website.com/london/page_size=25&q=london&pn='\n",
        "\n",
        "# creaty empty dict\n",
        "map = {}\n",
        "\n",
        "# initialise id value\n",
        "id = 0\n",
        "\n",
        "# define how many pages to scrape for \"London\"\n",
        "max_pages = 15\n",
        "\n",
        "for p in range(max_pages):\n",
        "    \n",
        "    # base url with dynamic page numbers in the end\n",
        "    cur_url = url + str(p + 1)\n",
        "\n",
        "    print(\"Scraping page: %d\" % (p + 1))\n",
        "\n",
        "    html_text = requests.get(cur_url).text\n",
        "    soup = BeautifulSoup(html_text, 'lxml')\n",
        "    \n",
        "    # find all ads within one page\n",
        "    ads = soup.find_all('div', class_ = 'css-ad-wrapper-123456')\n",
        "\n",
        "    for i in range(len(ads)):\n",
        "\n",
        "        ad = ads[i]\n",
        "        id += 1\n",
        "        map[id] = {}\n",
        "\n",
        "        #find price information\n",
        "        price = ad.find('p', class_ = 'css-aaabbbccc').text\n",
        "        # find address in ad\n",
        "        address = ad.find('p', class_ = 'css-address-123456').text\n",
        "        # store value into dict\n",
        "        map[id][\"address\"] = address\n",
        "        # store value into dict\n",
        "        map[id][\"price\"] = price"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MH9m49fuj9oP"
      },
      "source": [
        "# # base link to scrape ads across London\n",
        "# url = 'https://www.website.com/london/page_size=25&q=london&pn='\n",
        "# map = {}\n",
        "# id = 0\n",
        "# # use very large number\n",
        "# max_pages = 9999\n",
        "# for p in range(max_pages):\n",
        "    \n",
        "#     cur_url = url + str(p + 1)\n",
        "#     print(\"Scraping page: %d\" % (p + 1))\n",
        "#     html_text = requests.get(cur_url).text\n",
        "#     soup = BeautifulSoup(html_text, 'lxml')\n",
        "#     ads = soup.find_all('div', class_ = 'css-ad-wrapper-123456')\n",
        "    \n",
        "#     # searches for link in next button\n",
        "#     page_nav = soup.find_all('a', class_ = 'css-button-123456')\n",
        "#     # If no link is detectable, the variable will be empty (=0)\n",
        "#     if(len(page_nav) == 0):\n",
        "#         print(\"max page number: %d\" % (p))\n",
        "#         break"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPLRqc2_jkt_"
      },
      "source": [
        "# # libaries\n",
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "# import time\n",
        "# from bs4 import BeautifulSoup\n",
        "# import requests\n",
        "# import re\n",
        "# from re import sub\n",
        "# from decimal import Decimal\n",
        "# import io\n",
        "# from datetime import datetime\n",
        "\n",
        "\n",
        "# # functions to clean data\n",
        "# def to_num(price):\n",
        "#     '''\n",
        "#     1. Input price-formatted values (e.g. £ 10,000,000)\n",
        "#     2. Normalize value to plain numeric value (e.g. 10000000)\n",
        "#     '''\n",
        "#     value = Decimal(sub(r'[^\\d.]', '', price))\n",
        "#     return float(value)\n",
        "\n",
        "# def is_skipped(price):\n",
        "#     '''\n",
        "#     1. Detect price labels that are not actual prices\n",
        "#        (e.g. \"POA\")\n",
        "#     2. Return false if no price value is applicable\n",
        "#     '''\n",
        "#     for i in range(len(price)):\n",
        "#         if(price[i] != '£' and price[i] != ','\n",
        "#            and (not price[i].isdigit())):\n",
        "#               return True\n",
        "#     return False\n",
        "\n",
        "\n",
        "# # base link to scrape ads across London\n",
        "# url = '{{ENTER_WEBSITE_URL_OF_SEARCH_REQUEST_HERE}}'\n",
        "\n",
        "# map = {}\n",
        "# id = 0\n",
        "\n",
        "# # define how many pages to scrape for \"London\"\n",
        "# max_pages = 4\n",
        "\n",
        "# start = time.time()\n",
        "\n",
        "# for p in range(max_pages):\n",
        "    \n",
        "    \n",
        "#     cur_url = url + str(p + 1)\n",
        "\n",
        "#     print(\"Scraping page: %d\" % (p + 1))\n",
        "\n",
        "#     html_text = requests.get(cur_url).text\n",
        "#     soup = BeautifulSoup(html_text, 'lxml')\n",
        "\n",
        "#     ads = soup.find_all('div', class_ = '{{HTML CLASS TO TARGET AD}}')\n",
        "#     #print(len(ads))\n",
        "    \n",
        "#     # comment this logic\n",
        "#     page_nav = soup.find_all('a', class_ = '{{HTML CLASS TO TARGET LINK IN NEXT BUTTON}}')\n",
        "\n",
        "#     if(len(page_nav) == 0):\n",
        "#         print(\"max page number: %d\" % (p))\n",
        "#         end = time.time()\n",
        "#         print(end - start)\n",
        "#         break\n",
        "\n",
        "#     for k in range(len(ads)):\n",
        "        \n",
        "#         ad = ads[k]\n",
        "        \n",
        "#         id += 1\n",
        "#         map[id] = {}\n",
        "\n",
        "#         #find section for address\n",
        "#         address = ad.find('p', class_ = '{{HTML CLASS TO TARGET ADDRESS}}').text\n",
        "\n",
        "#         #find price information\n",
        "#         price = ad.find('p', class_ = 'css-6v9gpl-Text eczcs4p0').text\n",
        "\n",
        "#         # drop if price section does not contain a real price value\n",
        "#         if(is_skipped(price)): continue\n",
        "\n",
        "#         #find public transport information\n",
        "#         transport_section = ad.find('div', class_ = '{{HTML CLASS}}')\n",
        "#         transport_type = ad.find_all('span', class_ = '{{HTML CLASS}}')\n",
        "#         transport_information = transport_section.find_all('p', class_ = '{{HTML CLASS}}')\n",
        "\n",
        "#         #assign address\n",
        "#         map[id][\"address\"] = address     \n",
        "\n",
        "#         #assign price\n",
        "#         map[id][\"price\"] = to_num(price)\n",
        "\n",
        "#         # create dicts for public transport information\n",
        "#         map[id][\"distance\"] = []\n",
        "#         map[id][\"station\"] = []\n",
        "#         map[id][\"transport_type\"] = []\n",
        "\n",
        "#         for i in range(len(transport_information)):\n",
        "#             s = transport_information[i].text\n",
        "#             x = s.split(' miles ')\n",
        "#             map[id][\"distance\"].append(float(x[0]))\n",
        "#             map[id][\"station\"].append(x[1])\n",
        "#             map[id][\"transport_type\"].append(transport_type[i]['testid'])\n",
        "        \n",
        "\n",
        "# print(\"Scraping task finished\")\n",
        "# end = time.time()\n",
        "# print(str(round(end - start, 2)) + 'sec')"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6dJo_4wSkAre"
      },
      "source": [
        "# 4. Tackling information inconsistency"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZnmYIMeakEYs"
      },
      "source": [
        "def is_skipped(price):\n",
        "    '''\n",
        "    1. Detect price labels that are not actual prices\n",
        "       (e.g., \"POA\")\n",
        "    2. Return false if no price value is applicable\n",
        "    '''\n",
        "    for i in range(len(price)):\n",
        "        if(price[i] != '£' and price[i] != ','\n",
        "           and (not price[i].isdigit())):\n",
        "              return True\n",
        "    return False"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jnKb7EpBkGL7"
      },
      "source": [
        "for i in range(len(ads)):\n",
        "\n",
        "        ad = ads[i]\n",
        "        id += 1\n",
        "        map[id] = {}\n",
        "\n",
        "        # find price information\n",
        "        price = ad.find('p', class_ = 'css-aaabbbccc').text\n",
        "        # skip ad if price field does not contain a real price value\n",
        "        if(is_skipped(price)): continue\n",
        "        # store value into dict\n",
        "        map[id][\"price\"] = price"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3cIEQaQkLaM"
      },
      "source": [
        "def to_num(price):\n",
        "    '''\n",
        "    1. Input raw price value (e.g., £ 50,000)\n",
        "    2. Convert to plain numeric value (e.g., 50000)\n",
        "    '''\n",
        "    # drop special characters\n",
        "    value = Decimal(sub(r'[^\\d.]', '', price))\n",
        "    return float(value)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oj8xqfelkNE-"
      },
      "source": [
        "# 5. Extracting nested information"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vRXRYjmkPiE"
      },
      "source": [
        "# create emtpy category dictionaries within dictionary\n",
        "map[id][\"distance\"] = []\n",
        "map[id][\"station\"] = []\n",
        "# find all public transport information in one ad\n",
        "transport = ad.find_all('div', class_ = 'css-transport-123')\n",
        "for i in range(len(transport)):\n",
        "       s = transport[i].text\n",
        "       x = s.split(' miles ')\n",
        "       map[id][\"distance\"].append(float(x[0]))\n",
        "       map[id][\"station\"].append(x[1])"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5Hq0bvIkSXN"
      },
      "source": [
        "# create emtpy category dictionaries within dictionary\n",
        "map[id][\"distance\"] = []\n",
        "map[id][\"station\"] = []\n",
        "map[id][\"transport_type\"] = []\n",
        "# find all public transport information in one ad\n",
        "transport = ad.find_all('div', class_ = 'css-transport-123')\n",
        "type = ad.find_all('span', class_ = 'css-StyledIcon')\n",
        "for i in range(len(transport)):\n",
        "       s = transport[i].text\n",
        "       x = s.split(' miles ')\n",
        "       map[id][\"distance\"].append(float(x[0]))\n",
        "       map[id][\"station\"].append(x[1])\n",
        "       # add 'testid' to only retrieve the transport type\n",
        "       map[id][\"transport_type\"].append(type[i]['testid'])"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ythAdnLkUv7"
      },
      "source": [
        "# 6. Transform to data frame and export as CSV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1Yy7eXekWJ3"
      },
      "source": [
        "# show data of first ad\n",
        "map[0]"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HeiSiCf5kX9j"
      },
      "source": [
        "# create temporary list\n",
        "result = []\n",
        "cur_row = 0\n",
        "for idx in range(len(map[1][\"distance\"])):\n",
        "    result.append([])\n",
        "    \n",
        "    result[cur_row].append(str(map[1][\"uuid\"]))\n",
        "    result[cur_row].append(str(map[1][\"price\"]))\n",
        "    result[cur_row].append(str(map[1][\"address\"]))\n",
        "    result[cur_row].append(str(map[1][\"distance\"][idx]))\n",
        "    result[cur_row].append(str(map[1][\"station\"][idx]))\n",
        "    result[cur_row].append(str(map[1][\"transport_type\"][idx]))\n",
        "                           \n",
        "    cur_row += 1"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJKxUMH1jrQP"
      },
      "source": [
        "# Transform dictionary into list of lists\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMvw9EWWjlBY"
      },
      "source": [
        "# transform to dict to list\n",
        "result = []\n",
        "cur_row = 0\n",
        "\n",
        "for id in map.keys():\n",
        "    cur_price = map[cur_id][\"price\"]\n",
        "    cur_address = map[cur_id][\"address\"]\n",
        "    for idx in range(len(map[id][\"distance\"])):\n",
        "        result.append([])\n",
        "        result[cur_row].append(int(cur_id))\n",
        "        result[cur_row].append(float(cur_price))\n",
        "        result[cur_row].append(str(cur_address))\n",
        "        result[cur_row].append(float(map[id][\"distance\"][idx]))\n",
        "        result[cur_row].append(str(map[id][\"station\"][idx]))\n",
        "        result[cur_row].append(str(map[id][\"transport_type\"][idx]))\n",
        "\n",
        "        cur_row += 1"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EI6XFqNsjtfh"
      },
      "source": [
        "# Transform to DF\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hf5xLLL1jpKm"
      },
      "source": [
        "df = pd.DataFrame(result, columns = [\"ad_id\", \"price\",\"address\", \"distance\",\n",
        "                                     \"station\", \"transport_type\"])"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oRQcKZQojyOu"
      },
      "source": [
        "# Export as CSV\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXZRDLZkjxES"
      },
      "source": [
        "filename = 'test.csv'\n",
        "df.to_csv(filename)"
      ],
      "execution_count": 20,
      "outputs": []
    }
  ]
}