{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPSF0L6iEVC5YaVyexnlGX9"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[Reference](https://medium.com/@francescofranco_39234/dropout-regularization-with-keras-7b89651da252)"
      ],
      "metadata": {
        "id": "BrPfPfoBEZYe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "pVpXQ46-D23Z"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import backend as K\n",
        "from keras.constraints import max_norm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model configuration\n",
        "img_width, img_height         = 32, 32\n",
        "batch_size                    = 250\n",
        "no_epochs                     = 55\n",
        "no_classes                    = 10\n",
        "validation_split              = 0.2\n",
        "verbosity                     = 1\n",
        "max_norm_value                = 2.0"
      ],
      "metadata": {
        "id": "5CIXpyShEfQZ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load CIFAR10 dataset\n",
        "(input_train, target_train), (input_test, target_test) = cifar10.load_data()\n",
        "\n",
        "# Reshape data based on channels first / channels last strategy.\n",
        "# This is dependent on whether you use TF, Theano or CNTK as backend.\n",
        "# Source: https://github.com/keras-team/keras/blob/master/examples/mnist_cnn.py\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    input_train = input_train.reshape(input_train.shape[0],3, img_width, img_height)\n",
        "    input_test = input_test.reshape(input_test.shape[0], 3, img_width, img_height)\n",
        "    input_shape = (3, img_width, img_height)\n",
        "else:\n",
        "    input_train = input_train.reshape(input_train.shape[0], img_width, img_height, 3)\n",
        "    input_test = input_test.reshape(input_test.shape[0], img_width, img_height, 3)\n",
        "    input_shape = (img_width  , img_height, 3)\n",
        "\n",
        "# Parse numbers as floats\n",
        "input_train = input_train.astype('float32')\n",
        "input_test = input_test.astype('float32')\n",
        "\n",
        "# Normalize data\n",
        "input_train = input_train / 255\n",
        "input_test = input_test / 255\n",
        "\n",
        "# Convert target vectors to categorical targets\n",
        "target_train = keras.utils.to_categorical(target_train, no_classes)\n",
        "target_test = keras.utils.to_categorical(target_test, no_classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PpZl-MoSEgyS",
        "outputId": "994c8a4f-a2bd-4afa-a191-66c554950187"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 2s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the model\n",
        "model = Sequential()\n",
        "model.add(Conv2D(64, kernel_size=(3, 3), kernel_constraint=max_norm(max_norm_value), activation='relu', input_shape=input_shape, kernel_initializer='he_uniform'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.50))\n",
        "model.add(Conv2D(64, kernel_size=(3, 3), kernel_constraint=max_norm(max_norm_value), activation='relu', kernel_initializer='he_uniform'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.50))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation='relu', kernel_constraint=max_norm(max_norm_value), kernel_initializer='he_uniform'))\n",
        "model.add(Dense(no_classes, activation='softmax'))"
      ],
      "metadata": {
        "id": "NlMFmEo1EiXW"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.Adam(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Fit data to model\n",
        "model.fit(input_train, target_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=no_epochs,\n",
        "          verbose=verbosity,\n",
        "          validation_split=validation_split\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lKe3ZGLqEmbL",
        "outputId": "3e0e9253-11e0-4502-85ad-219ec88c4869"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/55\n",
            "160/160 [==============================] - 111s 677ms/step - loss: 2.0040 - accuracy: 0.2781 - val_loss: 1.7496 - val_accuracy: 0.3842\n",
            "Epoch 2/55\n",
            "160/160 [==============================] - 113s 707ms/step - loss: 1.5281 - accuracy: 0.4423 - val_loss: 1.4295 - val_accuracy: 0.5101\n",
            "Epoch 3/55\n",
            "160/160 [==============================] - 107s 669ms/step - loss: 1.3652 - accuracy: 0.5091 - val_loss: 1.2772 - val_accuracy: 0.5637\n",
            "Epoch 4/55\n",
            "160/160 [==============================] - 109s 681ms/step - loss: 1.2530 - accuracy: 0.5553 - val_loss: 1.1611 - val_accuracy: 0.6126\n",
            "Epoch 5/55\n",
            "160/160 [==============================] - 109s 679ms/step - loss: 1.1721 - accuracy: 0.5839 - val_loss: 1.0878 - val_accuracy: 0.6329\n",
            "Epoch 6/55\n",
            "160/160 [==============================] - 105s 655ms/step - loss: 1.1097 - accuracy: 0.6071 - val_loss: 1.0326 - val_accuracy: 0.6487\n",
            "Epoch 7/55\n",
            "160/160 [==============================] - 108s 674ms/step - loss: 1.0583 - accuracy: 0.6240 - val_loss: 0.9812 - val_accuracy: 0.6644\n",
            "Epoch 8/55\n",
            "160/160 [==============================] - 104s 652ms/step - loss: 1.0031 - accuracy: 0.6485 - val_loss: 0.9418 - val_accuracy: 0.6821\n",
            "Epoch 9/55\n",
            "160/160 [==============================] - 104s 649ms/step - loss: 0.9658 - accuracy: 0.6599 - val_loss: 0.9010 - val_accuracy: 0.6927\n",
            "Epoch 10/55\n",
            "160/160 [==============================] - 107s 669ms/step - loss: 0.9228 - accuracy: 0.6755 - val_loss: 0.8765 - val_accuracy: 0.7035\n",
            "Epoch 11/55\n",
            "160/160 [==============================] - 106s 663ms/step - loss: 0.8911 - accuracy: 0.6873 - val_loss: 0.8645 - val_accuracy: 0.7101\n",
            "Epoch 12/55\n",
            "160/160 [==============================] - 105s 657ms/step - loss: 0.8619 - accuracy: 0.6976 - val_loss: 0.8290 - val_accuracy: 0.7220\n",
            "Epoch 13/55\n",
            "160/160 [==============================] - 103s 644ms/step - loss: 0.8392 - accuracy: 0.7060 - val_loss: 0.8232 - val_accuracy: 0.7215\n",
            "Epoch 14/55\n",
            "160/160 [==============================] - 106s 663ms/step - loss: 0.8107 - accuracy: 0.7161 - val_loss: 0.8101 - val_accuracy: 0.7225\n",
            "Epoch 15/55\n",
            "160/160 [==============================] - 107s 670ms/step - loss: 0.7885 - accuracy: 0.7227 - val_loss: 0.7891 - val_accuracy: 0.7306\n",
            "Epoch 16/55\n",
            "160/160 [==============================] - 107s 671ms/step - loss: 0.7657 - accuracy: 0.7319 - val_loss: 0.8136 - val_accuracy: 0.7151\n",
            "Epoch 17/55\n",
            "160/160 [==============================] - 103s 646ms/step - loss: 0.7401 - accuracy: 0.7410 - val_loss: 0.7677 - val_accuracy: 0.7394\n",
            "Epoch 18/55\n",
            "160/160 [==============================] - 106s 661ms/step - loss: 0.7296 - accuracy: 0.7437 - val_loss: 0.7802 - val_accuracy: 0.7345\n",
            "Epoch 19/55\n",
            "160/160 [==============================] - 106s 660ms/step - loss: 0.7032 - accuracy: 0.7497 - val_loss: 0.7606 - val_accuracy: 0.7419\n",
            "Epoch 20/55\n",
            "160/160 [==============================] - 107s 667ms/step - loss: 0.6951 - accuracy: 0.7568 - val_loss: 0.7636 - val_accuracy: 0.7417\n",
            "Epoch 21/55\n",
            "160/160 [==============================] - 107s 667ms/step - loss: 0.6748 - accuracy: 0.7610 - val_loss: 0.7597 - val_accuracy: 0.7389\n",
            "Epoch 22/55\n",
            "160/160 [==============================] - 103s 645ms/step - loss: 0.6581 - accuracy: 0.7677 - val_loss: 0.7418 - val_accuracy: 0.7501\n",
            "Epoch 23/55\n",
            "160/160 [==============================] - 107s 667ms/step - loss: 0.6537 - accuracy: 0.7721 - val_loss: 0.7585 - val_accuracy: 0.7403\n",
            "Epoch 24/55\n",
            "160/160 [==============================] - 107s 671ms/step - loss: 0.6337 - accuracy: 0.7766 - val_loss: 0.7634 - val_accuracy: 0.7416\n",
            "Epoch 25/55\n",
            "160/160 [==============================] - 103s 644ms/step - loss: 0.6235 - accuracy: 0.7814 - val_loss: 0.7462 - val_accuracy: 0.7467\n",
            "Epoch 26/55\n",
            "160/160 [==============================] - 102s 637ms/step - loss: 0.6112 - accuracy: 0.7850 - val_loss: 0.7511 - val_accuracy: 0.7458\n",
            "Epoch 27/55\n",
            "160/160 [==============================] - 107s 672ms/step - loss: 0.6008 - accuracy: 0.7881 - val_loss: 0.7427 - val_accuracy: 0.7461\n",
            "Epoch 28/55\n",
            "160/160 [==============================] - 103s 645ms/step - loss: 0.5875 - accuracy: 0.7958 - val_loss: 0.7495 - val_accuracy: 0.7418\n",
            "Epoch 29/55\n",
            "160/160 [==============================] - 108s 677ms/step - loss: 0.5846 - accuracy: 0.7949 - val_loss: 0.7430 - val_accuracy: 0.7486\n",
            "Epoch 30/55\n",
            "160/160 [==============================] - 103s 643ms/step - loss: 0.5660 - accuracy: 0.8007 - val_loss: 0.7340 - val_accuracy: 0.7523\n",
            "Epoch 31/55\n",
            "160/160 [==============================] - 107s 669ms/step - loss: 0.5642 - accuracy: 0.8003 - val_loss: 0.7447 - val_accuracy: 0.7504\n",
            "Epoch 32/55\n",
            "160/160 [==============================] - 102s 638ms/step - loss: 0.5532 - accuracy: 0.8054 - val_loss: 0.7421 - val_accuracy: 0.7485\n",
            "Epoch 33/55\n",
            "160/160 [==============================] - 103s 643ms/step - loss: 0.5381 - accuracy: 0.8098 - val_loss: 0.7269 - val_accuracy: 0.7552\n",
            "Epoch 34/55\n",
            "160/160 [==============================] - 107s 669ms/step - loss: 0.5340 - accuracy: 0.8102 - val_loss: 0.7333 - val_accuracy: 0.7543\n",
            "Epoch 35/55\n",
            "160/160 [==============================] - 103s 645ms/step - loss: 0.5302 - accuracy: 0.8141 - val_loss: 0.7412 - val_accuracy: 0.7553\n",
            "Epoch 36/55\n",
            "160/160 [==============================] - 107s 671ms/step - loss: 0.5195 - accuracy: 0.8179 - val_loss: 0.7243 - val_accuracy: 0.7576\n",
            "Epoch 37/55\n",
            "160/160 [==============================] - 106s 665ms/step - loss: 0.5042 - accuracy: 0.8202 - val_loss: 0.7354 - val_accuracy: 0.7530\n",
            "Epoch 38/55\n",
            "160/160 [==============================] - 106s 665ms/step - loss: 0.4970 - accuracy: 0.8251 - val_loss: 0.7337 - val_accuracy: 0.7579\n",
            "Epoch 39/55\n",
            "160/160 [==============================] - 102s 638ms/step - loss: 0.4980 - accuracy: 0.8240 - val_loss: 0.7376 - val_accuracy: 0.7528\n",
            "Epoch 40/55\n",
            "160/160 [==============================] - 103s 643ms/step - loss: 0.4978 - accuracy: 0.8241 - val_loss: 0.7397 - val_accuracy: 0.7530\n",
            "Epoch 41/55\n",
            "160/160 [==============================] - 103s 644ms/step - loss: 0.4905 - accuracy: 0.8250 - val_loss: 0.7492 - val_accuracy: 0.7511\n",
            "Epoch 42/55\n",
            "160/160 [==============================] - 107s 667ms/step - loss: 0.4847 - accuracy: 0.8289 - val_loss: 0.7405 - val_accuracy: 0.7505\n",
            "Epoch 43/55\n",
            "160/160 [==============================] - 108s 673ms/step - loss: 0.4795 - accuracy: 0.8312 - val_loss: 0.7704 - val_accuracy: 0.7420\n",
            "Epoch 44/55\n",
            "160/160 [==============================] - 107s 665ms/step - loss: 0.4716 - accuracy: 0.8344 - val_loss: 0.7382 - val_accuracy: 0.7537\n",
            "Epoch 45/55\n",
            "160/160 [==============================] - 105s 660ms/step - loss: 0.4650 - accuracy: 0.8365 - val_loss: 0.7476 - val_accuracy: 0.7570\n",
            "Epoch 46/55\n",
            "160/160 [==============================] - 103s 647ms/step - loss: 0.4636 - accuracy: 0.8365 - val_loss: 0.7485 - val_accuracy: 0.7501\n",
            "Epoch 47/55\n",
            "160/160 [==============================] - 104s 652ms/step - loss: 0.4628 - accuracy: 0.8363 - val_loss: 0.7589 - val_accuracy: 0.7510\n",
            "Epoch 48/55\n",
            "160/160 [==============================] - 108s 674ms/step - loss: 0.4453 - accuracy: 0.8420 - val_loss: 0.7477 - val_accuracy: 0.7581\n",
            "Epoch 49/55\n",
            "160/160 [==============================] - 107s 670ms/step - loss: 0.4566 - accuracy: 0.8372 - val_loss: 0.7497 - val_accuracy: 0.7550\n",
            "Epoch 50/55\n",
            "160/160 [==============================] - 107s 668ms/step - loss: 0.4498 - accuracy: 0.8411 - val_loss: 0.7491 - val_accuracy: 0.7535\n",
            "Epoch 51/55\n",
            "160/160 [==============================] - 102s 637ms/step - loss: 0.4457 - accuracy: 0.8444 - val_loss: 0.7471 - val_accuracy: 0.7563\n",
            "Epoch 52/55\n",
            "160/160 [==============================] - 103s 644ms/step - loss: 0.4367 - accuracy: 0.8461 - val_loss: 0.7403 - val_accuracy: 0.7605\n",
            "Epoch 53/55\n",
            "160/160 [==============================] - 107s 669ms/step - loss: 0.4322 - accuracy: 0.8461 - val_loss: 0.7436 - val_accuracy: 0.7599\n",
            "Epoch 54/55\n",
            "160/160 [==============================] - 107s 671ms/step - loss: 0.4316 - accuracy: 0.8488 - val_loss: 0.7689 - val_accuracy: 0.7453\n",
            "Epoch 55/55\n",
            "160/160 [==============================] - 108s 675ms/step - loss: 0.4316 - accuracy: 0.8478 - val_loss: 0.7504 - val_accuracy: 0.7571\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7ef0a695f6d0>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate generalization metrics\n",
        "score = model.evaluate(input_test, target_test, verbose=0)\n",
        "print(f'Test loss: {score[0]} / Test accuracy: {score[1]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_A_6Wq7Enoi",
        "outputId": "b8e13fb5-b514-4b6d-d104-3132aad6f29a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 0.7763357758522034 / Test accuracy: 0.7472000122070312\n"
          ]
        }
      ]
    }
  ]
}