{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Meet Stacker — automatic python ensembling factory.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPukaK+8dU250qsoY9oD9LI"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[Reference](https://danilzherebtsov.medium.com/meet-stacker-automated-ensemble-creation-library-abcad0648a5d)|"
      ],
      "metadata": {
        "id": "VtDMJ85_b7CM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install verstack"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "OunUdx8OcMuy",
        "outputId": "babc6090-6344-4e11-8dfc-4de315e84444"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting verstack\n",
            "  Downloading verstack-3.0.3.tar.gz (9.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.6 MB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from verstack) (1.3.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from verstack) (1.21.5)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.7/dist-packages (from verstack) (0.90)\n",
            "Collecting scikit-learn==1.0.1\n",
            "  Downloading scikit_learn-1.0.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (23.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 23.2 MB 1.6 MB/s \n",
            "\u001b[?25hCollecting lightgbm==3.3.0\n",
            "  Downloading lightgbm-3.3.0-py3-none-manylinux1_x86_64.whl (2.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.0 MB 46.4 MB/s \n",
            "\u001b[?25hCollecting optuna==2.10.0\n",
            "  Downloading optuna-2.10.0-py3-none-any.whl (308 kB)\n",
            "\u001b[K     |████████████████████████████████| 308 kB 45.9 MB/s \n",
            "\u001b[?25hCollecting plotly==5.3.1\n",
            "  Downloading plotly-5.3.1-py2.py3-none-any.whl (23.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 23.9 MB 1.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from verstack) (3.2.2)\n",
            "Collecting python-dateutil==2.8.1\n",
            "  Downloading python_dateutil-2.8.1-py2.py3-none-any.whl (227 kB)\n",
            "\u001b[K     |████████████████████████████████| 227 kB 46.6 MB/s \n",
            "\u001b[?25hCollecting holidays==0.11.3.1\n",
            "  Downloading holidays-0.11.3.1-py3-none-any.whl (155 kB)\n",
            "\u001b[K     |████████████████████████████████| 155 kB 45.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: mlxtend in /usr/local/lib/python3.7/dist-packages (from verstack) (0.14.0)\n",
            "Collecting tensorflow==2.7.0\n",
            "  Downloading tensorflow-2.7.0-cp37-cp37m-manylinux2010_x86_64.whl (489.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 489.6 MB 23 kB/s \n",
            "\u001b[?25hCollecting keras==2.7.0\n",
            "  Downloading keras-2.7.0-py2.py3-none-any.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 57.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: hijri-converter in /usr/local/lib/python3.7/dist-packages (from holidays==0.11.3.1->verstack) (2.2.3)\n",
            "Requirement already satisfied: convertdate>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from holidays==0.11.3.1->verstack) (2.4.0)\n",
            "Requirement already satisfied: korean-lunar-calendar in /usr/local/lib/python3.7/dist-packages (from holidays==0.11.3.1->verstack) (0.2.1)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (from lightgbm==3.3.0->verstack) (0.37.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from lightgbm==3.3.0->verstack) (1.4.1)\n",
            "Requirement already satisfied: sqlalchemy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from optuna==2.10.0->verstack) (1.4.35)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from optuna==2.10.0->verstack) (3.13)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from optuna==2.10.0->verstack) (4.64.0)\n",
            "Collecting cliff\n",
            "  Downloading cliff-3.10.1-py3-none-any.whl (81 kB)\n",
            "\u001b[K     |████████████████████████████████| 81 kB 9.4 MB/s \n",
            "\u001b[?25hCollecting alembic\n",
            "  Downloading alembic-1.7.7-py3-none-any.whl (210 kB)\n",
            "\u001b[K     |████████████████████████████████| 210 kB 48.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from optuna==2.10.0->verstack) (21.3)\n",
            "Collecting cmaes>=0.8.2\n",
            "  Downloading cmaes-0.8.2-py3-none-any.whl (15 kB)\n",
            "Collecting colorlog\n",
            "  Downloading colorlog-6.6.0-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from plotly==5.3.1->verstack) (8.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from plotly==5.3.1->verstack) (1.15.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==1.0.1->verstack) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==1.0.1->verstack) (3.1.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0->verstack) (3.1.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0->verstack) (1.0.0)\n",
            "Collecting tensorflow-estimator<2.8,~=2.7.0rc0\n",
            "  Downloading tensorflow_estimator-2.7.0-py2.py3-none-any.whl (463 kB)\n",
            "\u001b[K     |████████████████████████████████| 463 kB 68.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0->verstack) (1.6.3)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0->verstack) (1.14.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0->verstack) (4.1.1)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0->verstack) (13.0.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0->verstack) (1.1.2)\n",
            "Collecting gast<0.5.0,>=0.2.1\n",
            "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0->verstack) (3.3.0)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0->verstack) (2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0->verstack) (1.44.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0->verstack) (0.24.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0->verstack) (0.2.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0->verstack) (1.1.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0->verstack) (3.17.3)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0->verstack) (2.8.0)\n",
            "Requirement already satisfied: pymeeus<=1,>=0.3.13 in /usr/local/lib/python3.7/dist-packages (from convertdate>=2.3.0->holidays==0.11.3.1->verstack) (0.5.11)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow==2.7.0->verstack) (1.5.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->optuna==2.10.0->verstack) (3.0.8)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna==2.10.0->verstack) (1.1.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna==2.10.0->verstack) (4.11.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0->verstack) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0->verstack) (3.3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0->verstack) (2.23.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0->verstack) (0.4.6)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0->verstack) (57.4.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0->verstack) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0->verstack) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0->verstack) (1.0.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.7.0->verstack) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.7.0->verstack) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.7.0->verstack) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow==2.7.0->verstack) (1.3.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->sqlalchemy>=1.1.0->optuna==2.10.0->verstack) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.7.0->verstack) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.7.0->verstack) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.7.0->verstack) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.7.0->verstack) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.7.0->verstack) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow==2.7.0->verstack) (3.2.0)\n",
            "Collecting Mako\n",
            "  Downloading Mako-1.2.0-py3-none-any.whl (78 kB)\n",
            "\u001b[K     |████████████████████████████████| 78 kB 7.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from alembic->optuna==2.10.0->verstack) (5.6.0)\n",
            "Collecting cmd2>=1.0.0\n",
            "  Downloading cmd2-2.4.1-py3-none-any.whl (146 kB)\n",
            "\u001b[K     |████████████████████████████████| 146 kB 53.5 MB/s \n",
            "\u001b[?25hCollecting autopage>=0.4.0\n",
            "  Downloading autopage-0.5.0-py3-none-any.whl (29 kB)\n",
            "Requirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna==2.10.0->verstack) (3.2.0)\n",
            "Collecting pbr!=2.1.0,>=2.0.0\n",
            "  Downloading pbr-5.8.1-py2.py3-none-any.whl (113 kB)\n",
            "\u001b[K     |████████████████████████████████| 113 kB 48.5 MB/s \n",
            "\u001b[?25hCollecting stevedore>=2.0.1\n",
            "  Downloading stevedore-3.5.0-py3-none-any.whl (49 kB)\n",
            "\u001b[K     |████████████████████████████████| 49 kB 6.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna==2.10.0->verstack) (21.4.0)\n",
            "Collecting pyperclip>=1.6\n",
            "  Downloading pyperclip-1.8.2.tar.gz (20 kB)\n",
            "Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna==2.10.0->verstack) (0.2.5)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from Mako->alembic->optuna==2.10.0->verstack) (2.0.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->verstack) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->verstack) (1.4.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->verstack) (2018.9)\n",
            "Building wheels for collected packages: verstack, pyperclip\n",
            "  Building wheel for verstack (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for verstack: filename=verstack-3.0.3-py3-none-any.whl size=73100 sha256=019422db4e5ce053ddba62777c2bcee0314893017208b69fe189cb958153147f\n",
            "  Stored in directory: /root/.cache/pip/wheels/d6/7d/41/2b9ac43b55213e71352931fc34878f7dd9d10b887555a625f7\n",
            "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyperclip: filename=pyperclip-1.8.2-py3-none-any.whl size=11137 sha256=5ce14e2a7e2e998ca25eae3a41508d343fd607fb7047e0055b622a6d86f755f8\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/18/84/8f69f8b08169c7bae2dde6bd7daf0c19fca8c8e500ee620a28\n",
            "Successfully built verstack pyperclip\n",
            "Installing collected packages: pyperclip, pbr, stevedore, python-dateutil, Mako, cmd2, autopage, tensorflow-estimator, scikit-learn, keras, gast, colorlog, cmaes, cliff, alembic, tensorflow, plotly, optuna, lightgbm, holidays, verstack\n",
            "  Attempting uninstall: python-dateutil\n",
            "    Found existing installation: python-dateutil 2.8.2\n",
            "    Uninstalling python-dateutil-2.8.2:\n",
            "      Successfully uninstalled python-dateutil-2.8.2\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.8.0\n",
            "    Uninstalling tensorflow-estimator-2.8.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.8.0\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.0.2\n",
            "    Uninstalling scikit-learn-1.0.2:\n",
            "      Successfully uninstalled scikit-learn-1.0.2\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.8.0\n",
            "    Uninstalling keras-2.8.0:\n",
            "      Successfully uninstalled keras-2.8.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.5.3\n",
            "    Uninstalling gast-0.5.3:\n",
            "      Successfully uninstalled gast-0.5.3\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.8.0\n",
            "    Uninstalling tensorflow-2.8.0:\n",
            "      Successfully uninstalled tensorflow-2.8.0\n",
            "  Attempting uninstall: plotly\n",
            "    Found existing installation: plotly 5.5.0\n",
            "    Uninstalling plotly-5.5.0:\n",
            "      Successfully uninstalled plotly-5.5.0\n",
            "  Attempting uninstall: lightgbm\n",
            "    Found existing installation: lightgbm 2.2.3\n",
            "    Uninstalling lightgbm-2.2.3:\n",
            "      Successfully uninstalled lightgbm-2.2.3\n",
            "  Attempting uninstall: holidays\n",
            "    Found existing installation: holidays 0.10.5.2\n",
            "    Uninstalling holidays-0.10.5.2:\n",
            "      Successfully uninstalled holidays-0.10.5.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed Mako-1.2.0 alembic-1.7.7 autopage-0.5.0 cliff-3.10.1 cmaes-0.8.2 cmd2-2.4.1 colorlog-6.6.0 gast-0.4.0 holidays-0.11.3.1 keras-2.7.0 lightgbm-3.3.0 optuna-2.10.0 pbr-5.8.1 plotly-5.3.1 pyperclip-1.8.2 python-dateutil-2.8.1 scikit-learn-1.0.1 stevedore-3.5.0 tensorflow-2.7.0 tensorflow-estimator-2.7.0 verstack-3.0.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "dateutil"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l2M7PpPLb5uX",
        "outputId": "09ec5cb1-d693-48f4-83ed-2bcedb641c9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   . Training/predicting with layer_1 models\n",
            "   .. Optimising model hyperparameters\n",
            "   .. fold 2 trained/predicted\n",
            "   .. fold 4 trained/predicted\n",
            "   .. Optimising model hyperparameters\n",
            "   ... Model not in optimisation list LinearRegression()\n",
            "   .. fold 2 trained/predicted\n",
            "   .. fold 4 trained/predicted\n",
            "   . Training/predicting with layer_2 models\n",
            "   .. Optimising model hyperparameters\n",
            "   .. fold 2 trained/predicted\n",
            "   .. fold 4 trained/predicted\n",
            "   .. Optimising model hyperparameters\n",
            "   .. fold 2 trained/predicted\n",
            "   .. fold 4 trained/predicted\n",
            "\n",
            "Time elapsed for fit_transform execution: 10.06823 seconds\n",
            "\n",
            "   . Predicting with layer_1 models\n",
            "   .. predicted with model 1\n",
            "   .. predicted with model 2\n",
            "   . Predicting with layer_2 models\n",
            "   .. predicted with model 1\n",
            "   .. predicted with model 2\n",
            "['x1', 'x2', 'layer_1_0', 'layer_1_1', 'diff_layer_1_0_layer_1_1', 'layer_1_std', 'layer_1_mean', 'layer_2_0', 'layer_2_1', 'diff_layer_2_0_layer_2_1', 'layer_2_std', 'layer_2_mean']\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from verstack import Stacker\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.linear_model import LinearRegression, Ridge\n",
        "\n",
        "# create dummy data for regression\n",
        "train = pd.DataFrame({'x1': np.random.choice([0,1],20),\n",
        "                      'x2': np.random.choice([10,100], 20),\n",
        "                      'y': np.random.randint(100, 1000, 20)})\n",
        "\n",
        "test = pd.DataFrame({'x1': np.random.choice([0,1],20),\n",
        "                     'x2': np.random.choice([10,100], 20)})\n",
        "\n",
        "X = train.drop('y', axis = 1)\n",
        "y = train['y']\n",
        "\n",
        "# initialise Stacker for regression\n",
        "stacker = Stacker(objective = 'regression')\n",
        "# define layers\n",
        "layer_1 = [RandomForestRegressor(), LinearRegression()]\n",
        "layer_2 = [DecisionTreeRegressor(), Ridge()]\n",
        "# add layers to Stacker instance\n",
        "stacker.add_layer(layer_1)\n",
        "stacker.add_layer(layer_2)\n",
        "\n",
        "# fit_transform the train/test sets (add stacked feats)\n",
        "X = stacker.fit_transform(X, y)\n",
        "test = stacker.transform(test)\n",
        "\n",
        "print(X.columns.tolist())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import pandas as pd\n",
        "# from verstack import NaNImputer\n",
        "# from verstack import MeanTargetEncoder\n",
        "\n",
        "# train = pd.read_csv('train.csv')\n",
        "# test = pd.read_csv('test.csv')\n",
        "# sub = pd.read_csv('sample_submission.csv')\n",
        "\n",
        "# target = 'SalePrice'\n",
        "\n",
        "# # drop column with constant values\n",
        "# test.drop('Utilities', axis = 1, inplace = True)\n",
        "# train.drop('Utilities', axis = 1, inplace = True)\n",
        "\n",
        "# # IMPUTE NANs\n",
        "# imputer = NaNImputer()\n",
        "# train = imputer.impute(train)\n",
        "# imputer = NaNImputer()\n",
        "# test = imputer.impute(test)\n",
        "\n",
        "# # Mean-target-encode all the categoric columns\n",
        "# cat_cols = train.select_dtypes(include = 'O').columns\n",
        "\n",
        "# for col in cat_cols:\n",
        "#     enc = MeanTargetEncoder()\n",
        "#     train = enc.fit_transform(train, col, target)\n",
        "#     test = enc.transform(test)\n",
        "#     print(f'Encoded column {col}')\n",
        "\n",
        "# # ALL DATA IS NUMERIC AND READY FOR MODELING\n",
        "# # -----------------------------------------------------------------------------\n",
        "# X = train.drop(target, axis = 1)\n",
        "# y = train[target]"
      ],
      "metadata": {
        "id": "8reWqyUub_bV"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from verstack import Stacker\n",
        "# from sklearn.linear_model import Ridge\n",
        "\n",
        "# stacker = Stacker(objective = 'regression', auto = True)\n",
        "# X = stacker.fit_transform(X, y)\n",
        "# test = stacker.transform(test)\n",
        "\n",
        "# # get lists of features created in each layer\n",
        "# layer_1_feats = stacker.stacked_features['layer_1']\n",
        "# layer_2_feats = stacker.stacked_features['layer_2']\n",
        "\n",
        "# model = Ridge()\n",
        "\n",
        "# # use only the second layer outputs as inputs in to the final meta_model\n",
        "# model.fit(X[layer_2_feats], y)\n",
        "# pred = model.predict(test[layer_2_feats])\n",
        "\n",
        "# sub['SalePrice'] = pred\n",
        "# sub.to_csv('simple_linear_model_on_layer_2_feats.csv', index = False)"
      ],
      "metadata": {
        "id": "uWc1Z8OTcJx-"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.linear_model import LinearRegression, Ridge\n",
        "# from sklearn.tree import DecisionTreeRegressor\n",
        "# from sklearn.ensemble import ExtraTreesRegressor\n",
        "# from verstack import Stacker\n",
        "\n",
        "# stacker = Stacker(objective = 'regression')\n",
        "# stacker.add_layer([LinearRegression(), DecisionTreeRegressor()])\n",
        "# stacker.add_layer([Ridge(), ExtraTreesRegressor()])\n",
        "\n",
        "# print(stacker.layers)\n",
        "# #>>> {'layer_1': [LinearRegression(), DecisionTreeRegressor()],\n",
        "# #>>>  'layer_2': [Ridge(), ExtraTreesRegressor()]}\n",
        "\n",
        "# print(stacker)\n",
        "# #>>> Stacker(objective: regression            \n",
        "# #>>>         auto: False            \n",
        "# #>>>         num_auto_layers: 2            \n",
        "# #>>>         metafeats: True            <--- will create metafeats in these two layers    \n",
        "# #>>>         epochs : 200            \n",
        "# #>>>         gridsearch_iterations: 10  <--- will optimise parameters for all models in these two layers\n",
        "# #>>>         stacking_feats_depth: 1    <--- will use only the previous layer for predicting with subsequent layer\n",
        "# #>>>         include_X: False           <--- will not use original features when creating subsequent layers\n",
        "# #>>>         verbose : True)\n",
        "\n",
        "# X = stacker.fit_transform(X, y)\n",
        "# test = stacker.transform(test)"
      ],
      "metadata": {
        "id": "8TolDv9icaMR"
      },
      "execution_count": 5,
      "outputs": []
    }
  ]
}