{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "A friendly introduction to Siamese Networks.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMirJl7s6ufKCU6XLxPhRzN"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wn7LMUjMan2e"
      },
      "source": [
        "[Reference](https://towardsdatascience.com/a-friendly-introduction-to-siamese-networks-85ab17522942)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvURXO2qakgI"
      },
      "source": [
        "#preprocessing and loading the dataset\n",
        "class SiameseDataset():\n",
        "    def __init__(self,training_csv=None,training_dir=None,transform=None):\n",
        "        # used to prepare the labels and images path\n",
        "        self.train_df=pd.read_csv(training_csv)\n",
        "        self.train_df.columns =[\"image1\",\"image2\",\"label\"]\n",
        "        self.train_dir = training_dir    \n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self,index):\n",
        "        # getting the image path\n",
        "        image1_path=os.path.join(self.train_dir,self.train_df.iat[index,0])\n",
        "        image2_path=os.path.join(self.train_dir,self.train_df.iat[index,1])\n",
        "        # Loading the image\n",
        "        img0 = Image.open(image1_path)\n",
        "        img1 = Image.open(image2_path)\n",
        "        img0 = img0.convert(\"L\")\n",
        "        img1 = img1.convert(\"L\")\n",
        "        # Apply image transformations\n",
        "        if self.transform is not None:\n",
        "            img0 = self.transform(img0)\n",
        "            img1 = self.transform(img1)\n",
        "        return img0, img1 , th.from_numpy(np.array([int(self.train_df.iat[index,2])],dtype=np.float32))\n",
        "    def __len__(self):\n",
        "        return len(self.train_df)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cysbhaaGdGYT"
      },
      "source": [
        "# Load the the dataset from raw image folders\n",
        "siamese_dataset = SiameseDataset(training_csv,training_dir,\n",
        "                                        transform=transforms.Compose([transforms.Resize((105,105)),\n",
        "                                                                      transforms.ToTensor()\n",
        "                                                                      ])\n",
        "                                       )"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UbV3-yt-dIYq"
      },
      "source": [
        "#create a siamese network\n",
        "class SiameseNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SiameseNetwork, self).__init__()\n",
        "        # Setting up the Sequential of CNN Layers\n",
        "        self.cnn1 = nn.Sequential(\n",
        "            nn.Conv2d(1, 96, kernel_size=11,stride=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.LocalResponseNorm(5,alpha=0.0001,beta=0.75,k=2),\n",
        "            nn.MaxPool2d(3, stride=2),\n",
        "            \n",
        "            nn.Conv2d(96, 256, kernel_size=5,stride=1,padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.LocalResponseNorm(5,alpha=0.0001,beta=0.75,k=2),\n",
        "            nn.MaxPool2d(3, stride=2),\n",
        "            nn.Dropout2d(p=0.3),\n",
        "\n",
        "            nn.Conv2d(256,384 , kernel_size=3,stride=1,padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            \n",
        "            nn.Conv2d(384,256 , kernel_size=3,stride=1,padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(3, stride=2),\n",
        "            nn.Dropout2d(p=0.3),\n",
        "        )\n",
        "        # Defining the fully connected layers\n",
        "        self.fc1 = nn.Sequential(\n",
        "            nn.Linear(30976, 1024),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout2d(p=0.5),\n",
        "            \n",
        "            nn.Linear(1024, 128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            \n",
        "            nn.Linear(128,2))\n",
        "        \n",
        "    def forward_once(self, x):\n",
        "        # Forward pass \n",
        "        output = self.cnn1(x)\n",
        "        output = output.view(output.size()[0], -1)\n",
        "        output = self.fc1(output)\n",
        "        return output\n",
        "\n",
        "    def forward(self, input1, input2):\n",
        "        # forward pass of input 1\n",
        "        output1 = self.forward_once(input1)\n",
        "        # forward pass of input 2\n",
        "        output2 = self.forward_once(input2)\n",
        "        return output1, output2"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4D-1XztdLZh"
      },
      "source": [
        "class ContrastiveLoss(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    Contrastive loss function.\n",
        "    Based on:\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, margin=1.0):\n",
        "        super(ContrastiveLoss, self).__init__()\n",
        "        self.margin = margin\n",
        "\n",
        "    def forward(self, x0, x1, y):\n",
        "        # euclidian distance\n",
        "        diff = x0 - x1\n",
        "        dist_sq = torch.sum(torch.pow(diff, 2), 1)\n",
        "        dist = torch.sqrt(dist_sq)\n",
        "\n",
        "        mdist = self.margin - dist\n",
        "        dist = torch.clamp(mdist, min=0.0)\n",
        "        loss = y * dist_sq + (1 - y) * torch.pow(dist, 2)\n",
        "        loss = torch.sum(loss) / 2.0 / x0.size()[0]\n",
        "        return loss"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COqPxNo0dP3U"
      },
      "source": [
        "# Declare Siamese Network\n",
        "net = SiameseNetwork().cuda()\n",
        "# Decalre Loss Function\n",
        "criterion = ContrastiveLoss()\n",
        "# Declare Optimizer\n",
        "optimizer = th.optim.Adam(net.parameters(), lr=1e-3, weight_decay=0.0005)\n",
        "#train the model\n",
        "def train():\n",
        "    loss=[] \n",
        "    counter=[]\n",
        "    iteration_number = 0\n",
        "    for epoch in range(1,config.epochs):\n",
        "        for i, data in enumerate(train_dataloader,0):\n",
        "            img0, img1 , label = data\n",
        "            img0, img1 , label = img0.cuda(), img1.cuda() , label.cuda()\n",
        "            optimizer.zero_grad()\n",
        "            output1,output2 = net(img0,img1)\n",
        "            loss_contrastive = criterion(output1,output2,label)\n",
        "            loss_contrastive.backward()\n",
        "            optimizer.step()    \n",
        "        print(\"Epoch {}\\n Current loss {}\\n\".format(epoch,loss_contrastive.item()))\n",
        "        iteration_number += 10\n",
        "        counter.append(iteration_number)\n",
        "        loss.append(loss_contrastive.item())\n",
        "    show_plot(counter, loss)   \n",
        "    return net\n",
        "#set the device to cuda\n",
        "device = torch.device('cuda' if th.cuda.is_available() else 'cpu')\n",
        "model = train()\n",
        "torch.save(model.state_dict(), \"model.pt\")\n",
        "print(\"Model Saved Successfully\") "
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ufAFrZWQdV6M"
      },
      "source": [
        "# Load the test dataset\n",
        "test_dataset = SiameseDataset(training_csv=testing_csv,training_dir=testing_dir,\n",
        "                                        transform=transforms.Compose([transforms.Resize((105,105)),\n",
        "                                                                      transforms.ToTensor()\n",
        "                                                                      ])\n",
        "                                       )\n",
        "\n",
        "test_dataloader = DataLoader(test_dataset,num_workers=6,batch_size=1,shuffle=True)\n",
        "#test the network\n",
        "count=0\n",
        "for i, data in enumerate(test_dataloader,0): \n",
        "  x0, x1 , label = data\n",
        "  concat = torch.cat((x0,x1),0)\n",
        "  output1,output2 = model(x0.to(device),x1.to(device))\n",
        "\n",
        "  eucledian_distance = F.pairwise_distance(output1, output2)\n",
        "    \n",
        "  if label==torch.FloatTensor([[0]]):\n",
        "    label=\"Original Pair Of Signature\"\n",
        "  else:\n",
        "    label=\"Forged Pair Of Signature\"\n",
        "    \n",
        "  imshow(torchvision.utils.make_grid(concat))\n",
        "  print(\"Predicted Eucledian Distance:-\",eucledian_distance.item())\n",
        "  print(\"Actual Label:-\",label)\n",
        "  count=count+1\n",
        "  if count ==10:\n",
        "     break"
      ],
      "execution_count": 6,
      "outputs": []
    }
  ]
}