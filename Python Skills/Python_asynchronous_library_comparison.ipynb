{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Python asynchronous library comparison.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNc6Im0YDrjwurODetSdzxY"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJzrAZTQ36wg"
      },
      "source": [
        "[Reference](https://oceanpad.medium.com/python-asynchronous-library-comparison-f4a9c8c225e5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "393RZqYr4JSN"
      },
      "source": [
        "- threading\n",
        "- multiprocessing\n",
        "- asyncio\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VoCYOnRG343K",
        "outputId": "f7ccb553-ec01-4d5d-c7f3-80806620f28c"
      },
      "source": [
        "import requests\n",
        "import time\n",
        "\n",
        "\n",
        "def download_site(url, session):\n",
        "  with session.get(url) as response:\n",
        "    print(\"Got content from website: {}\".format(url))\n",
        "\n",
        "\n",
        "def download_all_sites(sites):\n",
        "  with requests.Session() as session:\n",
        "    for url in sites:\n",
        "        download_site(url, session)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  sites = [\"https://stackoverflow.com\", \"https://github.com\"] * 10\n",
        "  start_time = time.time()\n",
        "  download_all_sites(sites)\n",
        "  duration = time.time() - start_time\n",
        "  print(\"Download time: {}\".format(duration))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Got content from website: https://stackoverflow.com\n",
            "Got content from website: https://github.com\n",
            "Got content from website: https://stackoverflow.com\n",
            "Got content from website: https://github.com\n",
            "Got content from website: https://stackoverflow.com\n",
            "Got content from website: https://github.com\n",
            "Got content from website: https://stackoverflow.com\n",
            "Got content from website: https://github.com\n",
            "Got content from website: https://stackoverflow.com\n",
            "Got content from website: https://github.com\n",
            "Got content from website: https://stackoverflow.com\n",
            "Got content from website: https://github.com\n",
            "Got content from website: https://stackoverflow.com\n",
            "Got content from website: https://github.com\n",
            "Got content from website: https://stackoverflow.com\n",
            "Got content from website: https://github.com\n",
            "Got content from website: https://stackoverflow.com\n",
            "Got content from website: https://github.com\n",
            "Got content from website: https://stackoverflow.com\n",
            "Got content from website: https://github.com\n",
            "Download time: 2.1867833137512207\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xp9rKEFu4N9y",
        "outputId": "153d9235-a03e-4fad-aa40-f80ea91cf8bb"
      },
      "source": [
        "import concurrent.futures\n",
        "import threading\n",
        "import requests\n",
        "import time\n",
        "thread_local = threading.local()\n",
        "\n",
        "def get_session():\n",
        "  if getattr(thread_local, \"session\", None) is None:\n",
        "    thread_local.session = requests.Session()\n",
        "  return thread_local.session\n",
        "\n",
        "def download_site(url):\n",
        "  session = get_session()\n",
        "  with session.get(url) as response:\n",
        "    print(\"Got content from website: {}\".format(url))\n",
        "\n",
        "def download_all_sites(sites):\n",
        "  with concurrent.futures.ThreadPoolExecutor(max_workers = 5) as executor:\n",
        "    executor.map(download_site, sites)\n",
        "    \n",
        "if __name__ == \"__main__\":\n",
        "  sites = [\"https://stackoverflow.com\", \"https://github.com\"] * 10\n",
        "  start_time = time.time()\n",
        "  download_all_sites(sites)\n",
        "  duration = time.time() - start_time\n",
        "  print(\"Download time: {}\".format(duration))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Got content from website: https://stackoverflow.com\n",
            "Got content from website: https://stackoverflow.com\n",
            "Got content from website: https://stackoverflow.com\n",
            "Got content from website: https://stackoverflow.com\n",
            "Got content from website: https://github.com\n",
            "Got content from website: https://github.com\n",
            "Got content from website: https://stackoverflow.com\n",
            "Got content from website: https://github.com\n",
            "Got content from website: https://github.com\n",
            "Got content from website: https://stackoverflow.com\n",
            "Got content from website: https://github.com\n",
            "Got content from website: https://stackoverflow.com\n",
            "Got content from website: https://github.com\n",
            "Got content from website: https://stackoverflow.com\n",
            "Got content from website: https://github.com\n",
            "Got content from website: https://stackoverflow.com\n",
            "Got content from website: https://github.com\n",
            "Got content from website: https://github.com\n",
            "Got content from website: https://github.com\n",
            "Got content from website: https://stackoverflow.com\n",
            "Download time: 0.8919253349304199\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8piaPll4Y9n",
        "outputId": "93583625-2624-4dbb-f5dc-a6027b865cb0"
      },
      "source": [
        "!pip install aiohttp"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.7.4.post0-cp37-cp37m-manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 7.1 MB/s \n",
            "\u001b[?25hCollecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.7.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 69.2 MB/s \n",
            "\u001b[?25hCollecting async-timeout<4.0,>=3.0\n",
            "  Downloading async_timeout-3.0.1-py3-none-any.whl (8.2 kB)\n",
            "Requirement already satisfied: chardet<5.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp) (3.0.4)\n",
            "Requirement already satisfied: typing-extensions>=3.6.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp) (3.7.4.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp) (21.2.0)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-5.2.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (160 kB)\n",
            "\u001b[K     |████████████████████████████████| 160 kB 56.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: idna>=2.0 in /usr/local/lib/python3.7/dist-packages (from yarl<2.0,>=1.0->aiohttp) (2.10)\n",
            "Installing collected packages: multidict, yarl, async-timeout, aiohttp\n",
            "Successfully installed aiohttp-3.7.4.post0 async-timeout-3.0.1 multidict-5.2.0 yarl-1.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDEOhGHc4Sff"
      },
      "source": [
        "import asyncio\n",
        "import aiohttp\n",
        "import time\n",
        "\n",
        "async def download_site(session, url):\n",
        "  async with session.get(url) as response:\n",
        "    print(\"Got content from website: {}\".format(url))\n",
        "\n",
        "async def download_all_sites(sites):\n",
        "  async with aiohttp.ClientSession() as session:\n",
        "    tasks = []\n",
        "    for url in sites:\n",
        "      task = asyncio.ensure_future(download_site(session, url))\n",
        "      tasks.append(task)\n",
        "    await asyncio.gather(*tasks, return_exceptions=True)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  sites = [\"https://stackoverflow.com\", \"https://github.com\"] * 10\n",
        "  start_time = time.time()\n",
        "  asyncio.get_event_loop().run_until_complete(download_all_sites(sites))\n",
        "  duration = time.time() - start_time\n",
        "  print(\"Download time: {}\".format(duration))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-uEos11g4WS-",
        "outputId": "364465e3-bb9d-4ac9-df4c-c03bbe8a2d32"
      },
      "source": [
        "import requests\n",
        "import multiprocessing\n",
        "import time\n",
        "session = None\n",
        "\n",
        "def set_global_session():\n",
        "  global session\n",
        "  if not session:\n",
        "      session = requests.Session()\n",
        "\n",
        "def download_site(url):\n",
        "  with session.get(url) as response:\n",
        "    print(\"Got content from website: {}\".format(url))\n",
        "\n",
        "def download_all_sites(sites):\n",
        "  with multiprocessing.Pool(initializer = set_global_session) as pool:\n",
        "        pool.map(download_site, sites)\n",
        "        \n",
        "if __name__ == \"__main__\":\n",
        "  sites = [\"https://stackoverflow.com\", \"https://github.com\"] * 10\n",
        "  start_time = time.time()\n",
        "  download_all_sites(sites)\n",
        "  duration = time.time() - start_time\n",
        "  print(\"Download time: {}\".format(duration))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Got content from website: https://stackoverflow.com\n",
            "Got content from website: https://github.com\n",
            "Got content from website: https://stackoverflow.com\n",
            "Got content from website: https://github.com\n",
            "Got content from website: https://github.com\n",
            "Got content from website: https://stackoverflow.com\n",
            "Got content from website: https://stackoverflow.com\n",
            "Got content from website: https://github.com\n",
            "Got content from website: https://github.com\n",
            "Got content from website: https://stackoverflow.com\n",
            "Got content from website: https://stackoverflow.com\n",
            "Got content from website: https://github.com\n",
            "Got content from website: https://stackoverflow.com\n",
            "Got content from website: https://github.com\n",
            "Got content from website: https://github.com\n",
            "Got content from website: https://stackoverflow.com\n",
            "Got content from website: https://stackoverflow.com\n",
            "Got content from website: https://github.com\n",
            "Got content from website: https://stackoverflow.com\n",
            "Got content from website: https://github.com\n",
            "Download time: 1.4255616664886475\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zsPuCOok4ju6"
      },
      "source": [
        "- So for CPU-intensive tasks, we should use multiprocessing, cause multiprocessing will use multiple CPUs and can reduce calculation time.\n",
        "\n",
        "- For I/O intensive tasks, we can choose threading or asyncio. This will help you run your tasks in a higher perfermance."
      ]
    }
  ]
}