{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Generate MS Word Tables With Python.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOmf9WECAMfqAKZ1Tk1xBL3"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OtXSliH0gxbM"
      },
      "source": [
        "[Reference](https://towardsdatascience.com/how-to-generate-ms-word-tables-with-python-6ca584df350e)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8e49kCQgvhr",
        "outputId": "53030c49-593e-426a-ae72-fc06725d8816",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "!pip install python-docx"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting python-docx\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e4/83/c66a1934ed5ed8ab1dbb9931f1779079f8bca0f6bbc5793c06c4b5e7d671/python-docx-0.8.10.tar.gz (5.5MB)\n",
            "\u001b[K     |████████████████████████████████| 5.5MB 1.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from python-docx) (4.2.6)\n",
            "Building wheels for collected packages: python-docx\n",
            "  Building wheel for python-docx (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-docx: filename=python_docx-0.8.10-cp36-none-any.whl size=184491 sha256=787ad6da1957c204c3cddfbb4cbcd2acef4bf0297288c551909cd603cb626f79\n",
            "  Stored in directory: /root/.cache/pip/wheels/18/0b/a0/1dd62ff812c857c9e487f27d80d53d2b40531bec1acecfa47b\n",
            "Successfully built python-docx\n",
            "Installing collected packages: python-docx\n",
            "Successfully installed python-docx-0.8.10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cta6d5xIhCdP"
      },
      "source": [
        "# Extracting Stats From Articles"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94iHqoFmg2FP"
      },
      "source": [
        "def describe_text(text):\n",
        "    import re, string\n",
        "    \n",
        "    description = dict()\n",
        "    \n",
        "    # remove punctuation marks\n",
        "    text_wo_punctuation_marks = re.sub(f'[%s]' % re.escape(string.punctuation), '', text)\n",
        "    \n",
        "    # tokens of the text without punctuation marks\n",
        "    tokens_of_text_wo_punctuation_marks = text_wo_punctuation_marks.split(' ') \n",
        "    \n",
        "    # list of sentences\n",
        "    pattern = re.compile(r'([A-Z][^\\.!?]*[\\.!?])', re.M)\n",
        "    list_of_sentences = re.findall(pattern, text)\n",
        "    \n",
        "    # sentence character and word counts\n",
        "    list_of_sentence_character_count = [len(sentence) for sentence in list_of_sentences]\n",
        "    list_of_sentence_words_counts = [len(sentence.split(' ')) for sentence in list_of_sentences]\n",
        "    \n",
        "    description['Number of characters'] = len(text) \n",
        "    description['Number of words'] = len(tokens_of_text_wo_punctuation_marks)\n",
        "    description['Number of unique words'] = len(set(tokens_of_text_wo_punctuation_marks)) \n",
        "    description['Number of sentences'] = len(list_of_sentences)\n",
        "    description['Number of new lines'] = len([char for char in text if char == '\\n'])\n",
        "    description['Number of punctuatino marks'] = len([char for char in text if char in string.punctuation])\n",
        "    description['Average words per sentence'] = round(len(tokens_of_text_wo_punctuation_marks)/len(list_of_sentences), 2)\n",
        "    description['Average word length'] = round(sum([len(token) for token in tokens_of_text_wo_punctuation_marks])/len(tokens_of_text_wo_punctuation_marks), 2)\n",
        "    description['Maximum characters in a sentence'] = max(list_of_sentence_character_count)\n",
        "    description['Minimum characters in a sentence'] = min(list_of_sentence_character_count)\n",
        "    description['Maximum words in a sentence'] = max(list_of_sentence_words_counts)\n",
        "    description['Minimum words in a sentence'] = min(list_of_sentence_words_counts)\n",
        "    description['Contains numbers'] = any(char.isdigit() for char in text)\n",
        "    description['Contains unicode characters'] = any([ord(char) > 255] for char in text)\n",
        "    description['Contains interrogative sentences'] = '?' in text\n",
        "    description['Contains exclamatory sentences'] = '!' in text\n",
        "    \n",
        "    return description"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xllhpk1pg9dD",
        "outputId": "68c0bff7-c073-4a88-cc0a-4e5288aff80f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "# Test\n",
        "text = \"\"\"Even at a school like CSM, the knitwear avenue is still considered a ‘niche’ pursuit. “I still get a lot of patronising remarks about knitting, mostly from men, who say things like ‘Oh so you just knit in a circle?’ The reality is that I’m operating intense machinery on a day-to-day basis. And even if I was knitting in a circle, what’s wrong with that?”\"\"\"\n",
        "describe_text(text)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Average word length': 4.32,\n",
              " 'Average words per sentence': 16.25,\n",
              " 'Contains exclamatory sentences': False,\n",
              " 'Contains interrogative sentences': True,\n",
              " 'Contains numbers': False,\n",
              " 'Contains unicode characters': True,\n",
              " 'Maximum characters in a sentence': 127,\n",
              " 'Maximum words in a sentence': 25,\n",
              " 'Minimum characters in a sentence': 63,\n",
              " 'Minimum words in a sentence': 12,\n",
              " 'Number of characters': 355,\n",
              " 'Number of new lines': 0,\n",
              " 'Number of punctuatino marks': 10,\n",
              " 'Number of sentences': 4,\n",
              " 'Number of unique words': 55,\n",
              " 'Number of words': 65}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_QOQymAhEbZ"
      },
      "source": [
        "# Generating Tables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uI6H9-_fikjT",
        "outputId": "496f62ec-4d3d-47e8-f396-cb0d890cfe5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "os.chdir('gdrive/My Drive/Medium')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWIv0-Dyg_uM",
        "outputId": "6b82d876-609f-4f8c-e9bc-b28d51c6dc2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "from docx import Document\n",
        "from docx.shared import Cm, Pt\n",
        "\n",
        "\n",
        "article_1 = \"\"\"Bayern Munich came out on top in a thrilling German Cup final, beating Bayer Leverkusen 4-2 to secure its 20th title and remain on course for an historic treble.\n",
        "David Alaba's stunning free kick and Serge Gnabry's clinical finish gave Bayern a commanding lead heading into half time and Hans-Dieter Flick's side seemingly already had one hand on the trophy.\n",
        "However, Leverkusen responded well early in the second half and had a golden opportunity to halve the deficit through substitute Kevin Volland.\"\"\"\n",
        "\n",
        "article_2 = \"\"\"(CNN)Liverpool got its Premier League title-winning celebrations back on track with a 2-0 win over Aston Villa, just days after being on the receiving end of a record-equaling defeat.\n",
        "Many had suggested Jurgen Klopp's side was suffering from something of a hangover during Thursday's 4-0 demolition at the hands of Manchester City -- the joint-heaviest defeat by a team already crowned Premier League champion -- but Liverpool recovered in time to put relegation-threatened Aston Villa to the sword.\n",
        "It wasn't all plain sailing at Anfield on Sunday as Villa wasted several good opportunities to take the lead, before Sadio Mane eventually broke the deadlock after 71 minutes. Villa, who gave the host a guard of honor before the game, had further chances to level the scores, but Liverpool youngster Curtis Jones wrapped up the victory in the dying moments with his first Premier League goal.\"\"\"\n",
        "\n",
        "list_of_articles = [article_1, article_2]\n",
        "\n",
        "word_document = Document()\n",
        "document_name = 'news-article-stats'\n",
        "\n",
        "word_document = Document()\n",
        "document_name = 'news-article-stats'\n",
        "\n",
        "for article in list_of_articles:\n",
        "    # extracting text stats\n",
        "    text_stats = describe_text(article)\n",
        "    text_stats['Article'] = article\n",
        "    text_stats = dict(sorted(text_stats.items()))\n",
        "    \n",
        "    # customizing the table\n",
        "    table = word_document.add_table(0, 0) # we add rows iteratively\n",
        "    table.style = 'TableGrid'\n",
        "    first_column_width = 5\n",
        "    second_column_with = 10\n",
        "    table.add_column(Cm(first_column_width))\n",
        "    table.add_column(Cm(second_column_with))\n",
        "    \n",
        "    for index, stat_item in enumerate(text_stats.items()):\n",
        "        table.add_row()\n",
        "        stat_name, stat_result = stat_item\n",
        "        row = table.rows[index]\n",
        "        row.cells[0].text = str(stat_name)\n",
        "        row.cells[1].text = str(stat_result)\n",
        "    word_document.add_page_break()\n",
        "\n",
        "word_document.save(document_name + '.docx')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/docx/styles/styles.py:139: UserWarning: style lookup by style_id is deprecated. Use style name as key instead.\n",
            "  return self._get_style_id_from_style(self[style_name], style_type)\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}