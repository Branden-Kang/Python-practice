{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPktpm/YTwmcd7g1iuTkKOq"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[Reference](https://levelup.gitconnected.com/how-to-train-your-pytorch-models-much-faster-14737c8c9770)"
      ],
      "metadata": {
        "id": "Rsf3rLUv86Uq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Enable Automatic Mixed Precision Training"
      ],
      "metadata": {
        "id": "7r0l479y8-AV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ChW9yj8l80oz"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# define model, optimizer and criterion\n",
        "\n",
        "# define scaler using amp (Automatic Mixed Precision)\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        " # load inputs and labels with dataloader\n",
        "for inputs, labels in dataloader:\n",
        "    inputs = inputs.cuda(non_blocking=True)\n",
        "    labels = labels.cuda(non_blocking=True)\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # enable mixed precision training with the scaler\n",
        "    with torch.cuda.amp.autocast():\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "\n",
        "    scaler.scale(loss).backward()\n",
        "    scaler.step(optimizer)\n",
        "    scaler.update()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Find and Fix Bottlenecks"
      ],
      "metadata": {
        "id": "AfvTN9TL9DYQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.profiler\n",
        "\n",
        "with torch.profiler.profile(\n",
        "    schedule=torch.profiler.schedule(wait=1, warmup=1, active=3),\n",
        "    on_trace_ready=torch.profiler.tensorboard_trace_handler('./log'),\n",
        "    record_shapes=True,\n",
        "    with_stack=True\n",
        ") as prof:\n",
        "    for inputs, targets in dataloader:\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "        prof.step()"
      ],
      "metadata": {
        "id": "h5dQdHJr9Bj6"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Speed Up Your DataLoader"
      ],
      "metadata": {
        "id": "XUIJsaZE9G7S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "dataloader = DataLoader(\n",
        "    dataset,\n",
        "    batch_size=64,\n",
        "    shuffle=True,\n",
        "    num_workers=4,         # Use as many workers as your CPU cores allow\n",
        "    pin_memory=True,       # Speeds up data transfer to the GPU\n",
        "    prefetch_factor=2      # Preload batches (only after PyTorch v1.8.0)\n",
        ")"
      ],
      "metadata": {
        "id": "McOmzDzt9FH2"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Enable Static Compilation"
      ],
      "metadata": {
        "id": "fhzn5E-b9LDm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "model = torch.compile(model, \"max-autotune\")\n",
        "# or\n",
        "model = torch.compile(model, \"reduce-overhead\")"
      ],
      "metadata": {
        "id": "TwEARzA09I-6"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Scale Up With Distributed Training"
      ],
      "metadata": {
        "id": "q8vyq81-9P7r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.1) Data Parallelism on a Single Machine"
      ],
      "metadata": {
        "id": "R1D1wHPh9RMn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "model = nn.Linear(100, 10)\n",
        "\n",
        "# Automatically split your data across available GPUs\n",
        "model = nn.DataParallel(model)\n",
        "model = model.cuda()"
      ],
      "metadata": {
        "id": "fvQk2UCM9M-J"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.2) Serious Scaling using Distributed Data Parallel (DDP)"
      ],
      "metadata": {
        "id": "6bnHC_hG9UZo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.distributed as dist\n",
        "from torch.nn.parallel import DistributedDataParallel as DDP\n",
        "\n",
        "# Initialize the distributed environment\n",
        "# Make sure you set up your environment variables correctly\n",
        "dist.init_process_group(backend='nccl')\n",
        "model = nn.Linear(100, 10).cuda()\n",
        "model = DDP(model)"
      ],
      "metadata": {
        "id": "Qzn2OGat9S3n"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5.3) Leverage Gradient Accumulation"
      ],
      "metadata": {
        "id": "CnlyMMCh9YXQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "accumulation_steps = 4\n",
        "\n",
        "for i, (inputs, targets) in enumerate(dataloader):\n",
        "    inputs, targets = inputs.cuda(non_blocking=True), targets.cuda(non_blocking=True)\n",
        "    outputs = model(inputs)\n",
        "    loss = criterion(outputs, targets) / accumulation_steps\n",
        "    loss.backward()\n",
        "\n",
        "    if (i + 1) % accumulation_steps == 0:\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()"
      ],
      "metadata": {
        "id": "xN6J9rgA9WMm"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Use Task-Specialized Libraries"
      ],
      "metadata": {
        "id": "aLwsABv_9ihQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6.1) PyTorch Lightning"
      ],
      "metadata": {
        "id": "J1CDhWuM9kH2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pytorch_lightning as pl\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class LitModel(pl.LightningModule):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.layer = nn.Linear(100, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layer(x)\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        y_hat = self(x)\n",
        "        loss = F.mse_loss(y_hat, y)\n",
        "        return loss\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return torch.optim.SGD(self.parameters(), lr=0.01)\n",
        "\n",
        "trainer = pl.Trainer(gpus=2, precision=16, accelerator='ddp')\n",
        "trainer.fit(LitModel(), dataloader)"
      ],
      "metadata": {
        "id": "Q4JDQn-79gSg"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6.2) NVIDIA Apex"
      ],
      "metadata": {
        "id": "paHGh39e9pH4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from apex import amp\n",
        "model, optimizer = amp.initialize(model, optimizer, opt_level=\"O1\")"
      ],
      "metadata": {
        "id": "-1rfPEsT9nFu"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. Model Specific Optimizations"
      ],
      "metadata": {
        "id": "vaEYHQ599w8a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.quantization\n",
        "\n",
        "model.qconfig = torch.quantization.get_default_qconfig('fbgemm')\n",
        "torch.quantization.prepare(model, inplace=True)\n",
        "\n",
        "# Calibrate with your data\n",
        "for inputs, _ in calibration_dataloader:\n",
        "    model(inputs)\n",
        "\n",
        "torch.quantization.convert(model, inplace=True)"
      ],
      "metadata": {
        "id": "e8O3cD4O9qyg"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8. cuDNN and GPU Tweaks"
      ],
      "metadata": {
        "id": "t3XtHz1d90df"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.backends.cudnn.deterministic = False"
      ],
      "metadata": {
        "id": "1OyeJhZP-Kln"
      },
      "execution_count": 11,
      "outputs": []
    }
  ]
}
