{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPMmyQvccjc8MaMyW6RsWPH"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[Reference](https://python.plainenglish.io/big-data-meet-apache-spark-061897b8358d)"
      ],
      "metadata": {
        "id": "qm9SOkYy8fmB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting Up PySpark"
      ],
      "metadata": {
        "id": "MsGAv-PB8lJh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ecbvZYe88XAe",
        "outputId": "1a40af91-c1dc-480d-cb07-3ce1d1c06646"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.5.3)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -c \"import pyspark; print(pyspark.__version__)\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQu5FDdT8m4v",
        "outputId": "0468c7dc-e7f6-43dd-f40b-98cb2f41a7d1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.5.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"PySpark Example\") \\\n",
        "    .getOrCreate()"
      ],
      "metadata": {
        "id": "Kk8DISPO8n3y"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading and Inspecting Data\n",
        "## Loading Data"
      ],
      "metadata": {
        "id": "6AU87n1Z8p4z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = [(\"Alice\", 29), (\"Bob\", 35), (\"Cathy\", 45)]\n",
        "columns = [\"Name\", \"Age\"]\n",
        "\n",
        "df = spark.createDataFrame(data, columns)\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R4yVCt0L8pmh",
        "outputId": "a035db0a-8601-4824-c057-b8a208303340"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+---+\n",
            "| Name|Age|\n",
            "+-----+---+\n",
            "|Alice| 29|\n",
            "|  Bob| 35|\n",
            "|Cathy| 45|\n",
            "+-----+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Python Spark Code:"
      ],
      "metadata": {
        "id": "fMoTmqRU8xIo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from io import StringIO\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "wYtgYQdq91Mi"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = StringIO(\n",
        "\"\"\"\n",
        "City,Population,Area,Population Density\n",
        "New York,8419600,789.4,10661\n",
        "Los Angeles,3980400,1213.9,3283\n",
        "Chicago,2716000,606.1,4484\n",
        "Houston,2328000,1625.2,1432\n",
        "Phoenix,1690000,1340.6,1255\n",
        "San Antonio,1547253,1194.3,1296\n",
        "San Diego,1423851,964.5,1475\n",
        "Dallas,1341000,880.1,1520\n",
        "Austin,978908,437.2,2244\n",
        "Miami,467963,143.1,3267\n",
        "Mexico City,8918653,1485.0,6013\n",
        "Lagos,9000000,1171.3,7674\n",
        "Bangkok,8300000,1569.0,5297\n",
        "Jakarta,10400000,662.3,15796\n",
        "Manila,1780148,38.55,46190\n",
        "Singapore,5612300,728.6,7700\n",
        "\"\"\")"
      ],
      "metadata": {
        "id": "ZgB5qsLc8sI5"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(df, sep=\",\")"
      ],
      "metadata": {
        "id": "uzOPUFLb9IlJ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv(\"cities_population_density.csv\",index=False)"
      ],
      "metadata": {
        "id": "IW3wczi2-ED6"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5zH27bV0-X9t",
        "outputId": "a6742273-14b4-45ac-8768-49e2de4ac374"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[City: string, Population: int, Area: double, Population Density: int]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "# Initialize the Spark session\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"City with Highest Population Density\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# Load the CSV file into a Spark DataFrame\n",
        "df = spark.read.csv(\"cities_population_density.csv\", header=True, inferSchema=True)\n",
        "\n",
        "# Find the city with the highest population density\n",
        "city_with_highest_density = df.orderBy(col(\"Population Density\").desc()).first()\n",
        "\n",
        "# Show the result\n",
        "print(f\"The city with the highest population density is {city_with_highest_density['City']} with a population density of {city_with_highest_density['Population Density']} people/km².\")\n",
        "\n",
        "# Stop the Spark session\n",
        "spark.stop()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VEloUSje-Prv",
        "outputId": "fb965594-8ad3-4c33-e716-621fa450616e"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The city with the highest population density is Manila with a population density of 46190 people/km².\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "# Initialize the Spark session\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"City with Highest Population Density\") \\\n",
        "    .getOrCreate()"
      ],
      "metadata": {
        "id": "Bop74MHT--yj"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.regression import LinearRegression\n",
        "\n",
        "data = [(1.0, 2.0), (2.0, 4.0), (3.0, 6.0), (4.0, 8.0)]\n",
        "columns = [\"Feature\", \"Label\"]\n",
        "\n",
        "df = spark.createDataFrame(data, columns)\n",
        "\n",
        "vector_assembler = VectorAssembler(inputCols=[\"Feature\"], outputCol=\"Features\")\n",
        "transformed_data = vector_assembler.transform(df)"
      ],
      "metadata": {
        "id": "5y3oCF_v-UJx"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = LinearRegression(featuresCol=\"Features\", labelCol=\"Label\")\n",
        "model = lr.fit(transformed_data)\n",
        "\n",
        "print(f\"Intercept: {model.intercept}\")\n",
        "print(f\"Coefficients: {model.coefficients}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VyseIUCM-kwA",
        "outputId": "f0f4c2da-833f-4006-92b8-d86b86fa0a82"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Intercept: 0.0\n",
            "Coefficients: [2.0]\n"
          ]
        }
      ]
    }
  ]
}
