{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fundamentals of Data Architecture to Help Data Scientists Understand Architectural Diagrams Better.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMgOh8KMhDT4UO82WIiufQV"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rj8YD_hUxccx"
      },
      "source": [
        "[Reference](https://towardsdatascience.com/fundamentals-of-data-architecture-to-help-data-scientists-understand-architectural-diagrams-better-7bd26de41c66)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJv0O4qfxPAF"
      },
      "source": [
        "import os\n",
        "import google.auth\n",
        "from google.cloud import bigquery\n",
        "from google.cloud import bigquery_storage_v1beta1\n",
        "import datetime\n",
        "import gspread\n",
        "import urllib.request\n",
        "from oauth2client.service_account import ServiceAccountCredentials\n",
        "\n",
        "def nytaxi_pubsub(event, context):\n",
        "\n",
        "\n",
        "    # 1st. Part - Run query upon data warehouse BigQuery table, create data mart BigQuery table, and create pandas data frame with the same contents.\n",
        "    \n",
        "\n",
        "    today = datetime.date.today().strftime('%Y%m%d')\n",
        "\n",
        "    # Explicitly create a credentials object. This allows you to use the same\n",
        "    # credentials for both the BigQuery and BigQuery Storage clients, avoiding\n",
        "    # unnecessary API calls to fetch duplicate authentication tokens.\n",
        "    credentials, project_id = google.auth.default(\n",
        "        scopes=[\"https://www.googleapis.com/auth/cloud-platform\"]\n",
        "    )\n",
        "\n",
        "    # Instantiate bigquery client and bigquery_storage client for the project.\n",
        "    client = bigquery.Client(project=project_id)\n",
        "    bqstorageclient = bigquery_storage_v1beta1.BigQueryStorageClient()\n",
        "\n",
        "    # Define query to run.\n",
        "    query = f\"\"\"\n",
        "        SELECT \n",
        "            {today} AS date\n",
        "            , passenger_count\n",
        "            , COUNT(*) AS ride_count\n",
        "            , SUM(passenger_count) AS total_passenger_count\n",
        "            , SUM(fare_amount) AS total_fare_amount\n",
        "            , SUM(tip_amount) AS total_tip_amount\n",
        "            , SUM(total_amount) AS total_amount\n",
        "        FROM < Original NY taxi data table in BigQuery >\n",
        "        --WHERE ride_month = {today}\n",
        "        GROUP BY passenger_count\n",
        "        ORDER BY passenger_count\n",
        "    \"\"\"\n",
        "\n",
        "    # Define BigQuery destination table.\n",
        "    destination_dataset = 'DataMart_NYTaxi_per_customer'\n",
        "    destination_table = f\"{project_id}.{destination_dataset}.DataMart_NYTaxi_per_customer_{today}\"\n",
        "\n",
        "    ## Delete if there's already a table as the target table.\n",
        "    client.delete_table(destination_table, not_found_ok=True)\n",
        "\n",
        "    # Run query upon data warehouse BigQuery table, create data mart BigQuery table, and create pandas data frame with the same contents.\n",
        "    query_job = client.query(query, job_config=bigquery.QueryJobConfig(destination=destination_table))\n",
        "    res_df = query_job.result().to_dataframe(bqstorage_client=bqstorageclient)\n",
        "\n",
        "    \n",
        "    \n",
        "    # 2nd. Part - Load the data frame to Google Sheets \n",
        "\n",
        "    # Instantiate Sheets service account client - Beforehand, create service account json and save it somewhere in GCP Storage.\n",
        "    if not os.path.isfile('/tmp/service_account.json'):\n",
        "        urllib.request.urlretrieve(\"< Path to .json with service account credentials stored in GCP Storage>\",\"/tmp/service_account.json\")\n",
        "\n",
        "    client = gspread.service_account(filename='/tmp/service_account.json')\n",
        "\n",
        "    sheet = client.open(\"DataMart_NYTaxi_per_customer\").sheet1\n",
        "\n",
        "    # Only when the Google Sheets file is new.\n",
        "    # sheet.update([res_df.columns.values.tolist()] + res_df.values.tolist())\n",
        "\n",
        "    # When Google Sheets file already has some input.\n",
        "    sheet.insert_rows(res_df.values.tolist(),2)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "db6GgJolxQ7L"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}