{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Read Excel Files in a 1000x faster way with Python.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMOil5zw0K27VujhjSwrOjJ"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pzmpRpmrpDi1"
      },
      "source": [
        "[Reference](https://towardsdatascience.com/read-excel-files-with-python-1000x-faster-407d07ad0ed8)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-lHYXpDo9MV"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from joblib import Parallel, delayed\n",
        "import time\n",
        "\n",
        "for file_number in range(10):\n",
        "    values = np.random.uniform(size=(20000,25))\n",
        "    pd.DataFrame(values).to_csv(f\"Dummy {file_number}.csv\")\n",
        "    pd.DataFrame(values).to_excel(f\"Dummy {file_number}.xlsx\")\n",
        "    pd.DataFrame(values).to_pickle(f\"Dummy {file_number}.pickle\")"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imMXY9vTpY3u"
      },
      "source": [
        "# Load an Excel File in Python"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O6a6z4dfpWdg",
        "outputId": "766b1472-b188-4c93-f05a-e02e893ab72c"
      },
      "source": [
        "start = time.time()\n",
        "df = pd.read_excel(\"Dummy 0.xlsx\")\n",
        "for file_number in range(1,10):\n",
        "    df.append(pd.read_excel(f\"Dummy {file_number}.xlsx\"))\n",
        "end = time.time()\n",
        "print(\"Excel:\", end - start)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Excel: 44.58169102668762\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LvJz5MZipeLh"
      },
      "source": [
        "# Load CSV in Python"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dWmEw7r1pcoS",
        "outputId": "1dacb1c8-098b-4964-ef8a-80dc061f49c5"
      },
      "source": [
        "start = time.time()\n",
        "df = pd.read_csv(\"Dummy 0.csv\")\n",
        "for file_number in range(1,10):\n",
        "    df.append(pd.read_csv(f\"Dummy {file_number}.csv\"))\n",
        "end = time.time()\n",
        "print(\"CSV:\", end - start)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CSV: 1.2988739013671875\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bhjq4vk4phd6",
        "outputId": "ee0eb1a4-acaf-4735-80e1-ae72172016d4"
      },
      "source": [
        "start = time.time()\n",
        "df = []\n",
        "for file_number in range(10):\n",
        "    temp = pd.read_csv(f\"Dummy {file_number}.csv\")\n",
        "    df.append(temp)\n",
        "df = pd.concat(df, ignore_index=True)\n",
        "end = time.time()\n",
        "print(\"CSV2:\", end - start)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CSV2: 1.2825779914855957\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fqd4KHNBp5cj"
      },
      "source": [
        "# CSV Import Parallelization with Joblib"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xaem83e4p22Z",
        "outputId": "60ae8ec3-8772-4468-f53d-467041dc1313"
      },
      "source": [
        "start = time.time()\n",
        "def loop(file_number):\n",
        "    return pd.read_csv(f\"Dummy {file_number}.csv\")\n",
        "df = Parallel(n_jobs=-1, verbose=10)(delayed(loop)(file_number) for file_number in range(10))\n",
        "df = pd.concat(df, ignore_index=True)\n",
        "end = time.time()\n",
        "print(\"CSV//:\", end - start)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.9s\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    1.2s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CSV//: 1.8728346824645996\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    1.8s finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YX1t-0SVqNVl"
      },
      "source": [
        "# Joblib"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VMN1F5tRp9mu",
        "outputId": "1d69cdd7-bf58-4e29-92ed-07832be96477"
      },
      "source": [
        "def loop(file_number):\n",
        "    return pd.read_csv(f\"Dummy {file_number}.csv\")\n",
        "df = Parallel(n_jobs=-1, verbose=10)(delayed(loop)(file_number) for file_number in range(10))\n",
        "\n",
        "#equivalent to\n",
        "df = [loop(file_number) for file_number in range(10)]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.5s\n",
            "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    1.1s finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0uluS8VkqS1h"
      },
      "source": [
        "# Faster with Pickles"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UcxpR78_qR1B",
        "outputId": "fda3c93d-3d56-4ca4-aa88-eec5c5f7a4d5"
      },
      "source": [
        "start = time.time()\n",
        "def loop(file_number):\n",
        "    return pd.read_pickle(f\"Dummy {file_number}.pickle\")\n",
        "df = Parallel(n_jobs=-1, verbose=10)(delayed(loop)(file_number) for file_number in range(10))\n",
        "df = pd.concat(df, ignore_index=True)\n",
        "end = time.time()\n",
        "print(\"Pickle//:\", end - start)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pickle//: 0.15920281410217285\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0241s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0800s.) Setting batch_size=4.\n",
            "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.1s finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0GhyNi_qdNs"
      },
      "source": [
        "# Loading Excel Files in Parallel"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TYOCZd-GqVCH",
        "outputId": "e4c2611c-8d17-4d33-bca4-1dd9dbf8f1ad"
      },
      "source": [
        "start = time.time()\n",
        "def loop(file_number):\n",
        "    return pd.read_excel(f\"Dummy {file_number}.xlsx\")\n",
        "df = Parallel(n_jobs=-1, verbose=10)(delayed(loop)(file_number) for file_number in range(10))\n",
        "df = pd.concat(df, ignore_index=True)\n",
        "end = time.time()\n",
        "print(\"Excel//:\", end - start)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    7.6s\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:   15.1s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Excel//: 37.57899594306946\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:   37.6s finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FQmUhRm9qbfn",
        "outputId": "dd996327-fc91-4c84-f7e1-f9bb076b3a0c"
      },
      "source": [
        "start = time.time()\n",
        "def loop(file_number):\n",
        "    temp = pd.read_excel(f\"Dummy {file_number}.xlsx\")\n",
        "    temp.to_pickle(f\"Dummy {file_number}.pickle\")\n",
        "    return temp\n",
        "df = Parallel(n_jobs=-1, verbose=10)(delayed(loop)(file_number) for file_number in range(10))\n",
        "df = pd.concat(df, ignore_index=True)\n",
        "end = time.time()\n",
        "print(\"Excel//:\", end - start)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    7.5s\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:   15.1s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Excel//: 37.55073857307434\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:   37.5s finished\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}