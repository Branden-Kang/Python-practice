{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP — Zero to Hero with Python.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOknweyQ9EC5gNF7NBfwHY8"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_xE08hx1AByK"
      },
      "source": [
        "[Reference](https://medium.com/towards-artificial-intelligence/nlp-zero-to-hero-with-python-2df6fcebff6e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENqLLOBHAFtU"
      },
      "source": [
        "# Section 1: NLP Introduction, Installation guide of Spacy and NLTK"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdczOHT5___b",
        "outputId": "123316d1-cb8d-4dda-ba4e-dbd3e2b8f566",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!python -m spacy download en"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.8.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.4)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.18.5)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (50.3.2)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.4.0)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/en_core_web_sm -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/en\n",
            "You can now load the model via spacy.load('en')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4c6GG0CARvH",
        "outputId": "a773b21b-c52e-4917-c6f3-6fb081e67d5f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print('Amit')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Amit\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_wW-TsrAVWF",
        "outputId": "4cb5beed-5c07-4ac4-9595-db2b47c995b5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#first insert the string to a variable\n",
        "string = 'GURUGRAM'\n",
        "\n",
        "#get first alphabet with index\n",
        "print(string[0])\n",
        "\n",
        "#printing multiple alphabets\n",
        "print(string[2], string[5])\n",
        "\n",
        "#for getting alphabet with negative indexing\n",
        "print(string[-4])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "G\n",
            "R R\n",
            "G\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPgcgCHRAhij",
        "outputId": "e9451e18-1c16-45a4-a361-b3833f46e2a3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(string[0:2])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GU\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Li3NlBOzAipB",
        "outputId": "4645780a-5247-4a76-a0af-5813f4f863cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(string[1:4])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "URU\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbZHXmEUBTVk"
      },
      "source": [
        "# Section 2: Basic ideas about a text, Regular expression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vX-hxxheAlCJ",
        "outputId": "7b929720-02bf-4d49-b7af-783e5b3fef5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        }
      },
      "source": [
        "#A sentence and the removing character from the sentence\n",
        "sentence = \"****Hello World! I am Amit Chauhan****\"\n",
        "removing_character = \"*\"\n",
        "\n",
        "#using strip function to remove star(*)\n",
        "sentence.strip(removing_character)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Hello World! I am Amit Chauhan'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PiQeAFizAoqb",
        "outputId": "ef4e40bd-43e4-49dd-d8bb-56ec90bdbf18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        }
      },
      "source": [
        "str1 = \"Happy\"\n",
        "str2 = \"Home\"\n",
        "\" Good \".join([str1, str2])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Happy Good Home'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RkzVqfiAuL-"
      },
      "source": [
        "# to use a regular expression, we need to import re\n",
        "import re"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NwoYVkS9Av0q"
      },
      "source": [
        "sentence = \"My computer gives a very good performance in a very short time.\"\n",
        "string = \"very\""
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_MzBHCtAxQx",
        "outputId": "72916c41-f848-4904-c44c-c29c53cd023d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "str_match = re.search(string, sentence)\n",
        "str_match"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_sre.SRE_Match object; span=(20, 24), match='very'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VfhFVkGTA946",
        "outputId": "624b2117-75d1-4dff-c09f-2eef76bd26ea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "str_match.span()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20, 24)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cN6nwifiBFAn",
        "outputId": "69cb112e-93d7-4899-bd39-fbb18e72c59e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "find_all = re.findall(\"very\", sentence)\n",
        "find_all"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['very', 'very']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJ2ljG8xBPIz",
        "outputId": "644b4f32-4f63-49c8-c9b0-ba9df9597b94",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for word in re.finditer(\"very\", sentence):\n",
        "    print(word.span())"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(20, 24)\n",
            "(47, 51)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38gbF4a5AIst"
      },
      "source": [
        "# Section 3: Tokenization and Stemming"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l65HZwn_AJJ1",
        "outputId": "163a5f85-512a-4360-f236-a42b67e7db47",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#import library\n",
        "import spacy\n",
        "\n",
        "#Loading spacy english library\n",
        "load_en = spacy.load('en_core_web_sm')\n",
        "\n",
        "#take an example of string\n",
        "example_string = \"I'm going to meet\\ M.S. Dhoni.\"\n",
        "\n",
        "#load string to library \n",
        "words = load_en(example_string)\n",
        "\n",
        "#getting tokens pieces with for loop\n",
        "for tokens in words:\n",
        "    print(tokens.text)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I\n",
            "'m\n",
            "going\n",
            "to\n",
            "meet\\\n",
            "M.S.\n",
            "Dhoni\n",
            ".\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xi-CECvUBfCB",
        "outputId": "51611502-b853-4a7a-9c16-6f1afd4c77d7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "str1 = load_en(u\"This laptop belongs to Amit Chauhan\")\n",
        "\n",
        "#getting tokens with index\n",
        "str1[1]\n",
        "\n",
        "#getting tokens with slicing\n",
        "str1[2:6]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "belongs to Amit Chauhan"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dn3CtDzBBkHd",
        "outputId": "b6c1114a-da5f-4ec2-b32e-1ff694ec287f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#import nltk library\n",
        "import nltk\n",
        "\n",
        "#import porter stemmer from nltk\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "pot_stem = PorterStemmer()\n",
        "\n",
        "#random words to test porter stemmer\n",
        "words = ['happy', 'happier', 'happiest', 'happiness', 'breathing', 'fairly']\n",
        "\n",
        "for word in words:\n",
        "    print(word + '----->' + pot_stem.stem(word))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "happy----->happi\n",
            "happier----->happier\n",
            "happiest----->happiest\n",
            "happiness----->happi\n",
            "breathing----->breath\n",
            "fairly----->fairli\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZenaU5wBpc6",
        "outputId": "463d9fb0-89a3-4925-b512-e9c06802fed0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from nltk.stem.snowball import SnowballStemmer\n",
        "snow_stem = SnowballStemmer(language='english')\n",
        "\n",
        "for word in words:\n",
        "    print(word + '----->' + snow_stem.stem(word))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "happy----->happi\n",
            "happier----->happier\n",
            "happiest----->happiest\n",
            "happiness----->happi\n",
            "breathing----->breath\n",
            "fairly----->fair\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9gOh7T0AKJG"
      },
      "source": [
        "# Section 4: Lemmatisation and Stop words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "761TXCAhAKoj",
        "outputId": "45eca964-0740-4fee-d2f4-f6397aab8e85",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#import library\n",
        "import spacy\n",
        "\n",
        "#Loading spacy english library\n",
        "load_en = spacy.load('en_core_web_sm')\n",
        "\n",
        "#take an example of string\n",
        "example_string = load_en(u\"I'm happy in this happiest place with all happiness. It feels how happier we are\")\n",
        "\n",
        "for lem_word in example_string:\n",
        "    print(lem_word.text, '\\t', lem_word.pos_, '\\t', lem_word.lemma, '\\t', lem_word.lemma_)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I \t PRON \t 561228191312463089 \t -PRON-\n",
            "'m \t AUX \t 10382539506755952630 \t be\n",
            "happy \t ADJ \t 244022080605231780 \t happy\n",
            "in \t ADP \t 3002984154512732771 \t in\n",
            "this \t DET \t 1995909169258310477 \t this\n",
            "happiest \t ADJ \t 244022080605231780 \t happy\n",
            "place \t NOUN \t 7512738811199700769 \t place\n",
            "with \t ADP \t 12510949447758279278 \t with\n",
            "all \t DET \t 13409319323822384369 \t all\n",
            "happiness \t NOUN \t 2779265004918961325 \t happiness\n",
            ". \t PUNCT \t 12646065887601541794 \t .\n",
            "It \t PRON \t 561228191312463089 \t -PRON-\n",
            "feels \t VERB \t 5741770584995928333 \t feel\n",
            "how \t ADV \t 16331095434822636218 \t how\n",
            "happier \t ADJ \t 244022080605231780 \t happy\n",
            "we \t PRON \t 561228191312463089 \t -PRON-\n",
            "are \t AUX \t 10382539506755952630 \t be\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddDNJF5mBwfI",
        "outputId": "62ebc4b1-6a6f-4c5e-8b87-80fc35abed3d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#import library\n",
        "import spacy\n",
        "\n",
        "#Loading spacy english library\n",
        "load_en = spacy.load('en_core_web_sm')\n",
        "\n",
        "print(load_en.Defaults.stop_words)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'those', 'bottom', 'doing', 'last', 'serious', 'nothing', 'next', 'should', 'whom', 'and', 'alone', 'cannot', 'per', 'after', 'afterwards', 'six', 'therefore', 'most', 'this', 'go', 'nor', 'they', 'thereafter', 'only', 'anywhere', 'whither', 'side', 'meanwhile', 'part', 'am', 'mine', 'except', 'get', 'third', 'whole', 'between', 'yourselves', 'be', 'take', 'him', 'themselves', 'one', 'without', 'whose', 'has', 'whereupon', 'in', 'noone', 'whereby', 'my', 'he', 'using', 'two', '‘re', 'less', 'behind', 'within', 'thus', 'becoming', 'someone', 'front', 'make', 'on', 'across', 'yet', 'the', 'wherever', 'full', 'indeed', 'over', 'out', 'ourselves', 'former', 'as', 'off', 'who', 'herself', 'therein', 'by', 'your', 'own', 'same', 'but', 'while', 'now', 'ever', 'anyhow', 'amongst', 'that', 'very', 'empty', 'several', 'something', 'everything', 'became', 'becomes', 'more', 'since', 'twelve', 'whatever', 'somewhere', 'yours', 'see', 'ten', 'herein', 'via', 'them', 'can', 'do', 'hundred', 'was', 'forty', 'everyone', 'another', 'i', 'keep', 'somehow', 'three', 'please', 'along', 'below', 'myself', 'with', 'these', 'did', 'either', 'not', 'beside', 'hereby', 'than', 'much', \"'ve\", 'when', 'does', 'done', 'others', 'beyond', 'an', 'been', '’d', 'eight', 'everywhere', 'both', 'formerly', 'here', 'towards', 'nobody', 'also', 'again', 'just', 'show', 'back', 'various', 'never', 'against', 'rather', 'such', 'give', 'moreover', 'fifty', 'from', 'himself', 'or', 'otherwise', 'were', 'quite', 'seem', 'there', 'at', 'might', 'whenever', '‘ve', 'around', 'our', 'thru', 'twenty', 'until', 'it', 'being', 'made', 'upon', 'due', 'his', 'into', 'put', 'really', 'unless', 'used', 'whereafter', 'hence', 'if', 'nine', 'yourself', 'may', \"'re\", '‘ll', 'seemed', '’m', 'its', 'neither', 'once', 'will', 'least', 'ours', 'a', 'have', 'because', '‘d', 'thereby', 'me', 're', 'must', 'thence', 'fifteen', 'become', 'say', 'thereupon', 'amount', 'many', 'of', 'n‘t', 'their', 'had', 'all', 'is', 'move', 'seems', 'anyone', 'seeming', 'too', 'you', 'ca', \"n't\", 'enough', 'together', 'are', '’ll', 'almost', 'always', 'itself', 'often', 'what', 'for', 'throughout', 'no', 'latterly', 'still', 'which', 'else', 'first', 'however', 'none', 'sometime', 'would', 'where', \"'ll\", 'mostly', 'above', 'latter', 'anyway', 'hereafter', 'beforehand', 'though', 'she', 'sometimes', 'her', 'so', 'toward', 'us', 'well', '‘s', 'further', 'during', 'hers', 'nowhere', 'among', 'perhaps', 'any', 'to', 'about', 'other', 'top', 'four', 'besides', \"'m\", 'whence', 'before', '’re', 'down', \"'s\", 'some', 'even', 'call', 'onto', \"'d\", 'n’t', 'five', 'each', 'how', 'few', 'namely', 'nevertheless', 'sixty', 'under', 'elsewhere', 'eleven', 'every', 'we', 'wherein', 'regarding', '’ve', 'whether', 'hereupon', 'name', 'anything', 'why', 'although', '‘m', 'then', '’s', 'whereas', 'whoever', 'already', 'could', 'up', 'through'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EB4ciyg2ALmU"
      },
      "source": [
        "# Section 5: Part of Speech (POS) and Named Entity Recognition (NER)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uaAsPjfMAMDz"
      },
      "source": [
        "#import library\n",
        "import spacy\n",
        "\n",
        "#Loading spacy english library\n",
        "load_en = spacy.load('en_core_web_sm')\n",
        "\n",
        "str1 = load_en(u\"This laptop belongs to Amit Chauhan\")"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wI55lYUB2lg",
        "outputId": "ccd75a64-37ef-499b-d7c4-cfd53715a887",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(str1[1])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "laptop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKvDiIceB4Bb",
        "outputId": "cc87e47f-d5c1-4fa8-c9ae-783d286ca2e6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#pos_ tag operation \n",
        "print(str1[1].pos_)\n",
        "\n",
        "#to know fine grained information\n",
        "print(str1[1].tag_)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NOUN\n",
            "NN\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHO4YfaaB7KW",
        "outputId": "86fc7205-bd69-45a7-f147-88219ee8a584",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "pos_count = str1.count_by(spacy.attrs.POS)\n",
        "pos_count"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{85: 1, 90: 1, 92: 1, 96: 2, 100: 1}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4IJTN45EB8hW",
        "outputId": "c927c91c-73d2-4821-9bef-bcd26de9f199",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        }
      },
      "source": [
        "str1.vocab[90].text"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'DET'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YM_qfbB3B9lL",
        "outputId": "5ed9880d-2dd1-4c0e-c98f-588be034b6d8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#import library\n",
        "import spacy\n",
        "\n",
        "#Loading spacy english library\n",
        "load_en = spacy.load('en_core_web_sm')\n",
        "\n",
        "#lets label the entity in the text file\n",
        "\n",
        "file = load_en(u\" I am living in India, Studying in IIT\")\n",
        "\n",
        "if file.ents:\n",
        "    for ner in file.ents:\n",
        "        print(ner.text + ' - '+ ner.label_ + ' - ' + \n",
        "               str(spacy.explain(ner.label_)))\n",
        "else:\n",
        "    print('No Entity Found')"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "India - GPE - Countries, cities, states\n",
            "IIT - ORG - Companies, agencies, institutions, etc.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}